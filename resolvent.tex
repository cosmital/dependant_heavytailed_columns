\documentclass[a4papaer, titlepage]{book}

\input{package}

\title{PhD manuscript:\\
Concentration of the measure and random matrices to study data processessing algorithms}
\author{Cosme Louart}
\date{February, 28 - 2022}
\begin{document}

\maketitle
\frontmatter


\mainmatter

\part{Concentration of the resolvent of sample covariance matrix}\label{prt:resolvent}
Considering a non centered sample covariance matrix $\frac{1}{n}XX^T$, where $X = (x_1,\ldots, x_n) \in \mathcal M_{p,n}$ is the data matrix, we denote $\Sp(\frac{1}{n}XX^T)$ the spectrum of $\frac{1}{n}XX^T$.
The spectral distribution of $\frac{1}{n}XX^T$, denoted $\mu \equiv  \frac{1}{p}\sum_{\lambda \in \Sp(\frac{1}{n}XX^T)} \delta_{\lambda}$, is classically studied through its Stieltjes transform expressed as:
\begin{align*}
  g : \begin{aligned}[t]
    &\mathbb C \setminus \Sp \left(\frac{1}{n}XX^T\right) &\longrightarrow& \hspace{1cm}\mathbb C\\
    &\hspace{1cm} z &\longmapsto & \int_{\mathbb R} \frac{d\mu(\lambda)}{\lambda - z} .
  \end{aligned}
\end{align*}
The relevance of the Stieltjes transform has been extensively justified in some seminal works \cite{MAR67,SIL86} by the Cauchy integral that provides for any analytical mapping $f$ defined on a neighborhood of a subset $B\subset \Sp(\frac{1}{n}XX^T)$ the identity:
\begin{align*}
  \int_B f(\lambda) d\mu(\lambda) = \frac{1}{2i \pi} \oint_{\gamma} f(z)g(z) dz,
\end{align*}
where $\gamma: [0,1] \to \mathbb C \setminus \Sp(\frac{1}{n}XX^T)$ is a closed path on which $f$ is defined and whose interior $I_\gamma$ satisfies $I_\gamma \cap \Sp(\frac{1}{n}XX^T) = B \cap \Sp(\frac{1}{n}XX^T)$.
 % When $\Sp(\frac{1}{n}XX^T)$ has several bulk ( discrete) 
  But we can go further and approximate linear functionals of the eigenvectors thanks to the resolvent. If we denote $E_B$ the random eigenspace associated to the eigenvalues of $\frac{1}{n}XX^T$ belonging to $B$, and $\Pi_B$ the orthogonal projector on $E_B$, then for any deterministic matrix $A \in \mathcal M_{p}$:
 \begin{align}\label{eq:estimation_eigenspaces}
   \tr(\Pi_BA) = \frac{1}{2i\pi}\int_\gamma \tr(AR(z)) dz&
   &\text{ with } R(z) \equiv \left(\frac{1}{n}XX^T - z I_p\right)^{-1}.
 \end{align}
% And noting that $g(z) = \frac{1}{n}\tr(R(z))$, 
The matrix $R(z)$ is commonly called the resolvent of $\frac{1}{n}XX^T$. It satisfies in particular that, for all $z \in \mathbb C \setminus \Sp(\frac{1}{n}XX^T)$, $g(z) = \frac{1}{p} \tr(R(z))$. It thus naturally becomes the central element of the study of the spectral distribution. 
One of the first tasks in random matrix theory is to devise a so called ``deterministic equivalent'' for $R(z)$ (\cite{HAC07}), that we will denote here $\tilde R(z)$. Specifically, we look for a deterministic matrix computable from the first statistics of our problem and close to $\mathbb E[R(z)]$. In particular, a main result of random matrix theory sets that this deterministic equivalent only expresses with means and covariances of the $x_i$'s. Two questions then arise:
\begin{enumerate}
  \item How close to $\mathbb E[R(z)]$ is $R(z)$?
  \item What does this notion of closeness really mean ?
  % \item 
\end{enumerate}
The first questions relate to concentrations properties on $R(z)$ that arise from concentration properties on $X$. The study of random matrices originally studied with i.i.d.\@ entries (\cite{MAR67}, \cite{YIN86}), mere Gaussian hypotheses (\cite{BOU96}), or with weaker hypotheses concerning the first moments of the entries (supposed to be independent or at least independent up to an affine transformation). 
Some more recent works showed the concentration of the spectral distribution of Wishart or Wigner matrices with bounding assumption on the entries of the random matrix under study --or at least a linear transformation of it-- allows to employ Talagrand results in \cite{guionnet2000concentration,guntuboyina2009concentration} that also treat some log-concave hypotheses allowing to relax some independence assumptions as it is done in \cite{ADA15}. One can also find very light hypotheses on the quadratic functionals of the columns (\cite{Bai08t}), improved in \cite{YAS16} or on the norms of the columns and the rows (\cite{ADA11}). 
In the present work, we do not consider the case of what is called convexly concentrated random vectors in \cite{VU2014,MEC11,ADA11} as it is done in \cite{guionnet2000concentration} because it requires a different approach (see Section~\ref{sec:resolvent_convex}). 
% We adopt slightly more general hypotheses than the one adopted by \cite{ADA15} that allows to provide more precise result than \cite{Bai08t} and \cite{ADA11}. The exact concentration hypothesis on $X$ is described in Assumption~\ref{ass:concentration_X}: for simplicity of exposition in the introduction, we will just assume here that the matrix $X$ is a $\lambda$-Lipschitz transformation of a Gaussian vector $Z\sim \mathcal N(0, I_d)$ for any given $d \in \mathbb N$ but for a Lipschitz parameter $\lambda \ll n,p$ (we will write $\lambda \leq O(1)$). We also require the columns $x_1,\ldots, x_n$ of $X$ to be independent, but the entries of the columns may have intricate dependencies, as long as they remain $\lambda$-Lipschitz transformations of a Gaussian vector. 
% This represents a wide range of random vectors and, among the most commonly studied random vectors, this mainly merely excludes the heavy tailed distributions and the discrete distributions.\footnote{Some of these random vectors still satisfy what is referred to as ``convex concentration'' hypotheses and their sample covariance matrix may still be studied but to the expense of more advanced control (see \cite{louart2018concentration} and a coming follow-up work).}
% Some large description of the concentration of measure phenomenon can be found in \cite{LED05} and \cite{BOU13} and more specifically, some elementary applications to random matrices are provided in \cite{TAO12}, \cite{VER18} and \cite{louart2018concentration}.
%  We further provide in subsection ``Practical implications'' a series of arguments demonstrating the relevance of this approach in classical problems of statistical machine learning.

The Lipschitz concentration hypothesis we assume on $X$ in a sense ``propagates'' to the resolvent that then satisfies, for all deterministic matrices $A$ such that $\|A\|_F \equiv \sqrt{\tr(AA^T)} \leq 1$ and for all $z$ not too close to the spectrum of $\frac{1}{n}XX^T$:
\begin{align}\label{eq:approximation_resolvante}
  \mathbb P \left(\left\vert \tr \left(A \left(R(z) - \mathbb E[R(z)]\right)\right)\right\vert\geq t\right) \leq C e^{-cnt^2} + C e^{-cn},
\end{align}
for some numerical constants $C,c$ independent of $n,p$. We see from \eqref{eq:approximation_resolvante} the important benefit gained with our concentration hypothesis on $X$: it provides simple \textit{quasi-asymptotic} results on the convergence of the resolvent with speed rates, while most of the results on random matrices are classically expressed in the limiting regime $n,p \to \infty$.

The condition $\|A\|_F \leq 1$ answers our second question: a specificity of our approach is to control the convergence of the resolvent with the Frobenius norm at a speed of order $O(1/\sqrt n)$. The concentration inequality \eqref{eq:approximation_resolvante} means that all linear forms of $R(z)$, which are $1$-Lipschitz\footnote{or $\lambda$-Lipschitz with $\lambda\leq O(1)$} for the Frobenius norm, have a standard deviation of order $O(1/\sqrt n)$; this is crucial to be able to estimate quantities expressed in \eqref{eq:estimation_eigenspaces}. 
Generally, the Stieltjes transform $g(z) = -\frac{1}{p}\tr(R(z)) $ is classically the only studied linear forms of the resolvent (it is $1/\sqrt p$-Lipschitz so its standard deviation is of order $O(1/\sqrt {pn})$ which is a classical result although not exactly under a concentration of measure assumption) or projections on deterministic vectors $u^T R(z)u$, for which only the concentration in spectral norm with a speed of order $O(1/\sqrt n)$ is needed.

Those remarks gain a real importance when we are able to estimate the expectation of $R(z)$ with a deterministic equivalent (that we can compute). We look for a closeness relation in Frobenius norm:
\begin{align*}
   \left\Vert \mathbb E[R(z)] - \tilde R(z)\right\Vert_F\leq O \left(\frac{1}{\sqrt n}\right).
 \end{align*} 
 We may then replace in \eqref{eq:approximation_resolvante} the term ``$\mathbb E[R(z)]$'' by $\tilde R(z)$ which we are able to compute from the expectations and covariances of the columns $x_1,\ldots, x_n$.

Note that we do not assume that the columns are identically distributed: in particular, the means and covariances can be all different (although they have to satisfy some boundedness properties expressed in Assumptions~\ref{ass:borne_norme_x_i} and~\ref{ass:Sigma_borne_inferieurement} at the beginning of Chapter~\ref{cha:resolvent}). This remark may be related to the studies made of matrices $X$ with a variance profile: but this is here even more general because the laws of the columns are not solely defined from their means and covariances (although the spectral distribution of $\frac{1}{n}XX^T$ just depends on these quantities).

The extension of Marcenko Pastur result to non-identically distributed columns was well known; one can cite for instance \cite{hachem2007deterministic,wagner2012large,yin2020singular} treating a very similar problem but with different assumptions of concentration (just some moments of the entries need to be bounded) the result is then given in the form of a limit (not a concentration inequality), \cite{kammoun2016no} showing that no eigenvalues lie outside of the support with Gaussian hypotheses and \cite{dembczak2022empirical} imposing some weak isotropic conditions on the different covariances. 
We will follow the proof scheme of \cite{hachem2007deterministic} where the authors introduce two consecutive deterministic equivalents, the first one depending on the expectations of $\Lambda^z = z - \frac{1}{n}x_i^TQ_{-i}^zx_i$, and the second one being expressed through fixed point equation that approximate those quantities.  
We can indeed estimate the expectations of the quantities $\Lambda^z_1, \ldots, \Lambda^z_n$ with a diagonal matrix\footnote{The interest to resort to a diagonal matrix of $\mathcal M_{n}$ rather than to a vector of $\mathbb R^n$ will be clearer later -- mainly to employ Proposition~\ref{pro:estimation_XDY} in a natural formalism.} $\tilde \Lambda^z = \diag(\tilde \Lambda_i^z)_{i \in [n]} \in \mathcal D_{n}(\mathbb C)$ obtained after successive iteration of the following equation (quite different from the one presented in \cite{hachem2007deterministic}): 
\begin{align}\label{eq:point_fixe_lambda_intro}
  \forall i\in [n]  : \ 
  \tilde \Lambda^z_i = z  - \frac{1}{n} \tr \left(\Sigma_i \tilde Q^{\tilde \Lambda^z}\right)&
  &\text{with} \ \ \tilde Q^{\tilde \Lambda^z} \equiv \left(I_p - \frac{1}{n} \sum_{i=1}^n \frac{\Sigma_i}{\tilde \Lambda^z_i}\right)^{-1},
\end{align}
in which $\Sigma_i = \mathbb E[x_ix_i^T]$.

% To our knowledge, the proof existence and uniqueness of these equations is an original contribution of the present paper.
% but we further need to describe some stability properties of \eqref{eq:point_fixe_lambda_intro} in order to set convergence bounds. This 
 % to extend the definition of the deterministic equivalent of the resolvent to the whole set $\mathbb H$ is incomplete because it does not ensure that the limit of their iterative sequence is the solutions to \eqref{eq:point_fixe_lambda_intro} whose existence and uniqueness is therefore not proven. Besides,  that is effectively used to estimate the Stieljes transform in practice -- besides, this approach also do not provide any converging bound).

 The difficulties are $(i)$ to prove the existence and uniqueness of $\tilde \Lambda^z$ and $(ii)$ to ensure some stability properties\footnote{Conceptually, it means that if we have a diagonal matrix $L \in \mathcal M_{n}$ satisfying $\forall i\in [n]  : \ L_i \equiv z - \frac{1}{n} \tr \left(\Sigma_i \tilde Q^{L}\right)$ then $L$ is ``close'' to $\tilde \Lambda^z$.} on this equation eventually allowing us to assert that $\|\mathbb E[R(z)] - \tilde R(z)\|_F \leq O( 1/ \sqrt n)$, where $\tilde R(z) \equiv \frac{1}{z}\tilde Q^{\tilde \Lambda^z}$.
 The existence and uniqueness of similar equations has already proven thanks to complex analysis justification (normal family theorem in \cite{hachem2007deterministic} and Vitali's theorem in \cite{wagner2012large,yin2020singular}), those approaches allows to extend convergence properties for some $z$ to the whole convex half plane $\mathbb H$, however we are not only looking for an asymptotic result but for a quasi asymptotic result, meaning that we want precise convergence bounds for $n$ and $p$ big but not infinite.

% The two aforementioned difficulties disappear when most of the $\Sigma_1, \ldots, \Sigma_n$ are equal; in other words, when we have a finite number of distinct distributions for the $x_i$'s. 
% When they are all different, our solution consists in introducing 
The two aforementioned difficulties disappear with the introduction of a convenient semi-metric\footnote{A semi metric is defined as a metric  that does not satisfy the triangular inequality.} $d_s$ on which the fixed point equation satisfied by $\tilde \Lambda^z$ is contractive, leading (after still some work since a semi-metric is not as easy to treat as if $d_s$ were a true metric) to existence, uniqueness and stability properties. This semi-metric, quite similar to the one already introduced in \cite{louart2022concentration} to study robust estimators, is defined for any $D,D' \in \mathcal D_n(\mathbb H)$ as:
\begin{align*}
  d_s(D,D') = \left\Vert \frac{D - D'}{\sqrt{\Im(D)\Im(D')}}\right\Vert.
\end{align*}
This semi-metric appears as a central object in random matrix theory, one can indeed point out the fact that any Stieltjes transform is $1$-Lipschitz under this semi-metric (see Proposition~\ref{pro:Stieltjes_transforms_are_1_Lipschitz}). It relates to PoincarÃ© metric, the hyperbolic metric writes indeed $d_{\mathbb H}(z,z') = \cosh(d_s(z,z')^2 - 1)$. Apart from the book \cite{earle1970fixed} that provided a groundwork for the introduction of such a metric, this approach already gained some visibility in \cite{helton2007operator,keller2013spectral} or in a context closer to ours for the study of Wishart matrices and in a squared form in \cite{AJA16}. We prefer an expression proportional to $\|D-D'\|$ because it is more adapted to comparison with classical distance on $\mathcal D_n(\mathbb H)$, as it is done in Proposition~\ref{pro:equation_proche_implique_solution_proche_version2} that subsequently provides bounds to the convergence speed. 
Let us outline that once the appropriate semi-metric is identified, contractivity properties are not sufficient to prove the existence and uniqueness to \eqref{eq:point_fixe_lambda_intro}: one also needs to introduce the correct space over which the mapping is contractive ($\mathcal D_{I^z} \equiv \{D \in \mathcal D_n(\mathbb H), \frac{D}{z} \in \mathcal D_n(\mathbb H)\}$). 



\chapter{Stable semi metric}\label{cha:stable_semi_metric}






% \subsection{Concentration of implicit solutions}

% The particular case of contractive equation is more spread then one could expect, in particular when studying the following equation:
% \begin{align}\label{eq:equation_implicite_Y}
%   \Theta(Y) = 0,
% \end{align}
% if $\Theta$ is differentiable, $\|d\Theta\|_\infty \leq O(1)$, then one can transform~\eqref{eq:equation_implicite_Y} into:
% \begin{align*}
%   Y = \Phi(Y)&
%   &\text{where}&
%   &\Phi:y \mapsto y - \Theta(y)/\|d\Theta\|_\infty,
% \end{align*}
% indeed, in that case










\section{Definition and first properties}\label{classe_stable_R}

The stable semi-metric which we define here is a convenient object which allows us to set Banach-like fixed point theorems. It has a crucial importance to prove the existence and uniqueness of $\hat C$ but also to obtain some random matrix identities on $\hat C$, such as the estimation of its limiting spectral distribution. 
\begin{definition}\label{def:distance_stable}
  We call the \emph{stable semi-metric} on $\mathcal D_n^+ = \{D\in \mathcal D_n, \forall i \in [n], \ D_i>0\}$ the function:
  \begin{align}\label{eq:definition_stable_metric}
    \forall \Delta,\Delta' \in \mathcal D_n^+ : \ \ d_s(\Delta, \Delta') \equiv  \left\Vert  \frac{ \Delta- \Delta'}{\sqrt{\Delta \Delta'}}\right\Vert.
  \end{align}
\end{definition}


In particular, this semi-metric can be defined on $\mathbb R^+$, identifying $\mathbb R^+$ with $\mathcal D_1^+$. 

The function $d_s$ is not a metric because it does not satisfy the triangular inequality, one can see for instance that:
  \begin{align}\label{eq:triangular_inequality_not_valid}
    d_s(4,1) = \frac{3}{2} > \frac{1}{\sqrt 2} + \frac{1}{\sqrt 2}=d_s(4,2) + d_s(2,1)  
  \end{align}
  More precisely, for any $x,z \in \mathbb R_+$ such that $x<z$, if one differentes twice the mapping $g : y \to \frac{(xy-x)^2}{xy} + \frac{(z-y)^2}{xy}$, one obtains:
   \begin{align*}
     g'(y) = \frac{1}{y}- \frac{y}{x^2} + \frac{1}{z} - \frac{z}{x^3}&
     &\text{and}&
     &g'\!{}'(y) = \frac{3y}{x^3} + \frac{3z}{x^3}>0,
   \end{align*}
  which proves that $g$ is strictly convex on $[x,z]$ and therefore it admits a minimum $y_0$ on $]x,z[$ (since $g(x) = g(z)$). In particular, one can bound:
  \begin{align*}
    d_s(x,z ) > \sqrt{d_s(x,y_0)^2 + d_s(y_0,z)^2}
  \end{align*}
  One can however sometimes palliate this weakness when needed thanks to the following inequality proved in Section~\ref{sub:stable_metic}.
  \begin{proposition}[Pseudo triangular inequality]\label{pro:palliation_absence_inegalite_triangulaire}
    Given $x,z,y \in \mathbb R^+$:
    \begin{align*}
        |x-y| \leq |y - z|&
        &\Longrightarrow&
       &d_s(x,y) \leq d_s(x,z).
     \end{align*}
     In addition, for any $p\in \mathbb N^*$ and $y_1,\ldots,y_{p-1} \in \mathbb R^+$, we have the inequalities\footnote{The mapping $x\mapsto x^p$ is not Lipschitz for the semi-metric $d_s$ (unlike $x \mapsto x^{\frac{1}{p}}$).}:
  \begin{align*}
    d_s(x,y_1) + \cdots + d_s(y_{p-1},z) \geq d_s \left(x^{\frac{1}{p}},z^{\frac{1}{p}}\right)
    \geq d_s \left(x,z\right)^{1/p}
  \end{align*}
  and the left inequality turns into an equality in the case $y_i = x^{\frac{p-i}{p}} z^{\frac{i}{p}}$ for $i\in\{1,\ldots,p-1\}$.
  \end{proposition}
  
\begin{proof}%[Proof of Proposition~\ref{pro:palliation_absence_inegalite_triangulaire}]
   For a given integer $p \geq 1$, let us differentiate the mapping:
   \begin{align*}
     f_p : \begin{aligned}[t]
       \mathbb R_+^{p-1}\hspace{0.4cm}& \longrightarrow&\mathbb R \hspace{1.8cm}\\
       (y_1,\ldots, y_{p-1})&\longmapsto&\frac{y_1-x}{\sqrt{y_1x}} + \cdots  \frac{z-y_{p-1}}{\sqrt{zy_{p-1}}}
     \end{aligned}
   \end{align*}
   one can compute for any $y_1,\ldots, y_{p-1} \in \mathbb R^+$ and $i \in [p-1]$:
   \begin{align}\label{eq:differentielle_f_p_triangulaire}
     \frac{\partial f_p(y_1,\ldots, y_{p-1})}{\partial y_i} = \frac{1}{2} \frac{1}{\sqrt{y_i y_{i-1}}} \left(1+ \frac{y_{i-1}}{y_i}\right) -\frac{1}{2} \frac{1}{\sqrt{y_{i+1} y_{i}}} \left(1+ \frac{y_{i+1}}{y_{i}}\right) 
   \end{align}
   (where $y_0$ and $y_{p}$ designate respectively $x$ and $z$)
   In particular, when $p=1$, for any $y\geq x >0$:
   \begin{align*}
     \frac{\partial }{\partial y} \left(\frac{y-x}{\sqrt{yx}}\right) = \frac{1}{2} \frac{1}{\sqrt{xy}} \left(1+\frac{x}{y}\right) \geq 0
   \end{align*}
   which proves the first result of the proposition. 
   Now if we assume that $y \leq x \leq z$:
   \begin{align*}
     d_s(x,y) + d_s(y,z) \geq d_s(x,z),
   \end{align*}
   and the same inequality holds if one assumes that $x\leq z \leq y$. Returning to the setting of the proposition, we can therefore place ourselves in the open space:
   \begin{align*}
     \mathcal U^p_{x,z} = \{(y_1,\ldots, y_p) \in \mathbb R^{p-1}_+,x < y_1 < \cdots < y_{p-1} < z\}.
   \end{align*}

   If one fixes $x,z \in \mathbb R^+$, then $f_p(x,y_1,\ldots, y_{p-1},z) = d_s(x,y_1) + \cdots + d_s(y_{p-1} ,z)$ is minimum for $y_1,\ldots, y_{p-1}$ satisfying:
   \begin{align*}
     \frac{1}{\sqrt{y_i y_{i-1}}} \left(1- \frac{y_{i-1}}{y_i}\right) = \frac{1}{\sqrt{y_{i+1} y_{i}}} \left(1- \frac{y_{i}}{y_{i+1}}\right)
   \end{align*}
   which is equivalent to $y_i = \sqrt{y_{i-1} y_{i+1}}$. Noting $\tilde x = \log(x),\tilde y_1 = \log({y_1}), \ldots, \tilde y_n = \log({y_n}), \tilde z = \log(z) $, we see that this identity writes $\tilde y_i = \frac{1}{2} (\tilde y_{i-1} \tilde y_{i+1})$, which implies $\tilde y_i = \tilde x + \frac{i}{p} (\tilde z - \tilde x)$, or in other words:
   \begin{align*}
     y_i = x^{\frac{p-i}{p}} z^{\frac{i}{p}}.
   \end{align*}
   In that case:
   \begin{align*}
     d_s(y_i, y_{i+1}) 
     = \left\vert \frac{x^{\frac{p-i}{2p}} z^{\frac{i}{2p}}}{x^{\frac{p-i -1}{2p}} z^{\frac{i+1}{2p}}} - \frac{x^{\frac{p-i -1}{2p}} z^{\frac{i+1}{2p}}}{x^{\frac{p-i}{2p}} z^{\frac{i}{2p}}} \right\vert
     = \left\vert \frac{x^{\frac{1}{2p} } }{z^{\frac{1}{2p} } } - \frac{z^{\frac{1}{2p} } }{x^{\frac{1}{2p} } }  \right\vert  = d_s \left( x^{\frac{1}{p}} , z^{\frac{1}{p}}   \right),
   \end{align*}
   and the same holds for $d_s(x, y_{1}) $ and $d_s(y_{p-1}, z) $.

   The last inequality is just a consequence of the concavity of $t\to t^{1/p}$:
   \begin{align*}
     d_s \left( x^{\frac{1}{p}} , z^{\frac{1}{p}}   \right)
     =  \frac{z^{\frac{1}{p}} - x^{\frac{1}{p}}}{(xz)^{\frac{1}{2p}} }  
     = \frac{\frac{1}{p}\int_0^{z-x} (t+x)^{\frac{1-p}{p}} dt}{(xz)^{\frac{1}{2p}} } 
     \leq \frac{\frac{1}{p}\int_0^{z-x} t^{\frac{1-p}{p}} dt}{(xz)^{\frac{1}{2p}} } 
      = \left( \frac{z - x}{(xz)^{\frac{1}{2}} }  \right)^{\frac{1}{p}} \! \! \! \ = d_s(x,z)^{\frac{1}{p}}.
   \end{align*}
  \end{proof} 

The semi-metric $d_s$ is called stable due to its many interesting stability properties.
\begin{property}\label{prot:stabilite_homotethie_distance_stable}
  Given $\Delta,\Delta' \in \mathcal D_n^+$ and $\Lambda \in \mathcal D_n^+$:
  \begin{align*}
     d_s \left(\Lambda \Delta, \Lambda \Delta'\right) 
    =d_s \left(\Delta, \Delta'\right)&
    &\text{and}&
    &d_s \left(\Delta^{-1}, \Delta'^{-1}\right) =d_s \left(\Delta, \Delta'\right).
  \end{align*}
\end{property}

\begin{property}\label{prot:pseudo_tringular_inequality}
  Given four diagonal matrices $\Delta,\Delta',D,D' \in \mathcal D_n^+$:
  \begin{align*}
     d_s(\Delta +D,  \Delta'+D') \leq \max(d_s(\Delta,  \Delta'), d_s(D, D')).
   \end{align*} 
\end{property}
To prove this property one needs two elementary results.
\begin{lemma}\label{lem:stability_preliminary_lemma}
  Given four positive numbers $a,b,\alpha, \beta \in \mathbb R^+$:
  \begin{align*}
    \sqrt{ab} + \sqrt{\alpha \beta} \leq \sqrt{(a+\alpha)(b+\beta)}&
    &\text{and}&
    &\frac{a+\alpha}{b+\beta} \leq \max \left(\frac{a}{b} ,\frac{\alpha}{\beta} \right)
  \end{align*}
\end{lemma}
\begin{proof}
  For the first result, we deduce from the inequality $4ab\alpha\beta \leq (a\alpha + b\beta)^2$:
  \begin{align*}
    \left(\sqrt{ab} + \sqrt{\alpha \beta}\right)^2 
    &= ab + \alpha \beta + 2\sqrt{ab\alpha\beta}
    \leq ab + \alpha \beta + a\beta + b\alpha = (a+\alpha)(b+\beta)
  \end{align*}
  For the second result, we simply bound:
  \begin{align*}
    \frac{a+\alpha}{b+\beta} \leq \frac{a}{b} \frac{b}{b+\beta} + \frac{\alpha}{\beta} \frac{\beta}{b+\beta} \leq \max \left(\frac{a}{b} ,\frac{\alpha}{\beta} \right) \left( \frac{b}{b+\beta} + \frac{\beta}{b+\beta} \right) = \max \left(\frac{a}{b} ,\frac{\alpha}{\beta} \right)
  \end{align*}
\end{proof}
\begin{proof}[Proof of Property~\ref{prot:pseudo_tringular_inequality}]
  For any $\Delta,\Delta',D,D' \in \mathcal D_n^+$, there exists $i_0 \in [n]$ such that:
  \begin{align*}
  d_s(\Delta+D, \Delta'+D')
    &= \frac{\left\vert \Delta_{i_0}- \Delta_{i_0}'+ D_{i_0}-D_{i_0}' \right\vert}{\sqrt{(\Delta_{i_0}+D_{i_0})(\Delta'_{i_0}+D_{i_0}')}}\\
    &\leq \frac{\left\vert \Delta_{i_0}-\Delta_{i_0}'\right\vert +\left\vert D_{i_0}-D_{i_0}' \right\vert}{\sqrt{\Delta_{i_0}\Delta'_{i_0}} +\sqrt{D_{i_0}D_{i_0}' })}
    \leq \max \left(\frac{\left\vert \Delta_{i_0}-\Delta_{i_0}'\right\vert}{\sqrt{\Delta_{i_0}\Delta_{i_0}'}}, \frac{\left\vert D_{i_0}-D_{i_0}' \right\vert}{\sqrt{D_{i_0}D_{i_0}'}}\right)
  \end{align*}
  thanks to Lemma~\ref{lem:stability_preliminary_lemma}.
\end{proof}

\section{Stable class}
\begin{definition}[Stable class]\label{def:classe_des_fonctions_stables}
  The set of $1$-Lipschitz functions for the stable semi-metric is called the stable class. We denote it:
  \begin{align*}
    \mathcal S \left(\mathcal D_n^+\right) \equiv \left\{ f : \mathcal D_n^+ \rightarrow \mathcal D_n^+ \ | \ \forall \Delta,\Delta' \in \mathcal D_n^+,  \ \Delta \neq \Delta': \ d_s(f(\Delta),f(\Delta')) \leq d_s (\Delta,\Delta')\right\}.
  \end{align*}
  The elements of $\mathcal S \left(\mathcal D_n^+\right) $ are called the stable mappings. 
\end{definition}

Let us then provide the properties which justify why we call $\mathcal S \left(\mathcal D_n^+\right)$ a \textit{stable} class: this class indeed satisfies far more stability properties than the usual Lipschitz mappings (for a given norm). Those stability properties are direct consequences to Properties~\ref{prot:stabilite_homotethie_distance_stable} and~\ref{prot:pseudo_tringular_inequality}.
\begin{property}\label{prot:stabilite_contr_mapping_mat_diagonales}
  Given $\Lambda, \Gamma\in \mathcal D_n^+$ and $f,g \in \mathcal S(\mathcal D_n^+)$:
  \begin{align*}
    \left( \Delta \mapsto \Lambda f(\Gamma \Delta) \right)\in \mathcal S(\mathcal D_n^+),&
    &\frac{1}{f}\in \mathcal S(\mathcal D_n^+),&
    &f \circ g\in \mathcal S(\mathcal D_n^+),&
    &f +g\in \mathcal S(\mathcal D_n^+).
  \end{align*}
\end{property}
\section{The sub-monotonic class}
The stable class has a very simple interpretation when $n=1$.
Given a function $f: \mathbb R^+ \rightarrow \mathbb R^+$ we introduce two characteristic functions $f_/,f_\times : \mathbb R^+ \rightarrow \mathbb R^+$:
\begin{align*}
    f_{/} \ : \ x \mapsto \frac{f(x)}{x} &
    &\text{and}&
    &f_{\times} \ : \ x \mapsto x f(x).
  \end{align*}
\begin{property}\label{prot:Caracterisation_stabilite_monotonie}
A function $f : \mathbb R^+ \rightarrow \mathbb R^+$ is a stable mapping if and only if $f_/ $ is non-increasing and $f_\times$ is non-decreasing.
\end{property}
\begin{proof}%[Proof of Property~\ref{prot:Caracterisation_stabilite_monotonie}]
  
  Let us consider $x,y \in \mathbb R^+$, such that, say, $x\leq y$. We suppose in a first time that $f_/$ is non-increasing and that $f_\times$ is non-decreasing.
  We know that $\frac{f(x)}{x} \geq \frac{f(y)}{y}$, and subsequently:
  \begin{align}\label{eq:inegalite_caract_syabe_class1}
    f(y) - f(x) \leq \frac{f(y)}{y}(y-x)&
    &\text{and}&
    &f(y) - f(x) \leq \frac{f(x)}{x}(y-x)
  \end{align}
  The same way, since $f(x)x \leq f(y)y$ we also have the inequalities:
  \begin{align}\label{eq:inegalite_caract_syabe_class2}
    f(x)-f(y) \leq \frac{f(y)}{x}(y-x)&
    &\text{and}&
    &f(x) - f(y) \leq \frac{f(x)}{y}(y-x)
  \end{align}
  Now if $f(y)\geq f(x)$, we can take the root of the product of the two inequalities of \eqref{eq:inegalite_caract_syabe_class1} and if $f(y)\leq f(x)$, we take the root of the product of the two inequalities of \eqref{eq:inegalite_caract_syabe_class2}, to obtain, in both cases:
  \begin{align*}
    \left\vert f(x)-f(y)\right\vert \leq \sqrt{\frac{f(y)f(x)}{xy}} \left\vert x-y\right\vert
  \end{align*}
  That means that $f\in \mathcal S(\mathbb R^+)$.

  Conversely, if we now suppose that $f\in \mathcal S(\mathbb R^+)$, we then use the bound:
  \begin{align*}
    \left\vert f(y) - f(x) \right\vert \leq \sqrt{\frac{f(y)f(x)}{xy}} (y-x).
  \end{align*}
  First, if $f(x) \leq f(y)$, then $f(x)x \leq f(y)y$ and we can bound:
  \begin{align*}
   f(y)-f(x)
   \leq\max \left( \frac{f(x)}{x}, \frac{f(y)}{y} \right) (y-x)
   \leq \max \left( \left( \frac{y}{x} - 1  \right)f(x), \left( 1-\frac{x}{y} \right) f(y) \right) &
  \end{align*}
  which directly implies $\frac{f(y)}{y}\leq \frac{f(x)}{x}$.
  Second, if $f(x) \geq f(y)$, $\frac{f(x)}{x} \geq \frac{f(y)}y$ and we can then bound in the same way:
  \begin{align*}
    f(x)xy- f(y)xy\leq \max \left( xf(x)(y-x), \left( y-x \right) yf(y) \right)
  \end{align*}
  which implies $xf(x) \leq yf(y)$.
  In both cases ($f(x) \leq f(y)$ and $f(y) \leq f(x)$), and we see that $f_/(x) \geq f_/(y)$ and $f_\times(x) \leq f_\times(y)$, proving the result.
  
\end{proof}

This property allows us to understand directly that the stability of a function is a local behavior. We then conclude staightforwardly that the supremum or the infimum of stable mappings is also stable.
\begin{corollary}\label{cor:inf_sup_stable}
  Given a family of stable mappings $(f_\theta)_{\theta \in \Theta} \in \mathcal S(\mathbb R^+)^\Theta$, for a given set $\Theta$, the mappings $\sup_{\theta \in \Theta} f_\theta$ and $\inf_{\theta \in \Theta} f_\theta$ are both stable.
\end{corollary}

Given $f: \mathcal D^+_n \rightarrow \mathcal D^+_n$, we can introduce by analogy to the case of mappings on $\mathbb R^+$, the mappings $f_/, f_\times: \mathcal D^+_n \rightarrow \mathcal D^+_n$ defined with:
\begin{align*}
    f_{/} \ : \ \Delta \mapsto \tr  \left(\frac{f(\Delta)}{\Delta}\right) &
    &\text{and}&
    &f_{\times} \ : \ \Delta \mapsto \tr  \left(\Delta f(\Delta)\right)
\end{align*}
Inspiring from Property~\ref{prot:Caracterisation_stabilite_monotonie}, one can then define:
\begin{definition}[Sub-monotonuous class]\label{def:sub_monotonuous_class}
   A mapping $f: \mathcal D_n^+ \to \mathcal D_n^+$ is said to be sub-monotonuous if and only if $f_\times$ is non decreasing and $f_/$ is non-increasing, we note this class of mappings $ \mathcal S_m(\mathcal D_n^+)$.
 \end{definition} 
 \begin{remark}\label{rem:sub_monotonuous_and_stable_class}
   We know from Property~\ref{prot:Caracterisation_stabilite_monotonie} that $\mathcal S(\mathbb R_+)= \mathcal S_m(\mathbb R_+)$ but for $n>1$, none of the classes $\mathcal S_m(\mathcal D_n^+)$ and $\mathcal S(\mathcal D_n^+)$ contains strictly the other one. On the first hand, introducing:
   \begin{align*}
     f: \begin{aligned}[t]
       \mathcal D_2^+ & \longrightarrow& \mathcal D_2^+ \hspace{1.5cm}\\
       \Delta \ & \longmapsto& \diag \left(\frac{1}{\Delta_2}, \frac{1}{\Delta_1}\right),
     \end{aligned}
   \end{align*}
   we see that $f \in \mathcal S(\mathcal D_n^+)$ but $f \notin \mathcal S_m(\mathcal D_n^+)$ (for $\Delta = \diag(1,2)$ and $\Delta' = \diag(2, 2)$, $\Delta \leq \Delta'$ but $\tr(f(\Delta)\Delta) = \frac{5}{2} > 2 = \tr(f(\Delta')\Delta')$). On the other hand, the mapping:
   \begin{align*}
     g: \begin{aligned}[t]
       \mathcal D_2^+ & \longrightarrow& \mathcal D_2^+ \hspace{1.5cm}\\
       \Delta \ & \longmapsto& \diag \left(\frac{\Delta_1\Delta_2}{1+\Delta_2}, 1\right)
     \end{aligned}
   \end{align*}
   is in $\mathcal S_m(\mathcal D_n^+)$ because:
   \begin{align*}
     \left\{\begin{aligned}
       \frac{\partial g_.}{\partial \Delta_1} &= \frac{2\Delta_1\Delta_2}{1+\Delta_2} \geq 0\\
       \frac{\partial g_.}{\partial \Delta_2} &= \frac{\Delta_1^2}{(1+\Delta_2)^2} + 1 \geq 0
     \end{aligned}\right.&
     &\text{and}&
     &\left\{\begin{aligned}
       \frac{\partial g_/}{\partial \Delta_1} &= 0\leq 0\\
       \frac{\partial g_/}{\partial \Delta_2} &= \frac{1}{(1+\Delta_2)^2} - \frac{1}{\Delta_2^2} \leq 0.
     \end{aligned}\right.
   \end{align*}
   However, we can see that $g$ is not stable if we introduce the diagonal matrices $\Delta = \diag(1,2)$ and $\Delta' = \diag(2, 3)$ since we have then:
   \begin{align*}
     d_s(g(\Delta), g(\Delta')) = d_s \left(\frac{2}{3},\frac{3}{2}\right)  = \frac{5}{6} > \frac{1}{\sqrt 2} = \max \left(\frac{|3-2|}{\sqrt {6}}, \frac{|2-1|}{\sqrt 2}\right) = d_s(\Delta, \Delta')
   \end{align*}
 \end{remark}

\section{Fixed Point theorem for stable and sub-monotonic mappings}

The Banach fixed point theorem states that a contracting function on a complete space admits a unique fixed point. The extension of this result to contracting mappings on $\mathcal D_n^+$, for the semi-metric $d_s$, is not obvious: first because $d_s$ does not verify the triangular inequality and second because the completeness needs to be proven. The completeness of the semi-metric space $(\mathcal D_n^+,d_s)$ is left in Section~\ref{sub:stable_metic} since we will not need it.
Let us start with a first bound.
\begin{lemma}\label{lem:suite_iterative_application_contractante_borne}
  Given a mapping $f : \mathcal D_n^+ \to \mathcal D_n^+$, contracting for the semi metric $d_s$, any sequence of diagonal matrices $(\Delta_n)_{n \in \mathbb N}$ satisfying $\Delta^{(p+1)} = f(\Delta^{(p)})$ is bounded from below and above and satisfies for all $p\in \mathbb N$ and $i \in [n]$:
  \begin{align*}%\label{eq:borne_Delta_exponentielle}
     \exp \left(- \frac{\lambda d_s \left( \Delta^{(1)}, \Delta^{(0)} \right)}{2(1- \lambda)} \right) \Delta^{(1)}_i
     \leq \Delta^{(p)}_i 
     \leq  \exp \left( \frac{\lambda d_s \left( \Delta^{(1)}, \Delta^{(0)} \right)}{2(1- \lambda)} \right) \Delta^{(1)}_i
  \end{align*}
\end{lemma}
\begin{proof}
  Noting $\lambda >0$, the Lipschitz parameter of $f$ for the semi-metric $d_s$, let us first show that, for all $i\in [n]$:
  \begin{align}\label{eq:borne_Delta_np1_s_Delta_n}
     \forall p\in \mathbb N, \sqrt{\frac{\Delta^{(p+1)_i}}{\Delta^{(p)}_i}} \leq  1 + \lambda^p d_s \left( \Delta^{(1)}, \Delta^{(0)} \right).
  \end{align} 
  When $\Delta^{(p+1)}_i \leq \Delta^{(p)}_i$, it is obvious and when $\Delta^{(p+1)} \geq \Delta^{(p)}$ the contractivity of $f$ allows us to set $d_s(\Delta^{(p+1)}, \Delta^{(p)}) \leq \lambda^p d_s \left( \Delta^{(1)}, \Delta^{(0)} \right)$, which implies:
  \begin{align*}
    \sqrt{\frac{\Delta^{(p+1)}_i}{\Delta^{(p)}_i}} \leq \sqrt{\frac{\Delta^{(p)}_i}{\Delta^{(p+1)}_i}} + \lambda^p d_s \left( \Delta^{(1)}, \Delta^{(0)} \right) \leq 1 + \lambda^p d_s \left( \Delta^{(1)}, \Delta^{(0)} \right).
  \end{align*}
  Multiplying \eqref{eq:borne_Delta_np1_s_Delta_n} for all $p \in \{1,\ldots, P\}$, we obtain:
  \begin{align*}
    \sqrt{\frac{\Delta^{(P)}_i}{\Delta_i^{(1)}}} 
    &\leq 1 \leq \prod_{p=1}^P \left( 1 + \lambda^p d_s \left( \Delta^{(1)}, \Delta^{(0)} \right) \right) 
    = \exp \left( \sum_{p=1}^P \log \left( 1+ \lambda^p d_s \left( \Delta^{(1)}, \Delta^{(0)} \right) \right)\right)\\
    &\leq \exp \left( \sum_{p=1}^P  \lambda^p d_s \left( \Delta^{(1)}, \Delta^{(0)} \right)\right) \leq \exp \left( \frac{\lambda d_s \left( \Delta^{(1)}, \Delta^{(0)} \right)}{1- \lambda} \right).
  \end{align*}
  With a similar approach, we can eventually show the result of the lemma.  
\end{proof}


Let us now present two fixed point results that will justify the definition of the robust scatter matrix $C$ but also of the deterministic diagonal matrix $U$ introduced in Section~\ref{sec:main_result}. 

\begin{theorem}\label{the:point_fixe_fonction_contractante_de_D_n_borne_superieurement}
  Any mapping $f: \mathcal D_n^+\to \mathcal D_n^+$, contracting for the stable semi-metric $d_s$, admits a unique fixed point $\Delta^*\in\mathcal D_n(\mathbb R^+ \cup \{0\})$ satisfying $\Delta^* =  f(\Delta^*)$.
\end{theorem}
\begin{proof}%[Proof of Theorem~\ref{the:point_fixe_fonction_contractante_de_D_n_borne_superieurement}]
  We cannot repeat exactly the proof of the Banach fixed point theorem since $d_s$ does not satisfy the triangular inequality. 
  Noting $\lambda \in (0,1)$ the parameter such that $\forall \Delta,\Delta' \in \mathcal D_n^+$, $d_s(f(\Delta) , f(\Delta')) \leq \lambda d_s(\Delta,\Delta')$, we show that the sequence $(\Delta^{(k)})_{k\geq 0}$ satisfying: 
  \begin{align*}
    \Delta^{(0)} = I_n&
    &\text{and}&
    &\forall k\geq 1: \ \Delta^{(k)} = f(\Delta^{(k-1)})
   \end{align*}
   is a Cauchy sequence in $(\overline{\mathcal D}_n^+ ,\|\cdot \|)$, where $\overline{\mathcal D}_n^+ \equiv \mathcal D_n(\mathbb R^+ \cup \{0\})$. 


 We know from Lemma~\ref{lem:suite_iterative_application_contractante_borne} that there exists $\delta>0$ such that $\forall p \in \mathbb N$, $\Vert \Delta^{(p)} \Vert \leq \delta$. One can then bound for any $p \in \mathbb N$:
  \begin{align*}
      \left\Vert \Delta^{(p+1)}-\Delta^{(p)}\right\Vert\leq \delta
      d_s(\Delta^{(p+1)},\Delta^{(p)})
      \leq \lambda^p \delta d_s(\Delta^{(1)},\Delta^{(0)}).
  \end{align*}
  Therefore, thanks to the triangular inequality (in $(\mathcal D_n^+ ,\|\cdot \|)$), for any $n \in \mathbb N$:
  \begin{align*}
    \left\Vert\Delta^{(p+n)} - \Delta^{(p)}\right\Vert
    &\leq \left\Vert\Delta^{(p+n)} - \Delta^{(p+n-1)}\right\Vert+\cdots + \left\Vert\Delta^{(p+1)} - \Delta^{(p)}\right\Vert \\
    &\leq \  \frac{\delta d_s(\Delta^{(1)},\Delta^{(0)})}{1-\lambda} \lambda^p \ \ \ \underset{p \to \infty}{\longrightarrow} \ 0.
  \end{align*}
  That allows us to conclude that $(\Delta^{(p)})_{p\in \mathbb N}$ is a Cauchy sequence, and therefore that it converges to a diagonal matrix $\Delta^* \equiv \lim_{p \to \infty} \Delta^{(p)} \in \overline{\mathcal D}_n^+$ which is complete (closed in a complete set). But since $\Delta^{(p)}$ is bounded from below and above thanks to Lemma~\ref{lem:suite_iterative_application_contractante_borne}, we know that $\Delta^* \in \mathcal D_n^+$. By contractivity of $f$, it is clearly unique.
\end{proof}
It is possible to relax a bit the contracting hypotheses on $f$ if one supposes that $f$ is monotonic. We express rigorously this result in next theorem, but it will not be employed in our applications in Chapter~\ref{cha:robust_estimation} about the robust estimation of scatter matrix since we preferred to assume $u$ bounded to obtain the contracting properties of the fixed point satisfied by $\hat \Delta$.
\begin{theorem}\label{the:point_fixe_fonction_stable_monotone_de_D_n}
   Let us consider a weakly monotonic mapping $f: \mathcal D_n^+\to \mathcal D_n^+$ bounded from below and above. If we suppose that $f$ is stable and verifies:
  \begin{align}\label{eq:faiblement_contractant}
    \forall \Delta,\Delta' \in\mathcal D_n^+: \ d_s(f(\Delta),f(\Delta') )<d_s(\Delta,\Delta')
   \end{align} then there exists a unique fixed point $D\in\mathcal D_n^+$ satisfying $\Delta^* = f(\Delta^*)$.
\end{theorem}


\section{Supplementary inferences on the stable semi-metric and topological properties}\label{sub:stable_metic}
\begin{remark}\label{rem:stable_non_continu_en_zero}
  Not all the stable mappings admit a continuous continuation on $\overline{\mathcal D}_n^+$. To construct a counter example, for any $n \in \mathbb N$, let us note 
  \begin{itemize}
    \item $e_n: x \mapsto \frac{3}{2} - 2^{n-1}x$ (it satisfies $e_n(1/2^n) = 1$ and $e_n(3/2^{n+1}) = \frac{3}{4}$),
    \item $d_n: x \mapsto 2^{n-1}x$ (it satisfies $d_n(1/2^{n-1}) = 1$ and $e_n(3/2^{n+1}) = \frac{3}{4}$),
    \item $v_n : \mathbb R^+ \to \mathbb R^+$ satisfying for all $x \in \mathbb R^+$, $v_n(x) = \max(e_n,d_n)$ (in particular, $v_n(2^n) = v_n(2^{n-1}) = 1$),
    \item $f : \mathbb R^+ \to \mathbb R^+$ satisfying for all $x \in \mathbb R^+$, $f(x) = \inf_{n\in \mathbb N} v_n(x)$.
  \end{itemize} 
  We know from Property~\ref{prot:Caracterisation_stabilite_monotonie} that for all $n \in \mathbb N$, $d_n$ is stable and that $e_n$ is stable on $[0,3/2^{n+1}]$ (where $x \mapsto xe_n(x)$ is non decreasing) which eventually allows us to set that $f$ is stable, thanks to Corollary~\ref{cor:inf_sup_stable}.

  However $f$ does not admit continuous continuation on $0$ since:
  \begin{align*}
    \underset{n \to \infty} \lim f \left( \frac{1}{2^n} \right) = 1 \neq \frac{3}{4}= \underset{n \to \infty} \lim f \left( \frac{3}{2^n}\right).
  \end{align*}
\end{remark}


\begin{lemma}\label{lem:borne_suite_de_cauchy_D_n}
  Any Cauchy sequence of $(\mathcal D_n^+,d_s)$ is bounded from below and above (in $\mathcal D_n^+$).
\end{lemma}
\begin{proof}%[Proof of Lemma~\ref{lem:borne_suite_de_cauchy_D_n}]
  Considering a Cauchy sequence of diagonal matrices $\Delta^{(k)} \in \mathcal D_n^+$, we know that there exists $K\in \mathbb N$ such that:
  \begin{align*}
    \forall p,q\geq K, \ \forall i\in\{1,\ldots,n\}: \ \ \vert \Delta^{(p)}_i-\Delta^{(q)}_i\vert \leq \sqrt {\Delta^{(p)}_i\Delta^{(q)}_i}.
  \end{align*} 
  For $k\in \mathbb N$, let us introduce the indexes $i^k_M, i^k_m \in \mathbb N$, satisfying:
  \begin{align*}
    \Delta^{(k)}_{i^k_M} = \max \left(\Delta^{(k)}_{i}, 1\leq i \leq n\right)&
    &\text{and}&
    &\Delta^{(k)}_{i^k_M} = \min \left(\Delta^{(k)}_{i}, 1\leq i \leq n\right).
  \end{align*}
  If we suppose that there exists a subsequence $(\Delta_{i_M^k}^{(\phi(k))})_{k\geq 0}$ such that $\Delta_{i_M^k}^{(\phi(k))} \underset{k \to\infty}{\longrightarrow}  \infty$, then
  \begin{align*}
    \sqrt{\Delta^{(\phi(k))}_{i^{\phi(k)}_M}} \leq \sqrt{\Delta^{(N)}_{i^{\phi(k)}_M} } + \frac{\Delta^{(N)}_{i^{\phi(k)}_M}}{\sqrt{\Delta^{(\phi(k))}_{i^{\phi(k)}_M}}}\underset{k \to\infty}{\longrightarrow} \sqrt{\Delta^{(N)}_{i^{\phi(k)}_M} } < \infty
  \end{align*}
  which is absurd. Therefore $(\Delta_{i^{k}_M}^{(k)})_{k\geq 0}$ and thus also $(\Delta^{(k)})_{k\geq 0}$ are bounded from above. For the lower bound, we consider the same way a subsequence $(\Delta_{i_m^k}^{(\psi(k))})_{k\geq 0}$ such that $\Delta_{i_m^k}^{(\psi(k))} \underset{k \to\infty}{\longrightarrow}  0$. We have:
  \begin{align*}
    \Delta^{(\phi(k))}_{i^{\phi(k)}_M} \geq \Delta^{(N)}_{i^{\phi(k)}_M}  - \sqrt{\Delta^{(N)}_{i^{\phi(k)}_M}\Delta^{(\phi(k))}_{i^{\phi(k)}_M}}\underset{k \to\infty}{\longrightarrow} \sqrt{\Delta^{(N)}_{i^{\phi(k)}_M} } >0
  \end{align*}
  which is once again absurd.
\end{proof}
\begin{property}\label{prot:D_n_complet}
  The semi-metric space $(\mathcal D_n^+,d_s)$ is complete.
\end{property}
\begin{proof}%[Proof of Property~\ref{prot:D_n_complet}]
  Given a Cauchy sequence of diagonal matrices $\Delta^{(k)} \in \mathcal D_n^+$, we know from the preceding lemma that there exists $\delta_M,\delta_m\in \mathbb R^+ $ such that $\forall k\geq 0:\delta_m I_n \leq \Delta^{(k)} \leq \delta_M I_n$.
  Thanks to the Cauchy hypothesis:
  \begin{align*}
    \forall \varepsilon >0, \exists K \geq 0 \ | \ \forall p,q \geq K: \ \forall i \in \{1,\ldots,n\}: \left\vert \Delta_i^{(p)} - \Delta_i^{(q)}\right\vert \leq \varepsilon \delta_M
  \end{align*}
  and, as a consequence, $(\Delta^{(k)})_{k\geq 0}$ is a Cauchy sequence in the complete space $(\mathcal D_n^{0,+}, \Vert \cdot \Vert)$: it converges to a matrix $\Delta^{(\infty)} \in \mathcal D_n^{0,+}$. Moreover, $\Delta^{(\infty)}\geq \delta_k I_n$ (as any $\Delta^{(k)}$) for all $k\in \mathbb N$, so that $\Delta^{(\infty)} \in \mathcal D_n^+$ and we are left to showing that $\Delta^{(k)}\underset{k \to\infty}{\longrightarrow}\Delta^{(\infty)}$ for the semi-metric $d_s$. It suffices to write:
  \begin{align*}
    d_s(D^{(k)},D^{(\infty)}) = \left\Vert \frac{D^{(k)}-D^{(\infty)}}{\sqrt {D^{(k)}D^{(\infty)}}}\right\Vert \leq \delta_m\left\Vert D^{(k)}-D^{(\infty)}\right\Vert \underset{k \to\infty}{\longrightarrow} 0.
  \end{align*}
\end{proof}
\begin{proof}[Proof of Theorem~\ref{the:point_fixe_fonction_stable_monotone_de_D_n}]
  We first suppose that $f$ is non-decreasing. As before, let us consider $\delta_M,\delta_m \in \mathbb R^+$ such that $\forall \Delta \in \mathcal D_n^+$ $\delta_m I_n \leq f(\Delta) \leq \delta_M I_n$. The sequence $(\Delta^{(k)})_{k\geq 0}$ satisfying $\Delta^{(0)} = \Delta_m I_n$, and for all $k\geq 1$, $\Delta^{(k)} = f(\Delta^{(k-1)})$ is a non-decreasing sequence bounded superiorly with $\delta_M$, thus it converges to $\Delta^* \in \mathcal D_n^+$ and $\Delta^* = f(\Delta^*)$. This fixed point is clearly unique thanks to \eqref{eq:faiblement_contractant}. 

  Now if $f$ is non-increasing then $\Delta \mapsto f^2(\Delta)$ is non-decreasing and bounded inferiorly and superiorly thus it admits a unique fixed point $\Delta^* \in \mathcal D_n^+$ satisfying $\Delta^* = f^2(\Delta^*)$. We can deduce that $f(\Delta^*) = f^2(f(\Delta^*))$ which implies by uniqueness of the fixed point that $f(\Delta^*) = \Delta^*$ and the uniqueness of such a $\Delta^*$ is again a consequence of \eqref{eq:faiblement_contractant}.
\end{proof}


\section{Complex stable semi-metric and some consequences in random matrix theory}\label{sec:stable_metric_complex}
Let us for any $D, D' \in \mathcal D_n(\mathbb H)$ as:
\begin{align*}
  d_s(D,D') = \sup_{1\leq i \leq n} \frac{|D_i- D_i'|}{\sqrt{\Im(D_i) \Im(D_i')}}
\end{align*}
(it lacks the triangular inequality to be a true metric). This semi-metric is introduced to set Banach-like fixed point theorems.% For that purpose, we introduce:
\begin{definition}\label{def:stable_class}
  Given $\lambda>0$, we denote $\mathcal C_s^\lambda(\mathcal D_n(\mathbb H))$ (or more simply $\mathcal C_s^\lambda$ when there is no ambiguity), the class of functions $f: \mathcal D_n(\mathbb H) \to \mathcal D_n(\mathbb H)$, $\lambda$-Lipschitz for the semi-metric $d_s$; i.e. satisfying for all $D, D' \in \mathcal D_n(\mathbb H)$:
\begin{align*}
  d_s(f(D),f(D')) \leq \lambda d_s(D,D').
\end{align*}
% Given $f \in \mathcal C_s(\mathcal D_n(\mathbb H))$, if there exists a constant $\epsilon>0$ such that:
% \begin{align*}
%   \forall D,D' \in \mathcal D_n(\mathbb H), \ d_s(f(D),f(D')) \leq (1- \epsilon)d_s(D,D'),
% \end{align*}
when $\lambda <1$, we say that $f$ is contracting for the semi-metric $d_s$.
\end{definition}
\begin{proposition}\label{pro:stability_propertis}
  Given three parameters $\alpha,\lambda, \theta>0$ and two mappings $f \in \mathcal C_s^\lambda$ and $g \in \mathcal C_s^\theta$,% and $h: D_n(\mathbb H\cup \mathbb R) \to D_n(\mathbb H\cup \mathbb R)$ $\theta$-Lipschitz for the spectral norm:
  \begin{align*}
    \frac{-1}{f} \in \mathcal C_s^\lambda ,&% \in \mathcal C_s&
    &\alpha f\in \mathcal C_s^\lambda,&% \in \mathcal C_s(\mathcal D_n(\mathbb H))&
    &f\circ g\in \mathcal C_s^{\lambda \theta},&
    &\text{and}&
    &f + g \in \mathcal C_s^{\max(\lambda,\theta)}.% \in \mathcal C_s(\mathcal D_n(\mathbb H))&
  \end{align*}
  % are all in the stable class.
\end{proposition}
% We then deduce easily from these properties that:
% \begin{corollary}\label{cor:phi_stable}
%   $\chi(\mathbb H) \subset \mathbb H$ and $\chi \in \mathcal C_s(\mathbb H)$.
% \end{corollary}
The stability towards the sum is a mere adaptation of Property~\ref{prot:pseudo_tringular_inequality}
\begin{lemma}\label{lem:pseudo_tringular_inequality}
  Given four diagonal matrices $\Delta,\Delta',D,D' \in \mathcal D_n(\mathbb H)$:
  \begin{align*}
     d_s(\Delta +D,  \Delta'+D') \leq \max(d_s(\Delta,  \Delta'), d_s(D, D')).
   \end{align*} 
\end{lemma}
\begin{proof}[Proof of Lemma~\ref{lem:pseudo_tringular_inequality}]
  For any $\Delta,\Delta',D,D' \in \mathcal D_n(\mathbb H)$, there exists $i_0 \in [n]$ such that:
  \begin{align*}
  d_s(\Delta+D, \Delta'+D')
    &= \frac{\left\vert \Delta_{i_0}- \Delta_{i_0}'+ D_{i_0}-D_{i_0}' \right\vert}{\sqrt{\Im(\Delta_{i_0}+D_{i_0})\Im(\Delta'_{i_0}+D_{i_0}')}}\\
    &\leq \frac{\left\vert \Delta_{i_0}-\Delta_{i_0}'\right\vert +\left\vert D_{i_0}-D_{i_0}' \right\vert}{\sqrt{\Im(\Delta_{i_0}) \Im(\Delta'_{i_0})} +\sqrt{\Im(D_{i_0})\Im(D_{i_0}' )})}\\
    &\leq \max \left(\frac{\left\vert \Delta_{i_0}-\Delta_{i_0}'\right\vert}{\sqrt{\Im(\Delta_{i_0}) \Im(\Delta'_{i_0})}}, \frac{\left\vert D_{i_0}-D_{i_0}' \right\vert}{\sqrt{\Im(D_{i_0})\Im(D_{i_0}' )}}\right)
    % \\ &\leq \max(d_s(\Delta, \Delta'),d_s(D, D'))
    % &\leq \frac{\mathcal N }{\mathcal D} \frac{\left\vert \Delta- \Delta'\right\vert}{\sqrt{\Delta \Delta'}}
  \end{align*}
  thanks to Lemma~\ref{lem:stability_preliminary_lemma}.
\end{proof}


We can now present our fixed point theorem that has been demonstrated once again in \cite{louart2022concentration}:
\begin{theorem}[\cite{louart2022concentration} Theorem 3.13]\label{the:fixed_point_theorem}
  Given a subset $\mathcal D_f$ of $\mathcal D_n(\mathbb H)$ and a mapping $f: \mathcal D_f\to \mathcal D_f$ with an imaginary part bounded from above and below (in $\mathcal D_f$), if it is furthermore contracting for the stable semi-metric $d_s$ on $D_f$, then there exists a unique fixed point $\Delta^*\in\mathcal D_f$ satisfying $\Delta^* = f(\Delta^*)$.
\end{theorem}
We will now employ the semi-metric $d_s$ indifferently on diagonal matrices $\mathcal D_n(\mathbb H)$ or vectors of $\mathbb H^n$ or more simply with variables of $\mathbb H$ as in next proposition.
% In this appendix, we will employ the semi-metric $d_s$ indifferently on diagonal matrices $\mathcal D_n(\mathbb H)$ or vectors of $\mathbb H^n$ or more simply with variables of $\mathbb H$ as in next proposition.
\begin{proposition}\label{pro:Stieltjes_transforms_are_1_Lipschitz}
  All the Stieltjes transforms are $1$-Lipschitz for the semi-metric $d_s$ on $\mathbb H$.
\end{proposition}
\begin{proof}
  We consider a Stieltjes transform $g : z \to \int \frac{d\mu(t)}{t-z}$ for a given measure $\mu$ on $\mathbb R$. Given $z,z' \in \mathbb H$, we can bound thanks to Cauchy-Schwarz inequality:
  \begin{align*}
    |g(z) - g(z') |
    &\leq \left\vert \int \frac{z' -z }{(t-z)(t-z')} d\mu(t)\right\vert
    \leq \left\vert \frac{z' -z }{\sqrt{\Im(z)\Im(z')}}\right\vert\left\vert \int \frac{\sqrt{\Im(z)\Im(z')} }{(t-z)(t-z')} d\mu(t)\right\vert\\
    &\leq \left\vert \frac{z' -z }{\sqrt{\Im(z)\Im(z')}}\right\vert \sqrt{\int \frac{\Im(z) }{|t-z|^2} d\mu(t)\int \frac{\Im(z') }{|t-z'|^2} d\mu(t)}\\
    & = \sqrt{\Im(g(z))\Im(g(z'))} d_s(z,z')
  \end{align*}
\end{proof}
We did not find any particular use of this proposition (the idea could be to solve $g(z) = z$) but the stability it introduces looks interesting. 

% Let us start with some preliminary lemmas before proving the fourth point of Proposition~\ref{pro:stability_propertis}, i.e. the stability towards the sum of the class of mappings, $1$-Lipschitz for the semi-metric $d_s$. 
% They are mere adaptation of results of \cite{louart2022concentration}.

% To treat the sum of $1$-Lipschitz mappings, we need 

We deduce directly from Lemma~\ref{lem:pseudo_tringular_inequality} that if $f,g : \mathcal D_n(\mathbb H) \to \mathcal D_n(\mathbb H)$ are $\lambda$-Lipschitz for $d_s$ then $f+g$ is also $\lambda$-Lipschitz.
This property gives a very fast proof to show the existence and uniqueness of solutions to the equations studied in \cite{AJA16} (however their proof is not much longer).  We start with a preliminary proposition:
% We will consider in particular a class of operators on $\mathbb C^n$ defined as:
% \begin{align*}
% \end{align*}
\begin{proposition}\label{pro:produit_avec_S_1_lipschitz_pour_d_s}
  Given a matrix $S \in \mathcal M_{n,p}(\mathbb R_+)$ , $z \mapsto Sz$ goes from $\mathbb H^p$ to $\mathbb H^n$ and it is $1$-Lipschitz for the semi-metric $d_s$.
\end{proposition}
\begin{proof}
  For any $z \in \mathbb H^p$, $\Im(Sz) = S \Im(z) \in \mathbb R^p_+$ since all the entries of $S$ are positive. If we denote $s_1,\ldots, s_n$, the columns of $S$, we can decompose $Sz = \sum_{i=1}^n s_i \pi_i(z)$, where $\pi_i(z) = z_i$.
  Each mapping $s_i \pi_i$ is $1$-Lipschitz for $d_s$, since we have for any $z,z' \in \mathbb H^p$:
  % The spectral decomposition of $S$ writes $S = \sum_{i=1}^n \lambda_ix_ix_i^T$ with $x_1,\ldots, x_n$ orthonormal. Then we can write:
  \begin{align*}
    d_s(s_i\pi_i(z), s_i \pi_i(z')) = \sup_{j\in[p]} \left\vert \frac{[s_i]_j z_i - [s_i]_j z'_i}{\sqrt{\Im([s_i]_j z_i)\Im([s_i]_j z'_i)}}\right\vert =  \frac{ z_i -  z_i'}{\sqrt{\Im( z_i)\Im( z_i')}},
  \end{align*}
  therefore, as a sum of $1$-Lipschitz operators, we know that $z \to Sz$ is also $1$-Lipschitz for $d_s$.
\end{proof}
% We can then deduce easily

% Let us start by showing that the St

% More interestingly is the simplifications it brings to the equations studied in \cite{}.
\begin{proposition}\label{pro:resolution_equation_erdos}
  Given any $a \in \mathbb R^n$ and any matrix\footnote{Note that unlike in \cite{AJA16}, we do not suppose that $S$ is symmetric.} $S \in \mathcal M_{n}(\mathbb R_+)$, and $z \in \mathbb H$, the equation:
  \begin{align*}
    -\frac{1}{m} = z\un + a + Sm
  \end{align*}
  admits a unique solution $m \in \mathbb C_ +^n$.
\end{proposition}
\begin{proof}
  Let us introduce $I : x \to z\un + a - S \frac{\un}{x}$. To employ Theorem~\ref{the:fixed_point_theorem}, let us first show that the imaginary part of $I(x)$ is bounded from below and above for all $x \in \mathbb H^n$. Given $x \in \mathbb H^n$ we see straightforwardly that $\Im(I(x)) \geq \Im(z)$, we can furthermore bound:
  \begin{align*}
    \Im(I(x)) \leq \Im(z) \un + S \frac{\Im(x)}{|x|^2} \leq \Im(z) \un + S \frac{\un}{\Im(x)}  \leq \left(\Im(z)I_p + \frac{1}{\Im(z)}S\right)\un\equiv \kappa_I \un.
  \end{align*}
  Besides, we already know from Proposition~\ref{pro:stability_propertis} that $I$ is $1$-Lipschitz for $d_s$ but we need a Lipschitz parameter lower than $1$.
  Given $x,y \in \mathbb H^n$ we can bound thanks to Proposition~\ref{pro:stability_propertis} and~\ref{pro:produit_avec_S_1_lipschitz_pour_d_s}:
  \begin{align*}
     \left\vert I(x) - I(y)\right\vert
     \leq \left\vert S \left(\frac{1}{x}- \frac{1}{y}\right)\right\vert
     \leq  \sqrt{\Im \left( S \left(\frac{1}{x}\right)\right)\Im \left(S \left(\frac{1}{y}\right)\right)} d_s(x,y) 
     % = \sqrt{\Im \left(\frac{1}{x}\right)\Im \left(\frac{1}{y}\right)}  d_s(S(x),S(y)),%\left\vert \frac{S(m-q)}{\sqrt{\Im(Sm)\Im(Sq)}}\right\vert
   \end{align*} 
   that implies that the Lipschitz parameter of $I$ is lower than:
   \begin{align*}
     % \sqrt{\frac{\Im(S(x))\Im(S(y))}{\Im(I(x))\Im(I(y))}} \leq 
     \sqrt{\left(1- \frac{\Im(z)}{\Im(I(x))}\right)\left(1- \frac{\Im(z)}{\Im(I(y))}\right)}\leq 1 - \frac{\Im(z)}{\kappa_I} <1
   \end{align*}
   We conclude then with Theorem~\ref{the:fixed_point_theorem} that there exists a unique $x\in \mathbb H^n$ such that $x = I(x)$, from which we deduce the existence and uniqueness of $m = \frac{1}{x}$.
   % To bound this term, let us show that $I$ is stable on:
   % \begin{align*}
   %   \mathcal A_I \equiv
   % \end{align*}
   % But for any 
\end{proof}



\section{Stability of the stable semi-metric towards perturbations}

A classical problem is to be able to bound the difference between two solution of two contractive equations for the stable semi-metric. This is possible when one of the equation is a small perturbation of the other one. For the absolute value on $\mathbb R$ for instance, if one is given two $1-\varepsilon$ Lipschitz mapping $f,g: \mathbb R \to \mathbb R$, and two fixed point $x,y \in \mathbb R$ satisfying:
\begin{align*}
  x = f(x)&
  &\text{and}&
  &y = g(y),
\end{align*}
then one can bound thanks to the triangular inequality:
\begin{align}%\label{eq:perturbation_managment_triangular_inequality}
  |x - y| \leq |f(x) - f(y) |  + | f(y) - g(y)|\leq (1- \varepsilon) |x - y| + |f(y) - g(y)|,
\end{align}
which implies $|x - y | \leq \frac{ | f(y) - g(y)|}{\varepsilon}$. When working with the semi-metric $d_s$, the triangular inequality is not valid (see \eqref{eq:triangular_inequality_not_valid}), one therefore needs more elaborated inferences displayed below. Note than the contractiveness of $g$ is actually completely useless.
 % we naturally employ Proposition~\ref{pro:equation_proche_implique_solution_proche_version2} on the matrices $\tilde \Gamma^n = \tilde \Lambda^z$ and $\Gamma^n = \hat \Lambda^z$ and on the mapping $f^n = I^z$. We first need to set:

  \begin{proposition}\label{pro:equation_proche_implique_solution_proche_version_statique}
  Given a diagonal matrices $\Gamma \in \mathcal D_n(\mathbb H)$, a mapping $f: \to \mathcal D_{n} (\mathbb H)$ $\lambda$-Lipschitz\footnote{Actually, $f$ does not need to be $\lambda$-Lipschitz on the whole set $\mathcal D_{n}(\mathbb H)$, but we need to be able to bound:
  \begin{align*}
    d(f(\tilde \Gamma), f(\Gamma)) \leq \lambda d(\tilde \Gamma, \Gamma)
  \end{align*}} for the semi-metric $d_s$ with $\lambda < 1$ and admitting the fixed point $\tilde \Gamma = f(\tilde \Gamma)$, we have the bound: 
  \begin{align*}
    % \left\Vert \frac{\tilde \Gamma - \Gamma}{\sqrt{\Im(\tilde \Gamma) \Im(f(\Gamma))}}\right\Vert\leq O \left(\left\Vert \frac{f( \Gamma) - \Gamma}{\sqrt{\Im(\tilde \Gamma) \Im(f(\Gamma))}}\right\Vert\right).
    d( \Gamma , \tilde \Gamma)
    &\leq \left\Vert \frac{f(\Gamma) - \Gamma}{\sqrt{\Im(\tilde \Gamma) \Im(\Gamma)}}\right\Vert\  / \ \left( 1 - \lambda- \lambda d(\Im(\Gamma), \Im(f(\Gamma)) \right) 
    % \leq O_{s \to \infty} 
    % \left( d_s( \Gamma , f(\Gamma))\right)
    % \left(\left\Vert \frac{f(\Gamma) - \Gamma}{\sqrt{\Im(\tilde \Gamma) \Im(\Gamma)}}\right\Vert\right)
  \end{align*}
  The same result is valid replacing $\mathbb H$ with $\mathbb R_+$ and removing the symbols $\Im$.
  \end{proposition}
  This proposition is a consequence of the following elementary result that we set for  the semi-metric defined on $\mathcal D_n(\mathbb H)$ since it needs more justification than to set the result on $\mathcal D_n(\mathbb R_+)$ (which merely expresses removing the symbols $\Im$ in the inequality).
  \begin{lemma}\label{lem:tool_matrices_diag_d_s}
    Given three diagonal matrices $\Gamma^1, \Gamma^2, \Gamma^3 \in \mathcal D_n(\mathbb H)$:
    \begin{align*}
      \left\Vert \frac{\Gamma^3}{\sqrt{\Im(\Gamma^1) }}\right\Vert \leq \left\Vert \frac{\Gamma^3}{\sqrt{\Im(\Gamma^2) }}\right\Vert \left(1 + d_s(\Im(\Gamma^1), \Im(\Gamma^2)) \right).
      % \left\Vert \frac{\Gamma^1 - \Gamma^2}{\sqrt{\Im(\Gamma^1) \Im(\Gamma^3)}}\right\Vert \leq d_s(\Gamma^1, \Gamma^2)(1 + d_s(\Im(\Gamma^3), \Im(\Gamma^2))).
    \end{align*}
  % The same result is valid replacing $\mathbb H$ with $\mathbb R_+$ and removing the symbols $\Im$.
  \end{lemma}
  \begin{proof}
    Let us simply bound:
    \begin{align*}
      \left\Vert \frac{\Gamma^3}{\sqrt{\Im(\Gamma^1) }}\right\Vert  
      % \left\Vert \frac{\Gamma^1 - \Gamma^2}{\sqrt{\Im(\Gamma^1) }}\right\Vert  
      &\leq \left\Vert \frac{\Gamma^3}{\sqrt{ \Im(\Gamma^2)}}\right\Vert + \left\Vert \frac{\Gamma^3 \left( \sqrt{\Im(\Gamma^2)} - \sqrt{\Im(\Gamma^1)} \right)}{\sqrt{\Im(\Gamma^2) \Im(\Gamma^1)}} \right\Vert \\
      &\leq \left\Vert \frac{\Gamma^3}{\sqrt{ \Im(\Gamma^2)}}\right\Vert +  \left\Vert \frac{\Gamma^3}{\sqrt{ \Im(\Gamma^2)}}\right\Vert \left\Vert \frac{\Im(\Gamma^2) - \Im(\Gamma^1)}{\sqrt{\Im(\Gamma^1)} \left(\sqrt{\Im(\Gamma^2)} +\sqrt{\Im(\Gamma^1)}\right)} \right\Vert,
    \end{align*}
    we can then conclude with the bound $\sqrt{\Im(\Gamma^1)} \left(\sqrt{\Im(\Gamma^2)} +\sqrt{\Im(\Gamma^1)}\right) \geq \sqrt{\Im(\Gamma^1)\Im(\Gamma^2)}$.
    % we can then conclude thanks to the simple bound $|\Im(\Gamma^2) - \Im(\Gamma^3)| \leq |\Gamma^2 - \Gamma^3|$.
  \end{proof}
    \begin{proof}[Proof of Proposition~\ref{pro:equation_proche_implique_solution_proche_version2}]
    Let us simply bound thanks to Lemma~\ref{lem:tool_matrices_diag_d_s}:
  \begin{align*}
    % d_s(\tilde \Gamma,\Gamma)
    d_s(\tilde \Gamma , \Gamma)
    % \left\Vert \frac{\tilde \Gamma - \Gamma}{\sqrt{\Im(\tilde \Gamma) \Im(\Gamma)}}\right\Vert
    &\leq  \left\Vert \frac{\tilde \Gamma - f(\Gamma)}{\sqrt{\Im(\tilde \Gamma) \Im(\Gamma)}}\right\Vert + \left\Vert \frac{f(\Gamma) - \Gamma}{\sqrt{\Im(\tilde \Gamma) \Im(\Gamma)}}\right\Vert\\
    &\leq  d_s \left(\tilde \Gamma,f(\Gamma) \right)\left(1 + d_s(\Im(\Gamma), \Im(f(\Gamma))\right) + \left\Vert \frac{f(\Gamma) - \Gamma}{\sqrt{\Im(\tilde \Gamma) \Im(\Gamma)}}\right\Vert\\
    &\leq  \lambda d_s \left(\tilde \Gamma,\Gamma \right)\left(1 + d_s(\Im(\Gamma), \Im(f(\Gamma))\right) + \left\Vert \frac{f(\Gamma) - \Gamma}{\sqrt{\Im(\tilde \Gamma) \Im(\Gamma)}}\right\Vert\ \
    \leq  \frac{\left\Vert \frac{f(\Gamma) - \Gamma}{\sqrt{\Im(\tilde \Gamma) \Im(\Gamma)}}\right\Vert}{1 - \lambda- \lambda d_s(\Im(\Gamma), \Im(f(\Gamma))} 
     % \leq O \left(\left\Vert \frac{f(\Gamma) - \Gamma}{\sqrt{\Im(\tilde \Gamma) \Im(\Gamma)}}\right\Vert\right)
  \end{align*}
  since $d_s(\Im(\Gamma), \Im(f(\Gamma))) \leq o(1) \leq \frac{1-\lambda}{2\lambda}$ for $s$ sufficiently big.

  \end{proof}
Proposition~\ref{pro:equation_proche_implique_solution_proche_version_statique} will be employed to set asymptotic results when $n \to \infty$ and to show continuity properties with a parameter $t\to 0$ in Chapters~\ref{cha:resolvente_lipschtiz} and~\ref{cha:robust_estimation}.
  \begin{proposition}\label{pro:equation_proche_implique_solution_proche_version2}
  Let us consider a family of mappings of $\mathcal D_{n_s} (\mathbb H)$, $(f^s)_{m \in \mathbb N}$, each $f^s$ being $\lambda$-Lipschitz
  for the semi-metric $d_s$ with $\lambda < 1$ and admitting the fixed point $\tilde \Gamma^s = f^s(\tilde \Gamma^s)$ and a family of diagonal matrices $\Gamma^s$. 
  If one assumes that\footnote{Usually the notations $O(1)$ and $o(1)$ are used for quasi-asymptotic studies when $n$ tends to infinity but in this proposition, the relevent parameter is $s$, thus $d_s(f^s(\Gamma^s), \Gamma^s) \leq o_{s \to \infty}(1)$ means that for all $K>0$, there exists $S \in \mathbb N$ such that for all $s \geq S$, $d_s(f^s(\Gamma^s), \Gamma^s) \leq K$.} 
  $d_s(\Im(\Gamma^s), \Im(f^s(\Gamma^s))) \leq o_{s \to \infty}(1)$, then:
  % $d_s(f^s(\Gamma^s), \Gamma^s) \leq o(1)$, then:
  \begin{align*}
    % \left\Vert \frac{\tilde \Gamma^s - \Gamma^s}{\sqrt{\Im(\tilde \Gamma^s) \Im(f^s(\Gamma^s))}}\right\Vert\leq O \left(\left\Vert \frac{f^s( \Gamma^s) - \Gamma^s}{\sqrt{\Im(\tilde \Gamma^s) \Im(f^s(\Gamma^s))}}\right\Vert\right).
    d_s( \Gamma^s , \tilde \Gamma^s)\leq O_{s \to \infty} 
    % \left( d_s( \Gamma^s , f^s(\Gamma^s))\right)
    \left(\left\Vert \frac{f^s(\Gamma^s) - \Gamma^s}{\sqrt{\Im(\tilde \Gamma^s) \Im(\Gamma^s)}}\right\Vert\right)
  \end{align*}
  The same result is valid replacing $\mathbb H$ with $\mathbb R_+$ and removing the symbols $\Im$.
  \end{proposition}

\begin{proof}
  It suffices to bound for $s$ sufficiently big:  
  \begin{align*}
    \frac{\left\Vert \frac{f(\Gamma) - \Gamma}{\sqrt{\Im(\tilde \Gamma) \Im(\Gamma)}}\right\Vert}{1 - \lambda- \lambda d_s(\Im(\Gamma), \Im(f(\Gamma))} 
     \leq O \left(\left\Vert \frac{f(\Gamma) - \Gamma}{\sqrt{\Im(\tilde \Gamma) \Im(\Gamma)}}\right\Vert\right)
  \end{align*}
  since $d_s(\Im(\Gamma), \Im(f(\Gamma))) \leq o(1) \leq \frac{1-\lambda}{2\lambda}$ when $s$ tends to infinity.
\end{proof}


\chapter{Statistical study of the resolvent}\label{cha:resolvente_lipschtiz}\label{cha:resolvent}
Denoting $\lambda_1\geq \cdots \geq \lambda_p\geq 0$ the $p$ eigenvalues of $\frac{1}{n}XX^T$ the spectral distribution is defined followingly:
\begin{align*}
  \mu = \frac{1}{p} \sum_{i=1}^p \delta_{\lambda_i}.
\end{align*}
% Let us now present more precisely our assumptions and main results.
% The semi metric is only working on $m$

% \begin{align*}
%   \left\Vert \mathbb E[\Pi_B] - \frac{1}{2i\pi}\int_\gamma \tilde R(z) dz\right\Vert_F \leq O \left(\frac{1}{\sqrt n}\right)
% \end{align*}
% where $\|\cdot \|_F$ is the Frobenius norm
% Therefore, approximating the random mapping $g$ around the bulks of the spectrum allows us to get good estimates on functionals of the eigen values.




% In most papers, authors choose to comprehend the Stieltjes transform through the device of a deterministic equivalent for the resolvent $(zI_p -\frac{1}{n}XX^T)^{-1}$. Here, for many -- mainly esthetical -- issues, we rather chose to work with $Q^z=(I_p - \frac{1}{nz}XX^T)^{-1}$, for which $g(z) = - \frac{1}{zp} \tr (Q^z)$ and that has the main advantage of being possibly continued in $z=0$, even if $0$ is an eigen value of $\frac{1}{n}XX^T$ (that was not the case of $(zI_p -\frac{1}{n}XX^T)^{-1}$). This aspect is very convenient because it allows us to avoid the discussion on weather $p>n$ or $p<n$ for which, respectively $\frac{1}{n}XX^T$ has $p-n$ or $\frac{1}{n}X^TX$ has $n-p$ zero eigen values. Here, only the spectrum without zero has our interest (weather we study $\frac{1}{n}XX^T$ or $\frac{1}{n}X^TX$).


% we study for any $z \in \mathbb C$ the resolvent $Q^z \equiv (I_p - \frac{1}{n} XX^T) ^{-1}$ for at least two reason originating from complex analysis. Noting $\Sp(\frac{1}{n}XX^T) = \{\lambda_1,\ldots, \lambda_p\}$, the spectrum of $\frac{1}{n} XX^T$, we introduce $\mu \equiv \frac{1}{p} \sum_{i=1}^p \delta_{\lambda_i}$, its spectral distribution, $\lambda  \sim \mu$ a random eigen value of $\frac{1}{n} XX^T$. Then the Cauchy integral allows us to set that for any closed path of $\mathbb C$, $\gamma$ whose inner surface contains $\Sp(\frac{1}{n}XX^T)$
% \begin{itemize}
%   % \item $m(z) = \frac{1}{p} \tr(Q^z )$ is the Stieltjes transform of  :
%   % \begin{align*}
%   %   \int f d\mu =  \frac{1}{2\pi i} \oint_\gamma f(z) m(z) dz
%   % \end{align*}
%   \item $\mathbb E[f(\lambda)] =  \frac{1}{2\pi i} \oint_\gamma  \frac{1}{pz}\tr (Q^z) f(z) dz$
%   \item for any deterministic vector $u \in \mathbb R^p$, $\mathbb E[(u^TY)^2] = \frac{1}{2\pi i} \oint_\gamma \frac{f(z)}{z} u^TQu dz$.
% \end{itemize}
% To deduce deterministic estimations from these random formulas, one has to devise what we call a deterministic equivalent of $Q$. It is a deterministic matrix $\tilde Q$ such that for all deterministic matrix $A \in \mathcal M_{p}$:
% \begin{align*}
%   \forall r>0, \ \mathbb E \left[ \left\vert \tr(AQ) - \tr(A\tilde Q) \right\vert^r\right] \underset{p,n \to \infty} \longrightarrow 0,
%  \end{align*}
%  with a convergence speed depending on the norm of $A$. In the litterature, people are generally more interested in the Stieltjes transform so they directly study $\frac{1}{n} \tr (Q^z)$. However when
%  tends to zero It has been shown in that case that only the independence between the columns $x_1,\ldots, x_n$ is required. In tat case,  nonetheless, to assume that the entries of each datum $x_i$ (for $i\in [n]$) are independent limits greatly the range of application. Thanks to concentration of the measure hypothesis, this last independence property is no longer needed. To present the simpler picture possible, we will admit in this introduction that what we call for the moment "concentrated vectors" are transformation $F(Z)$ of a Gaussian vector $Z \sim \mathcal N(0,I_d)$ for a given $1$-Lipschitz (for the euclidean norm) mapping $F : \mathbb R^d \to \mathbb R^p$. This class of random vectors is originated from a central result of CMT \cite[Corollary 2.6]{LED05} that states that for any $\lambda$-Lipschitz mapping $f: \mathbb R^d \to \mathbb R$ (where $\mathbb R^d$ and $\mathbb R$ are respectively endowed with the euclidean norm $\|\cdot\|$ and with the absolute value $|\cdot|$):
% \begin{align}\label{eq:first_concentration_inequality}
%   \forall t >0 : \mathbb P \left(\left\vert f(Z) - \mathbb E[f(Z)]\right\vert \geq t\right) \leq C e^{-(t/\sigma\lambda)^2},
% \end{align}
% where $C=2$ and $\sigma = \sqrt 2$ (they do not depend on the dimensions $d$ !). Note that the speed of concentration is proportional to the Lipschitz parameter of $f$, the random variable $f(Z)$ -- that is called a ``$\lambda$-Lipschitz observation of $Z$'' -- has a standard deviation that does not depend on the dimension $d$ (if $\lambda$ is constant when $d$ tends to $\infty$).
% We note this property succinctly $Z \propto C \mathcal E_2(\sigma)$, or, if we place ourselves in the quasi-asymptotic regime where the dimension $d$ (or $p$) is big, we do not pay attention to the constants appearing in the exponential bound (as long as $C,\sigma \underset{d \to \infty}\leq O(1)$, the result would not be much different) and we write $Z \propto \mathcal E_2$. Then we say that the ``observable diameter of $Z$'' is of order $O(1)$, which means that all the standard deviations of the $1$-Lipschitz observation of $Z$ are of order $O(1)$ (they do not increase with the dimension).

% We can then deduce an infinite number of concentration inequalities on any observation $g(F(Z))$ for $g: \mathbb R^p \to \mathbb R$ Lipschitz. If $F$ is, say, $\lambda$-Lipschitz with $\lambda$ possibly depending on the dimension, we have therefore the concentration $F(Z) \propto \mathcal E_2(\lambda)$. In particular, considering Generative adversarial neural network (GAN) whose objective is to construct from a given noise, realistic image of a given class (images of cats, images of planes, etc...), we can assert as it was explained in \cite{SED20} that the artificial (but realistic !) outputs of those networks form concentrated vectors as Lipschitz transformations of Gaussian drawings. 


% The notation $F(Z) \propto \mathcal E_2(\lambda)$ is set rigorously in the first section of this paper but we choose to introduce it already here as a foretaste because it will be extensively employed all over the paper and once it is well understood, it clarifies drastically the message (and reduce tremendously the expressions). In some aspects, this notation and the systematic attempt to employ it for each new random object that we meet constitute our main contribution to this field of research. To present it briefly, we will show in this paper that if $X \propto \mathcal E_2$ (and other minor hypotheses), then:
% \begin{align*}
%   (Q \ | \ \mathcal A_Q) = \left(I_p - \frac{1}{n}XX^T\right)^{-1} \propto \mathcal E_2(1/\sqrt n)&
%   &\text{and}&
%   &(\beta \ | \ \mathcal A_\beta) \propto \mathcal E_2(1/\sqrt n),
% \end{align*}
% where $\mathcal A_Q$ and $\mathcal A_\beta$ are event of high probability (bigger that $1 - Ce^{-c(n+p)}$, for two constants $C,c>0$) under which $Q$ and $\beta$ are, at the same time, well defined and concentrated. It was shown in \cite{louart2022concentration} that Lipschitz transformation, sums or product of concentrated vectors are also concentrated vectors, here, we go a step further setting that the concentration is preserved through such implicit formulations as the one defining $Q$ and $\beta$. Once we know that they are concentrated, we also provide means to estimate their statistics.% again with concentration of measure hypotheses.

% Our paper is organized as follows. In a first part we display briefly, but rigorously important results of \cite{louart2022concentration} and new ones that provide a solid basis to use CMT tools, we particularly insist on the distinction between three classes of concentrated vectors identified (in an increasing order for the inclusion relation):
% \begin{itemize}
%   \item the Lipschitz concentrated vectors $Z$ : $f(Z)$ satisfies \eqref{eq:first_concentration_inequality} for any $\lambda$-Lipschitz $f$ having value in $\mathbb R$, we denote $Z \propto \mathcal E_2(\sigma)$,
%   \item the convexly concentrated vectors $Z$ : $f(Z)$ satisfies \eqref{eq:first_concentration_inequality} for any $\lambda$-Lipschitz \textit{and convex} functional $f$, we denote $Z \propto_c \mathcal E_2(\sigma)$
%   \item the linearly concentrated random vectors -- $f(Z)$ satisfies \eqref{eq:first_concentration_inequality} for any \textit{linear forms} $f$ bounded by $\lambda$, we denote $Z \in \mathcal E_2(\sigma)$. For such linear mappings, we can rewrite \eqref{eq:first_concentration_inequality}:
% \begin{align}\label{eq:first_concentration_inequality_2}
%   \forall t >0 : \mathbb P \left(\left\vert f(Z) - f(\mathbb E[Z])\right\vert \geq t\right) \leq C e^{-(t/\sigma\lambda)^2},
% \end{align}
%   which leads us to introducing the notation $Z \in \mathbb E[Z] \pm \mathcal E_2(\sigma)$ to express the fact that the linear observations $f(Z)$ of $Z$ lie around $f(\mathbb E[Z])$ (which has no reason to be the case for Lipschitz observation when $Z$ is Lipschitz-concentrated). A major issue in RMT is to find a computable deterministic matrix $\tilde Z$ close to $\mathbb E[Z]$ such that $Z \in \tilde Z \pm \mathcal E_2(\sigma)$. Such deterministic matrices are then called ``deterministic equivalents'' of $Z$ ($\mathbb E[Z]$ is of course one of them).
% \end{itemize}
% Although it is the most stable class, the Lipschitz concentrated vectors can degenerate into linear concentration for instance when we look at the random matrix $XDY^T$ for $X,Y \in \mathcal M_{p,n}$ and $D \in \mathcal D_n$ Lipschitz concentrated. That justifies the introduction of the notion of linear concentration that is simpler to verify and still gives some capital control on the norm. 
% The convex concentration, although it is not so easy to treat -- being only stable through affine mappings -- finds some interest thanks to a well known result of \cite{TAL95} that sets its validity for any random vector of $[0,1]^p$ with independent entries, allowing this way to consider discrete distribution quite absent of the Lipschitz concentrated vectors class. The class of convexly concentrated vectors often degenerates into a mere linear concentration when one consider the product of convexly concentrated random matrices, the entry-wise product of convexly concentrated random vectors or the resolvent $(I_p - X)^{-1}$ of a convexly concentrated random matrix $X \in \mathcal M_{p}$...

% In a second part we present our main theorems allowing us to set the concentration of the solution of equation of the type:
% \begin{align*}
%   Y: \ \ Y = F(X,Y)
% \end{align*}
% where $X$ is concentrated and $y \mapsto F(X,y)$ is contracting with high probability.
% In a third part we give a first application of the two first theoretical part with the design of a deterministic equivalent of the resolvent $Q^z \equiv (zI_p - \frac{1}{n}XDX^T)^{-1}$. We consider three different settings where $n$ and $p$ are of the same order ($O(n) = O(p)$):
% \begin{itemize}
%   \item if $X \propto \mathcal E_2$, and $D = I_n$, then $(Q^z \ | \ \mathcal A_Q)\propto \mathcal E_2(1/\sqrt n)$ in $(\mathcal M_{p}, \| \cdot \|_F)$, 
%   \item if $X \propto \mathcal E_2$, and $D \propto \mathcal E_2$, then $(Q^z \ | \ \mathcal A_Q)\propto \mathcal E_2(\sqrt{\log n})$ in $(\mathcal M_{p}, \| \cdot \|_F)$,
%   \item if $X \propto_c \mathcal E_2$, and $D = I_n$, then $(Q^z \ | \ \mathcal A_Q)\in \mathcal E_2$ in $(\mathcal M_{p}, \| \cdot \|_*)$.%, for some constant $\kappa \underset{n,p \to \infty}{\leq} O(1)$
% \end{itemize}
% In addition, for all those settings we also provide a similar computable deterministic equivalent.
% Note that the different results of concentration differ by the observable diameter, by the type of concentration \textit{and} by the choice of the norm endowing $\mathcal M_{p}$. For a given matrix $A \in \mathcal M_{p}$, we employ the notation $\|A\|_F = \sqrt{\tr(AA^T)} = \sup_{\|B\|_F \leq 1}\tr(BA)$ and $$\|A\|_* = \tr(\sqrt{AA^T}) = \sup_{\|B\| \leq 1}\tr(BA),$$ where $\|\cdot\|$ is the spectral norm : $\|A\| = \sup_{\|u\|,\|v\|\leq 1} u^TAv$). In particular, since for any $A \in \mathcal M_{p}$ such that $\|A\| \leq 1$, $q \mapsto \tr(Aq)$ is $\sqrt{p}$-Lipschitz for the Frobenius norm, for any random matrix $Z$, $Z\propto \mathcal E_2(1/\sqrt n)$ in $(\mathcal M_{p}, \| \cdot \|_F)$ implies $Z\propto \mathcal E_2$ in $(\mathcal M_{p}, \| \cdot \|_*)$, which justifies that the last setting gives a weaker result than the first one (but it is still important !).

% Finally, in a last part, we consider a precise fixed point equation:
% \begin{align*}
%   Y = \frac{\lambda}{n}\sum_{i=1}^n f(x_i^TY)x_i,
% \end{align*}
% where the vectors $x_1,\ldots,x_n \in \mathbb R^p$ are all independent, $f : \mathbb R \to \mathbb R$ is twice differentiable, $f'$ and $f'$ are bounded and $\|f'\|_\infty$ is chosen small enough for the equation to be contractive with high probability (i.e. bigger that $1 - Ce^{-cn}$, for two constants $C,c>0$). 
% We show in that case how the statistical behavior of $Y$ can be understood and give, in particular, a precise estimation of its expectation and covariance.

% Our main contributions can be listed followingly:
% Our paper is organised as follows:



\section{Concentration and estimation of the resolvent}\label{sec:main_res_lipschitz}
   
  % Let us start with the deterministic results concerning the diagonal matrices $\tilde \Lambda^z$, which do not require any particularly constraining assumption. 
  % All our study will be centered around the deterministic diagonal matrix defined in the next proposition. 
  % Actually, none of the previous assumption is needed to set next theorem (just the nonnegativity of $\Sigma_1,\ldots, \Sigma_n$ is required)

% \begin{theorem}\label{the:definition_existence_tilde_Lambda}
%   Given $n$ nonnegative symmetric matrices $\Sigma_1,\ldots, \Sigma_n \in \mathcal M_{p}$, for all $z\in \mathbb H$, the equation:
%   \begin{align}\label{eq:fixed_point_equation_tilde_lambda_theorem}
%     \forall i \in [n], L_i = z - \frac{1}{n} \tr \left(\Sigma_i \left(I_p - \frac{1}{n}\sum_{i=1}^n \frac{\Sigma_i}{L_i}\right)^{-1}\right)
%   \end{align}
%   admits a unique solution $L \in \mathcal D_n(\mathbb H)$ that we denote $\tilde \Lambda^z$.
% \end{theorem}

% Letting $\tilde R : z \mapsto \left(\frac{1}{n}\sum_{i=1}^n \frac{z\Sigma_i}{L_i} - zI_p \right)^{-1}$, we can construct with $\tilde \Lambda^z$ a Stieltjes transform whose associated distribution converges towards the spectral distribution of $\frac{1}{n}XX^T$, where $X= (x_1,\ldots, x_n)$ and for all $i \in [n]$, $\Sigma_i = \mathbb E[x_ix_i^T]$. 
% \begin{theorem}\label{the:Stieltjes_transform_de_tilde_Lambda}
%   The mapping $\tilde g : z \to  \frac{1}{p}\tr(\tilde R)$ is the Stieltjes transform of a measure $\tilde \mu$ of compact support $\tilde S \subset \mathbb R_+$.
% \end{theorem}

We work here under the formalisme of Levy families where the random matrix under study, $X \in \mathcal{M}_{p,n}$ is seen as a sequence depending on $n$ and $p$ is also a sequence depending on $n$ but that should satisfy the following relation:
 \begin{assumption}\label{ass:n_p_commensurable}
  $p\leq O(n)$.
\end{assumption}
 We need of course a concentration hypothesis on $X$:
\begin{assumption}\label{ass:concentration_X}
  $X \propto \mathcal E_2$.
\end{assumption}

A third natural and fundamental hypothesis is to assume that the $n$ columns of $X = (x_1, \ldots, x_n)$ are independent. Again, we do not assume that $x_1, \ldots, x_n$ are identically distributed:
we can possibly have $n$ different distributions for the columns of $X$.
\begin{assumption}\label{ass:x_i_independant}
  $X$ has independent columns $x_1,\ldots, x_n\in \mathbb R^p$.
\end{assumption}
Let us note for simplicity, for any $i \in [n]$:
\begin{align*}
  \mu_i \equiv \mathbb E[x_i]&
  &\Sigma_i \equiv \mathbb E[x_ix_i^T]&
  &\text{and}&
  &C_i \equiv \Sigma_i - \mu_i\mu_i^T.
\end{align*}
It is easy to deduce from Assumption~\ref{ass:concentration_X} (see Proposition~\ref{pro:carcaterisation_vecteur_linearirement_concentre_avec_moments}) that there exists a constant $K>0$ such that for all $n\in \mathbb N$, $  \|C_i\| \leq O(1)$. But to have the best convergence bounds, we also need to impose:\footnote{In \cite{LOU17b}, we only supposed that $\|\mu_i\|\leq O(\sqrt n)$, however, then we only had an approximation of the resolvent with the spectral norm, here we will provide a similar convergence result with the Frobenius norm.}
\begin{assumption}\label{ass:borne_norme_x_i}
  $\sup_{i\in [n]}\|\mu_i\| \leq O(1) $.
\end{assumption}

We conclude with a last assumption which seems important to precisely approximate the support of the spectral distribution.\footnote{the values of the Stieltjes distribution $g(z)$ can be approximated for $z \in \mathbb C$ sufficiently far from the real axis or for $z\in \mathbb R$ sufficiently far from the support without this assumption.} Although we are unsure of its importance, our line of arguments could not avoid it; it is nonetheless quite a weak constraint in view of the practical use of our result.

\begin{assumption}\label{ass:Sigma_borne_inferieurement}
  $\inf_{i \in [n]}\Sigma_i \geq O(1) I_p$.
\end{assumption}

% Let us now give our main results and their consequences. 

% Recalling that our goal is to estimate the spectral distribution of $\frac{1}{n}XX^T$, we wish to estimate:
% \begin{align*}
%   \mu = \frac{1}{p} \sum_{i=1}^p \delta_{\lambda_i}.
% \end{align*}





% The remainder of the article is structured as follows. We first provide some basic notations and results to handle concentrated random vectors \textbf{(Section 1)}. Second, we explain why and how we have to place ourselves on an event of overwhelming probability where $Q^z$ is bounded to show our convergence results \textbf{(Section 2)}. Third, we prove the concentration of the resolvent \textbf{(Section 3)} and provide a first, intermediary, deterministic equivalent which at this stage will not be numerically satisfying \textbf{(Section 4)}. Then we introduce the semi-metric $d_s$ to be able to define correctly the determini $\tilde \Lambda)$ \textbf{(Section 5)} and devise our second deterministic equivalent $\tilde Q^{\tilde \Lambda}$ that we can compute from $\tilde \Lambda$ and that satisfies Theorem~\ref{the:concentration_resolvente_main_res} \textbf{(Section 6)}. Eventually, we show that $\tilde g$ is a Stieltjes transform (Theorem~\ref{the:Stieltjes_transform_de_tilde_Lambda}) and that it approaches the Stieltjes transform of our spectral distribution (Theorem~\ref{the:concentration_transformee_de_stieltjes_main_res}) \textbf{(Section 7)}.

%\tableofcontents


% \section{Study of a random spectral distribution with the resolvent}\label{sse:concentration_lipschitz_resolvent}
\subsection{Resorting to a ``concentration zone'' for $Q^z$}\label{sse:concentration_zone}
Before studying the matricial case, let us first place ourselves in $\mathbb R$.
% \begin{remarque}[concentration of the resolvent: real case]\label{rem:cas_reel}
We consider $X \in \mathbb R$, a Gaussian random variable with zero mean and variance equal to $\sigma^2$ ($X \sim \mathcal N(0,\sigma^2)$). In particular, although we work with unidimensional variables, there can still be a possible dependence on $n$, and we can write $X \propto \mathcal E_2$. 
The random variable $Q \equiv 1/(1-X)$ is only defined if $X \neq 1$ and its law $f_Q$ can be computed on $\mathbb R \setminus\{1\}$ and satisfies:
  \begin{align*}
    f_Q(q) = \frac{e^{-(1- \frac{1}{q})^2/\sigma^2}}{\sqrt{2\pi}\sigma q^2}.
  \end{align*}
  Thus $Q$ is clearly not exponentially concentrated (when $q \to \infty$, $f_Q(q) \sim \frac{e^{-1/\sigma^2}}{q^2}$ therefore the expectation of $Q$ is not even defined). 
  However, if $\sigma$ is small enough (at least $\sigma \leq o(1)$), it can be interesting to consider the event $\mathcal A_Q \equiv \{X \leq \frac{1}{2} \}$ satisfying $\mathbb P(\mathcal A_Q^c) \leq C e^{-1/2\sigma^2}$. 
  The mapping $f:z \mapsto \frac{1}{1-z}$ being $4$-Lipschitz on $(-\infty,\frac{1}{2}]$, one sees that $(Q \ | \ \mathcal A_Q) \in \mathcal E_2$. 
  Following this setting, in the matricial cases, we also need to place ourselves in a concentration zone $\mathcal A_Q$ where the fixed point $Q$ is defined; sufficiently small to retrieve an exponential concentration with $Q \ | \ \mathcal A_Q$ but large enough to be highly probable. 

  The same resort to a \textit{concentration zone} will take place for the resolvent matrix, for that purpose, we introduce in this section an event of high probability, $\mathcal A_Q$, under which the eigen values of $\frac1{zn} XX^T$ are far from $1$, for all $z \in S^\varepsilon$.
Let us start with a bound on $\|X\|$, Assumption~\ref{ass:borne_norme_x_i} leads us to:
\begin{align*}
  \|\mathbb E[X] \| \leq \sqrt n \sup_{1\leq i\leq n}\|\mathbb E[x_i]\| \leq O(\sqrt n)&
  % &\text{and}&
  % &
\end{align*}
then, we deduce from Example~\ref{exe:borne_esp_norm_vecteur_lin_conc} applied to Assumption~\ref{ass:concentration_X} that $\mathbb E[\|X\|] \leq \|\mathbb E[X] \| + O(\sqrt n) \leq O(\sqrt n)$.
Now, introducing a constant $\varepsilon>0$ such that $O(1) \leq \varepsilon \leq O(1)$ and $\nu >0$ defined with:
\begin{align*}
   \sqrt \nu \equiv \mathbb E \left[\frac{1}{ \sqrt n}\|X\|\right]\leq O(1),
 \end{align*} 
 % Now, introducing  
 we denote:
  \begin{align}\label{eq:definition_A_Q_epsilon}
  % \bar \nu = \nu + \varepsilon&
  %   &\text{and}&
  %   &
  \mathcal A_\nu \equiv \left\{\frac{1}{n}\left\Vert XX^T\right\Vert \leq  \nu +\varepsilon\right\}.
  \end{align}
Since $\|X\|/\sqrt n \in \nu \pm \mathcal E_2(1/\sqrt n)$, we know that there exist two constants $C,c>0$ such that $\mathbb P \left( \mathcal A_\nu^c \right)\leq C e^{-cn}$. % To introduce the reader to the issues and settings of this section,
The mapping $M \to \frac{1}{n} MM^T$ is $O(1/\sqrt n)$ Lipschitz on $X(\mathcal A_\nu) \subset \mathcal M_{p,n}$ and therefore, thanks to Lemma~\ref{lem:concentration_sous_ensemble} and Remark~\ref{rem:vecteur_conditionne}: 
\begin{align*}
  \frac{1}{n}XX^T \ | \ \mathcal A_\nu \propto \mathcal E_2 \left(\frac{1}{\sqrt n}\right)
\end{align*}
Let us note $\sigma : \mathcal M_{p} \to \mathbb R^p$, the mapping that associates to any matrix the sequence of its eigen values in decreasing order. It is well known (see \cite[Theorem 8.1.15]{Gol96}) that $\sigma$ is $1$-Lipschitz (from $(\mathcal M_{p}, \|\cdot \|_
F)$ to $(\mathbb R^p , \|\cdot\|$) and therefore if we denote $\lambda_1,\ldots, \lambda_p$ the eigen values of $\frac{1}{n}XX^T$ such that $\lambda_1\geq \cdots\geq \lambda_n$, we have the concentration:
\begin{align*}
  (\lambda_1,\ldots, \lambda_p) \ | \ \mathcal A_\nu \in \left(\mathbb E_{\mathcal A_\nu}[\lambda_1],\ldots, \mathbb E_{\mathcal A_\nu}[\lambda_p]\right) \pm \mathcal E_2 \left(\frac{1}{\sqrt n}\right).
\end{align*}
% It will be useful later to circumvent the spectrum of $\frac{1}{n}XX^T$, after having removed $0$ (as explained in the introduction).


% Considering a constant $\varepsilon >0$, independent with $n$ that will be fixed for the whole paper (we note $O(1) \leq \varepsilon \leq O(1)$). 
% From now on, to avoid unnecessary complication\footnote{Since $\mathbb P \left( \mathcal A_\nu^c \right)\leq C e^{-cn}$, for all $i\in[p]$, $|\mathbb E_{\mathcal A_\nu}[\lambda_i]- \mathbb E_{\mathcal A_\nu}[\lambda_i]| \leq 2 \sqrt{\nu} C e^{-cn}$, and we see that the definition is almost the same.}, 
Given a set $T\subset \mathbb C$, we note for any $\varepsilon>0$, $T^\varepsilon = \{z \in \mathbb C, \exists t \in T, |z-t|\leq \varepsilon\}$. Now, let us denote
\begin{align*}
   S \equiv \{\mathbb E_{\mathcal A_\nu}[\lambda_1], \ldots, \mathbb E_{\mathcal A_\nu}[\lambda_p]\},
 \end{align*}
 (with the expectation taken on $\mathcal A_\nu$). We show in the next lemma that the event
\begin{align*}
  \mathcal A_Q \equiv \mathcal A_\nu \cap \{\forall i\in [\min(p,n)] : \lambda_i \in S^{\varepsilon/2}\}
\end{align*}
has an overwhelming probability.
\begin{lemma}\label{lem:A_Q_overwhelming}
  There exist $C,c >0$ such that $\forall n \in \mathbb N$ $\mathbb P(\mathcal A_Q^c) \leq Ce ^{-cn}$.
\end{lemma}

\begin{proof}[Proof of Lemma~\ref{lem:A_Q_overwhelming}]
  Starting from the identity $S^{\frac{\varepsilon}{2}} \cup_{i \in [p]} \left[\mathbb E_{\mathcal A_\nu}[\lambda_i] - {\frac{\varepsilon}{2}}, \mathbb E_{\mathcal A_\nu}[\lambda_i] + \frac{\varepsilon}2\right]$, we see that $S^{\frac{\varepsilon}{2}}$ is a union of, say, $d$ intervals of $\mathbb R$. 
  % Let us introduce $d\in \mathbb N$, the minimum positive integer such that 
  There exists $2d$ indexes $i_{1}\leq\cdots \leq  i_d$ and $j_1 \leq \cdots \leq j_d$ in $[\min(p,n)]$  such that:
  \begin{align*}
    S^{\frac{\varepsilon}{2}} = \bigcup_{k \in[d]} \left[\mathbb E_{\mathcal A_\nu}[\lambda_{i_k}] - {\frac{\varepsilon}{2}}, \mathbb E_{\mathcal A_\nu}[\lambda_{j_k}] + {\frac{\varepsilon}{2}}\right].
  \end{align*}
  Since $\mathbb E_{\mathcal A_\nu}[\lambda_{i_1}] \geq 0$ and $\mathbb E_{\mathcal A_\nu}[\lambda_{j_d}] \leq \sqrt{\nu} \pm O(e^{-cn}) \leq O(1)$, we can bound:
  \begin{align*}
    \varepsilon d \leq \mathbb E_{\mathcal A_\nu}[\lambda_{j_d}] + \varepsilon \leq O(1),
  \end{align*}
  That implies in particular that $d \leq O(1)$ because $\varepsilon \geq O(1)$.
  We can then bound thanks to the concentration of the $2d$ random variables $\lambda_{i_1},\ldots, \lambda_{i_d}$ and $\lambda_{j_1},\ldots, \lambda_{j_d}$:
  \begin{align*}
    \mathbb P(\mathcal A_Q^c) 
    &= \mathbb P \left(\exists k \in [d], \left\vert \lambda_{i_k} - \mathbb E_{\mathcal A_\nu}[\lambda_{i_k}]\right\vert > {\frac{\varepsilon}{2}} \ \text{or} \ \left\vert \lambda_{j_k} - \mathbb E_{\mathcal A_\nu}[\lambda_{j_k}]\right\vert > {\frac{\varepsilon}{2}}\right)\\
    &\leq \sum_{k=1}^d \left( \mathbb P \left( \left\vert \lambda_{i_k} - \mathbb E_{\mathcal A_\nu}[\lambda_{i_k}]\right\vert > {\frac{\varepsilon}{2}}\right) + \mathbb P \left( \left\vert \lambda_{j_k} - \mathbb E_{\mathcal A_\nu}[\lambda_{j_k}]\right\vert > {\frac{\varepsilon}{2}}\right) \right)
    \ \ \leq 2dC e^{- cn \varepsilon^2/4},
  \end{align*}
  where $C$ and $c$ are the two constants appearing in the concentration inequality of $(\lambda_1,\ldots, \lambda_p) = \sigma(\frac{1}{n}XX^T)$.
\end{proof}


Now, let us remark that the spectrum of $\frac{1}{n}XX^T$ is closely related to the spectrum of $\frac{1}{n}X^TX$ via the equivalence:
\begin{align*}
   \lambda \in \Sp \left(\frac{1}{n}XX^T\right) \setminus \{0\}&
   &\Longleftrightarrow&
   &\lambda \in \Sp \left(\frac{1}{n}X^TX\right) \setminus \{0\}.
 \end{align*} 
 As a consequence, one of the two matrices has $|n-p|$ supplementary zeros in its spectrum. Since those zeros do not carry any specific information about the distribution of $\frac{1}{n}XX^T$, we try to remove them from the study to re-establish the symmetry. The $\min(p,n)$ first entries of $\sigma(\frac{1}{n}XX^T)$ and $\sigma(\frac{1}{n}X^TX)$ are the same (and some of them can cancel), we thus naturally introduce the set:
 \begin{align*}
    & S_{-0} 
    \equiv \left\{\mathbb E_{\mathcal A_Q}[\lambda_i], i\in [\min(p,n)] \right\},
  \end{align*} 
  Be careful that if $0 \in \Sp \left(\frac{1}{n}XX^T\right) \cap \Sp \left(\frac{1}{n}X^TX\right)$ then $0 \in S_{-0}$.

  To avoid the issue on zero, instead of studying, as it is usually done, the resolvent $(\frac{1}{n}XX^T- zI_p)^{-1}$, we rather look at:
  \begin{align*}
    Q^z\equiv \left(I_p - \frac{1}{zn}XX^T\right)^{-1},
  \end{align*}
  that has the advantage of satisfying $\|Q^z\| \leq O(1)$, for all $z \in S_{-0}$, which will allow us to show the concentration of $Q^z$ even for $z$ close to zero when $n<p$ (and $0 \notin S_{-0}$).

  One of the objective of the study was to establish converging bounds when $z$ is at a constant distance from $S_{-0}$. We were not able to set it for all our results (we failed with Proposition~\ref{pro:2_hypo_pour_proposition_equation_proche_pt_fixe_proche} where we could only set the result for $z$ at a constant distance from $S$) however, we hope to be able to set the general result after further research, we thus keep, when accessible, general formulations with $S_{-0}$.  



% At that point of the paper we know that the non zero eigen values of $\frac{1}{n}XX^T$ are most likely lying in the union of compact intervals $S_{-0}^\varepsilon\subset [-\varepsilon, \nu + \varepsilon]$.












































\subsection{Concentration of the resolvent $Q^z = (I_n -\frac{1}{nz}XX^T)^{-1}$.}
   Given a matrix $A \in \mathcal M_{p,n}(\mathbb C)$, we denote $|A| = \sqrt{A\bar A^T}$ ($A\bar A^T$ is a nonnegative Hermitian matrix). With a simple diagonalization procedure, one can show for any Hermitian matrix $A$ the simple characterization of the spectrum of $|A|$:
\begin{align}\label{eq:valeur_propre_module_matrice}
   \Sp(|A|) = \{|\lambda|, \lambda\in \Sp(A)\},
 \end{align} 
 note also that for any real vector $u \in \mathbb R^p$:
 \begin{align}\label{eq:borne_module_formme_q}
   |u^T A u| \leq u^T |A|u.
 \end{align} 
  % We will see later that t
  It is possible to go further than the mere bound $|Q^z| \leq O(1)$ when $z$ is close to $0$ and $p\leq n$, we are then able to show that $|Q^z| \leq O(|z|/(|z|+1))$. When $p \geq n$ no such bound is true and it is then convenient to rather look at the coresolvent $\check Q^z \equiv (I_p - \frac{1}{nz} X^TX)^{-1}$ that satisfies in that regime $|\check Q^z| \leq O(|z|/(|z|+1))$. 
To formalize this approach, we introduce two quantities that will appear in our convergence speeds:
\begin{align*}
  \kappa_z \equiv 
  \left\{\begin{aligned}
    &\frac{|z|}{1+|z|} \ \ \text{if} \ p \leq n\\
    &1 \ \ \text{if} \ n \leq p\\
  \end{aligned}\right.&
  & \check\kappa_z \equiv 
  \left\{\begin{aligned}
    &1 \ \ \text{if} \ p \leq n\\
    &\frac{|z|}{1+|z|} \ \ \text{if} \ n \leq p\\
  \end{aligned}\right.
\end{align*}
note that both of them are bounded by $1$ but they can tend to zero with $|z|$ depending on the sign of $p-n$, besides:
\begin{align}\label{eq:formulekxck}
  \kappa_z \check \kappa_z = \frac{|z|}{1+|z|}.
\end{align}
Note than in our formalism, the parameter $z$, as most quantities of our manuscript, is varying with $n$ (we do not assume that $O(1) \leq |z| \leq O(1)$ like $\varepsilon$. It is not a "constant").


%  $|\Sp(A) | \equiv \{|\lambda|, \lambda\in \Sp(A)\}$ and we have the identity:
% \begin{align*}
%   |\Sp(A) | = 
% \end{align*}
% the inequality $a\leq |\Sp(A) | \leq b$ signifies that $\forall \lambda \in A$, $ a\leq \lambda \leq b$.
% \begin{align*}
%   |\Sp(A) | \equiv \{|\lambda|, \lambda\in \Sp(A)\}
% \end{align*}


\begin{lemma}\label{lem:Borne_resolvante}
  Under $\mathcal A_Q$, $Q^z$ and $\check Q^z$ can be defined on $0$ and for any\footnote{In theory, both the parameter $z$ and the set $S_{-0}^\varepsilon$ depends on our asymptotic parameter $n$, so one should rigorously write $z_n \in S_{-0}^\varepsilon(n)$} $z \in \mathbb C \setminus S_{-0}^\varepsilon$:
\begin{align*}
  O \left(\kappa_z\right) I_p \leq |Q^z| \leq O \left(\kappa_z\right)I_p&
  &\text{and}&
  &O \left(\check \kappa_z\right) I_p \leq |\check Q^z| \leq O \left(\check \kappa_z\right)I_p
\end{align*}
(for the classical order relation on hermitian matrices).
\end{lemma}

\begin{proof}%[Proof of Lemma~\ref{lem:Borne_resolvante}]
   % Let us first place ourselves in the general case. 
   We can diagonalize the nonnegative symmeric matrix: $\frac{1}{n}XX^T = P D P^T$, with $D = \diag(\lambda_1,\cdots, \lambda_p)$ and $P \in \mathcal O_p$, an orthogonal matrix. There exists $q \in [p]$ such that $\lambda_{q+1} = \cdots = \lambda_{p} = 0$, and for all $i \leq q$, $\lambda_i \neq 0$ (possibly $q = p$ or $q < \min(p,n)$). Then, if we denote $P_0 \in \mathcal M_{p,{p-q}}$ the matrix composed of the $p-q$ last columns of $P$, $P_+$ the matrix composed of the rest of the $q$ columns, and $D_+ = \diag(\lambda_{1}, \ldots, \lambda_q)$, we can decompose:
  \begin{align*}
     Q^z = P \left(\frac{zI_p}{zI_p - D}\right) P^T = P_0P_0^T + P_+ \left(\frac{zI_q}{zI_q - D_+} \right) P_+^T.
   \end{align*}
  Since $P_0P_+^T =0$ and $P_+P_0^T =0$, we have: $|Q^z|^2 = P_0P_0^T + P_+ \left(\frac{|z|^2I_q}{|zI_q - D_+|^2} \right) P_+^T$. We can bound:
   \begin{align*}
     O \left(\frac{|z|}{1+|z|}\right) \leq \frac{|z|}{|z| + \nu + \varepsilon} \leq P_+ \left(\frac{|z|I_q}{|zI_q - D_+|} \right) P_+^T 
        \leq  \frac{|z|}{d(z, S_{-0}) - \frac{\varepsilon}{2}} \leq O \left(\frac{|z|}{1+|z|}\right)
   \end{align*}
   % Now, from the bound 
   % \begin{align*}
   %   O \left(\frac{|z|^2}{1 + |z|^2}\right) \leq \frac{|z|^2}{(|z| + \nu + \varepsilon)^2} \leq\left\vert  \frac{zI_q}{zI_q - D_+}\right\vert^2\leq \frac{|z|^2}{d(z, S_{-0})^2} \leq O \left(\frac{|z|^2}{1 + |z|^2}\right),
   % \end{align*}
  Therefore, in all cases ($p \leq n$ or $p\geq n$) $O(1) \leq |Q^z| \leq O(1)$. However, when $p\leq n$, we can precise those bounds:
   % $\mathbb E_{\mathcal A_Q}[\lambda_{\min(p,n)}] \geq O(1)$ We can then distinguish the cases:
   \begin{itemize}
     \item if $\mathbb E_{\mathcal A_Q}[\lambda_{\min(p,n)}] > \frac{\varepsilon}{2}$, then $P_0$ is empty, $P_ + = P$ and we see that $ O \left(\frac{|z|}{1+|z|}\right) \leq |Q^z|\leq  O \left(\frac{|z|}{1+|z|}\right)$.
      % and the same holds for $\check Q^z$ when $p\geq n$.
      \item if $\mathbb E_{\mathcal A_Q}[\lambda_{\min(p,n)}] \leq \frac{\varepsilon}{2}$, the bound $d(z, S_{-0}) \geq \varepsilon$ implies that $|z| \geq \frac{\varepsilon}{2}$ %and therefore:
       and $ O(\kappa_z) = O(\frac{|z|}{1+|z|})\leq O(1) \leq O(\kappa_z)$, therefore:% $O(1) \leq \kappa_z \leq O(1)$ and we can bound:
     \begin{align*}
       O \left(\kappa_z\right)%\leq O(1) I_p 
       &\leq O \left(\min \left(1, \kappa_z\right)\right)I_p 
       \leq |Q^z|   \leq O \left(1 +\kappa_z\right) I_p
       \leq O \left(\kappa_z\right).
       % \leq O(1)I_p,
     \end{align*}
     The inequalities on $\check Q^z$ are proven the same way.
   \end{itemize}

\end{proof}
\begin{proposition}\label{pro:concentration_resolvente_1}
  Given $z \in \mathbb C \setminus S_{-0}^\varepsilon$, we have the concentrations $Q^z \ | \ \mathcal A_Q \propto \mathcal E_2 (\kappa_z/\sqrt n)$ in $(\mathcal M_{p}, \|\cdot \|_F)$ and $\check Q^z \ | \ \mathcal A_Q \propto \mathcal E_2 (\check\kappa_z/\sqrt n)$ in $(\mathcal M_{n}, \|\cdot \|_F)$.
\end{proposition}
\begin{proof}
  % We could see it as a consequence of Theorem~\ref{the:lipschitz_COncentration_solution_conentrated_equation_phi_concentre_norme_infinie}, applied to the equation
  % \begin{align*}
  %   Q^z = \frac{I_p}{z} + \frac{1}{zn} XX^TQ^z,
  % \end{align*}  
  % but it is probably more simple to see 
  Noting $\Phi : \mathcal M_{p,n} \to \mathcal M_{p}(\mathbb C)$ and $\check\Phi: \mathcal M_{p,n} \to \mathcal M_{n}(\mathbb C)$ defined as:
  \begin{align*}
     \Phi(M) =  \left(I_p - \frac{MM^T}{zn}\right)^{-1}&
     &\text{and}&
     &\check \Phi(M) =  \left(I_n - \frac{M^TM}{zn}\right)^{-1},
   \end{align*}
   it is sufficient to show that $\Phi$ (resp. $\check \Phi$) is $O(\kappa_z/\sqrt n)$-Lipschitz (resp. $O(\check\kappa_z/\sqrt n)$-Lipschitz) on $\mathcal M_{n,p}^{\mathcal A_Q} \equiv X(\mathcal A_Q)$\footnote{$\mathcal M_{n,p}^{\mathcal A_Q} \subset \{ M \in \mathcal M_{n,p}, \frac{1}{n}\|MM^T\| \leq \nu+\varepsilon \}$}. For any $M \in \mathcal M_{n,p}^{\mathcal A_Q}$ and any $H \in \mathcal M_{p,n}$, we can bound $\|M\|\leq (\nu + \varepsilon) \sqrt n \leq O(\sqrt n)$ and:
  \begin{align*}
    \|\restriction{d\Phi }{M} \cdot H\|_F 
    &= \left\Vert \Phi \left(M\right)\frac{1}{nz}(MH^T + HM^T) \Phi \left(M\right)\right\Vert_F
    % = \left\Vert \Phi(M)(z\Phi(M) - I_p)\right\Vert 
    % \leq O \left(\frac{\|H\|}{\sqrt n}\right).%
    % &\leq \frac{(\nu + \varepsilon) |z| \|H\|}{d(z,S_\varepsilon)^2 \sqrt n} 
    % \leq O \left(\frac{\|H\|}{\sqrt n}\right).
  \end{align*}
  We can now distingish two different cases:
  \begin{itemize}
    % \item if $\mathbb E_{\mathcal A_Q}[\lambda_{\min(p,n)}] \leq o(1)$, then $z \geq O(1)$ and Lemma~\ref{lem:Borne_resolvante} allows us to bound:
    % \begin{align*}
    %   \|\restriction{d\Phi }{M} \cdot H\| \leq O \left(\frac{\|H\|}{\sqrt n}\right).
    % \end{align*}
    \item if %$\mathbb E_{\mathcal A_Q}[\lambda_{\min(p,n)}] \geq O(1)$ and 
    $p \leq n$ then:
    \begin{align*}
      \|\restriction{d\Phi }{M} \cdot H\|_F \leq O \left(\frac{\|H\|_F |z|}{(1 + |z|)^2\sqrt n}\right)\leq O \left(\frac{\|H\|_F |z|/\sqrt n}{1 + |z|}\right).
    \end{align*}
    \item if %$\mathbb E_{\mathcal A_Q}[\lambda_{\min(p,n)}] \geq O(1)$ and 
    $p \geq n$, we know that $\|\Phi(M)\| \leq O(\kappa_z) \leq O(1)$ and $\|\check \Phi(M)\| \leq O(\check\kappa_z) \leq O(\frac{|z|}{1+ |z|})$. We employ then the classical identity:
    \begin{align}\label{eq:lien_Q_Q_check}
      \Phi(M)M = M^T \check \Phi(M)
    \end{align}
    to be able to bound:
    \begin{align*}
      \|\restriction{d\Phi }{M} \cdot H\|_F 
      &\leq \frac{2 (\nu + \varepsilon) \|H\|_F}{|z| \sqrt n}\left\Vert  \check\Phi(M)  \right\Vert \left\Vert\Phi \left(M\right)\right\Vert  \\
      &\leq O \left(\frac{\|H\|_F }{(1 + |z|)\sqrt n}\right) %\leq O \left(\frac{\|H\|}{\sqrt n}\right)
      \leq O \left(\frac{\|H\|_F}{\sqrt n}\right)
    %     \|\restriction{d\Psi }{M} \cdot H\| 
    % & \leq \frac{2}{n|z|}\left\Vert H\check \Phi \left(M\right)M^T\right\Vert + \frac{1}{n^2|z|^2}\left\Vert M \check \Phi \left(M\right)(M^TH + H^TM) \check \Phi \left(M\right) M^T\right\Vert \\%+ \left\Vert M\check \Phi \left(M\right)\frac{H}{z n}\right\Vert\\
    % &\leq O \left(\frac{\|H\||z|}{\sqrt n(1+|z|)^ 2}\right) + O \left(\frac{\|H\||z|}{(1+|z|)\sqrt n}\right) .
    \end{align*}
  \end{itemize}
  Thus, in all cases, under $X(\mathcal A_Q)$, $Q^z$ is a $O(\kappa_z/\sqrt n)$-Lipschitz transformation of $X\propto \mathcal E_2 (1)$ and as such, it satisfies the concentration inequality of the proposition thanks to Lemma~\ref{lem:concentration_sous_ensemble} and Remark~\ref{rem:vecteur_conditionne}. The same holds for $\check Q^z$.
\end{proof}
\begin{remark}\label{rem:XX_borne_not_needed}
  The preceding proof partly relies on the assertion $\| X\| \leq \sqrt n$ available under the event $\mathcal A_Q$. However one does not need it to be able to prove that $Q$ is a Lipschitz transformation of $X$ since one can bound the element $QX/\sqrt n$ as a whole thanks to the formulas:
  \begin{align}\label{eq:formume_Q_check}
  % X^TQ^z = \check Q^z X&
  \frac{1}{zn} Q^zXX^T =  Q^ z - I_n&
  &\text{and}&
  &\frac{1}{zn}\check Q^zX^TX =  \check Q^ z - I_n.
\end{align}
On the one hand:
\begin{align*}
  \left\Vert \frac{1}{\sqrt n}Q^zX  \right\Vert 
  \leq \sqrt{|z|\left\Vert \frac{1}{zn}Q^zXX^TQ^z \right\Vert }
  \leq \sqrt{|z| \left\Vert (Q^z)^2-Q^z \right\Vert }
  \leq O(\sqrt {|z|}(\kappa_z + \kappa_z^2)) \leq O(\sqrt {|z|}\kappa_z)
\end{align*} 
On the other hand, \eqref{eq:lien_Q_Q_check} gives us:
\begin{align*}
  \left\Vert \frac{1}{\sqrt n}Q^zX \right\Vert 
  =\|\frac{1}{\sqrt n}X\check Q^z \| 
  \leq \sqrt{|z|\left\Vert \frac{1}{zn}Q^zX^TXQ^z \right\Vert }
  % \leq \sqrt{|z| \left\Vert ((\check Q^z)^2-\check Q^z )\right\Vert }
  % \leq O(\sqrt {|z|}(\kappa_z + \kappa_z^2)) 
  \leq O(\sqrt {|z|}\check \kappa_z)
\end{align*}
\end{remark}
% {\color{orange} Finalement pour Ã©viter d'avoir Ã  supposer que les $x_i$ sont identiquement distribuÃ©s, je vais supposer que $f$ est bornÃ©e.}
% {\color{orange} J'aimerais bien me passer de l'hypothÃ¨se $x_i$ identiquement distribuÃ©s, mais j'en ai besoin Ã  des moments ponctuels que j'ai signalÃ©}







































\subsection{A first deterministic equivalent}
One is often merely working with linear functionals of $Q^z$, and since Proposition~\ref{pro:concentration_resolvente_1} implies that $Q^z \ | \ \mathcal A_Q \in \mathbb E_{\mathcal A_Q} Q^z \pm \mathcal E_2$, one naturally wants to estimate the expectation $\mathbb E_{\mathcal A_Q} [Q^z]$. 


In \cite{louart2018concentration} is provided a deterministic equivalent $\tilde Q^z \in \mathcal M_p(\mathbb C)$ satisfying $\|\mathbb E[Q^{z}]- \tilde Q^z\| \leq O(1/\sqrt n)$ for any $z \in \mathbb R^-$, we are going to show below a stronger result,
\begin{itemize}
   \item with a Frobenius norm replacing the spectral norm,
   \item for any complex $z \in \mathbb C \setminus S_{-0}^\varepsilon$,
   \item for random vectors $x_1,\ldots, x_n$ having possibly different distributions (it was assumed in \cite{louart2018concentration} that there was a finite number of classes)
 \end{itemize}

An efficient approach, developed in particular in \cite{SIL86,SIL95} is to look for a deterministic equivalent of $Q^z$ depending on a deterministic diagonal matrix $\Delta \in \mathbb R^n$ and having the form:
\begin{align}\label{eq:definition_of_tilde_Q}
  \tilde Q^\Delta= \left( I_p - \Sigma^{\Delta}\right)^{-1}&
  &\text{where}&
  &\Sigma^{\Delta} \equiv  \frac{1}{n}\sum_{i=1}^n \frac{\Sigma_i}{\Delta_i} = \frac{1}{n} \mathbb E[X \Delta^{-1} X^T].
 \end{align}
 One can then express the difference with the expectation of $Q^z$ under $\mathcal A_Q$, $\mathbb{E}_{\mathcal A_Q} \left[Q^z\right]$ followingly:
 \begin{align*}
  \mathbb{E}_{\mathcal A_Q} \left[Q^z\right] - \tilde Q^\Delta
  &=\mathbb{E}_{\mathcal A_Q}\left[Q^z\left(\frac{1}{zn}XX^T - \Sigma^{\Delta}\right)\tilde{Q}^\Delta\right] \\
  &=\frac{1}{n}\sum_{i=1}^n  \mathbb{E}_{\mathcal A_Q}\left[Q^z  \left(\frac{x_ix_i^T}z - \frac{\Sigma_i}{\Delta_i} \right)\tilde{Q}^\Delta\right].
  % &\hspace{0.5cm}+ \frac{1}{n^2}\sum_{i=1}^n \mathbb{E}_{\mathcal A_Q}\left[\left(1+\Delta_i\right)Q_{-i}^zx_ix_i^TQ^z \Sigma \tilde Q^z(\Delta) \right]
\end{align*}
To pursue the estimation of the expectation, one needs to control the dependence between $Q^z$ and $x_i$. For that purpose, one uses classically the Schur identities:
\begin{align}\label{eq:lien_q_qj_schur}
  % &Q=Q_{-i} +\frac{1}{n}(1+ \frac1nx_i^TQx_i)Q_{-i}x_ix_i^TQ_{-i}&
  % &\text{and}&
  % &Qx_i=(1+ \frac1nx_i^TQx_i)Q_{-i}x_i,
  &Q^z=Q^z_{-i} +\frac{1}{zn}\frac{Q^z_{-i}x_ix_i^TQ^z_{-i}}{1- \frac1{zn}x_i^TQ_{-i}^zx_i}&
  &\text{and}&
  &Q^zx_i=\frac{Q^z_{-i}x_i}{1- \frac1{zn}x_i^TQ^z_{-i}x_i},
\end{align}
for $Q_{-i}^z = (I_n - \frac{1}{zn} X_{-i}X_{-i}^T)^{-1}$ (recall that $X_{-i} = (x_1,\ldots, x_{i-1}, 0, x_{i+1}, \ldots, x_n) \in \mathcal M_{p,n}$). The Schur identities can be seen as simple consequences to the so called ``resolvent identity'' that can be generalized to any, possibly non commuting, square matrices $A,B \in \mathcal M_p$ with the identity:
\begin{align}\label{eq:resolvent_identity}
   A^{-1} - B^{-1} = A^{-1} (B-A) B^{-1}&
   &\text{or}&
   &A^{-1} + B^{-1} = A^{-1} (A+B) B^{-1}
 \end{align}
 (it suffices to note that $A(A^{-1} + A^{-1} (B-A) B^{-1})B = I_p$).

% The central quantity of our estimation is
Introducing the notation:
\begin{align*}
   \Lambda^z \equiv \diag_{1\leq i \leq n} (z - \frac1nx_i^TQ_{-i}^zx_i),&
   &\text{satisfying: } \ \ \forall i \in [n]: \ Q^z x_i = \frac{z}{\Lambda^z}Q_{-i}^z x_i,
 \end{align*} 
one can express thanks to the independence between $Q^z_{-i}$ and $x_i$:
\begin{align}\label{eq:definition_epsilon_1_2}
\mathbb{E}_{\mathcal A_Q} \left[Q^z\right] - \tilde Q^\Delta 
    &= \frac{1}{n}\sum_{i=1}^n  \mathbb{E}_{\mathcal A_Q}\left[Q^z_{-i} \left(\frac{x_ix_i^T}{\Lambda_i^z} - \frac{\Sigma_i}{\Delta_i}\right)\tilde{Q}^\Delta\right] 
    + \frac{1}{n}\sum_{i=1}^n \frac{1}{\Delta_i}\mathbb{E}_{\mathcal A_Q}\left[(Q_{-i}^z - Q^z) \Sigma_i \tilde Q^\Delta\right]\nonumber\\
    % + \frac{1}{zn^2}\sum_{i=1}^n \frac{1}{\Delta_i}\mathbb{E}_{\mathcal A_Q}\left[Q^zx_ix_i^TQ_{-i}^z \Sigma_i \tilde Q^\Delta\right]\nonumber\\
% \end{align}
% Since $Q_{-i}$ is independent with $x_i$, the difference then decomposes:
% \begin{align}
%   &\tilde Q^{z}(\Delta^z) - \mathbb{E}_{\mathcal A_Q}Q^z
  % &=\mathbb{E}_{\mathcal A_Q}\left[\varepsilon_1 + \varepsilon_2 + \varepsilon_3 \right]\  \\
  &= \varepsilon_1 + \delta_1 + \delta_2 +\varepsilon_2 \\
  \text{with :} \ \ \ &\left\{
  \begin{aligned}
    &\varepsilon_1 = \frac{1}{n} \mathbb{E}_{\mathcal A_Q}\left[\sum_{i = 1}^nQ^z_{-i}x_i \left(\frac{\Delta_i - \Lambda_i^z}{\Lambda_i^z\Delta_i}\right)x_i^T \tilde{Q}^\Delta \right] = \frac{1}{n} \mathbb{E}_{\mathcal A_Q}\left[Q^zX \left(\frac{\Delta - \Lambda^z}{z\Delta}\right)X^T \tilde{Q}^\Delta \right] \\
    &\delta_1 = \frac{1}{n}\sum_{i=1}^n \mathbb{E}_{\mathcal A_Q}\left[Q^z_{-i} \left(\frac{x_ix_i^T - \mathbb{E}_{\mathcal A_Q}[x_ix_i^T] }{\Delta_i}\right)\tilde{Q}^\Delta \right] \\
    &\delta_2 = \frac{1}{n}\sum_{i=1}^n \mathbb{E}_{\mathcal A_Q}\left[Q^z_{-i} \left(\frac{\mathbb{E}_{\mathcal A_Q}[x_ix_i^T] - \Sigma_i}{\Delta_i}\right)\tilde{Q}^\Delta \right] \\
    & \varepsilon_2 =  -\frac{1}{zn^2} \sum_{i=1}^n \frac{1}{\Delta_i}\mathbb{E}_{\mathcal A_Q}\left[Q^zx_i x_i^TQ_{-i}^z\Sigma_i\tilde{Q}^\Delta\right],
  \end{aligned}
  \right. \nonumber
\end{align}
where we recall that $Q^z - Q^z_{-i} = \frac{1}{nz}Q^zx_i x_i^TQ_{-i}^z$.
From this decomposition, one is enticed into choosing, in a first step $\Delta \approx \mathbb E_{\mathcal A_Q}[\Lambda^z] \in \mathcal D_n(\mathbb C)$ so that $\varepsilon_1$ would be small. We will indeed take for $\Delta$, the deterministic diagonal matrix: 
$$\hat \Lambda^z \equiv
 \diag \left( z - \frac{1}{n} \tr(\Sigma_i\mathbb E_{\mathcal A_Q}[Q^z]) \right)_{1\leq i \leq n} \in \mathcal D_n(\mathbb C).$$ 
\begin{lemma}\label{lem:Concentration_lambda}
  Given $z\in \mathbb C \setminus S_{-0}^\varepsilon$, $(\Lambda^z \ | \ \mathcal A_Q) \propto \mathcal E_2(\kappa_z/\sqrt n)$ in $(\mathcal D_n(\mathbb C), \| \cdot \|)$.
  % \begin{align*}
  %   (\Lambda^z \ | \ \mathcal A_Q) \in \mathbb E_{\mathcal A_Q} [\Lambda^z] \pm \mathcal E_2(|\kappa_z|/\sqrt n)&
  %   &\text{in} \ \left( \mathcal D_n(\mathbb C), \|\cdot \| \right).
  % % &\text{in} \ \ (\mathcal D_n(\mathbb C), \| \cdot \|_F).
  % \end{align*}
  % and .
\end{lemma}
\begin{proof}
  Inspiring from the proof of Proposition~\ref{pro:concentration_resolvente_1}, one can show easily that for all $z \in \mathbb C \setminus S_{-0}^\varepsilon$, the mapping $X \to \Lambda^z = \diag_{i \in [n]}(z - \frac{1}{n}x_i^T Q_{-i}^zx_i)$ is a $O(\kappa^z/\sqrt n)$-Lipschitz transformation from $(\mathcal{M}_{p,n}, \| \cdot \|_F)$ to $(\mathcal D_n, \| \cdot \|)$  under $\mathcal A_Q$ (since then $\|x_i\| \leq O(\sqrt n)$). 
\end{proof}
Putting the Schur identities \eqref{eq:lien_q_qj_schur}, the relation \eqref{eq:lien_Q_Q_check} and the formula \eqref{eq:formume_Q_check}
\begin{align}\label{eq:formume_Q_check}
  % X^TQ^z = \check Q^z X&
  % &\text{and}&
  \frac{1}{zn}\check Q^zXX^T =  \check Q^ z - I_n,
\end{align}
together one obtains:
% \begin{align*}
%   \frac{z}{\Lambda^z} = \diag_{i\in [n]}\left(\frac{1}{1- \frac1{zn}x_i^TQ^z_{-i}x_i}\right)
%   % = \diag_{i\in [n]}\left(1+ \frac1{zn}x_i^TQ^zx_i\right) 
%   = I_n + \frac{1}{zn} \diag(X^TQ^zX)
% \end{align*}
\begin{align}\label{eq:link_lambda_cQ}
   \frac{z}{\Lambda^z}
   =\diag_{i\in [n]}\left(\frac{1}{1- \frac1{zn}x_i^TQ^z_{-i}x_i}\right) %= \diag_{1\leq i \leq n} (\frac{1}{1- \frac1nx_i^TQ_{-i}^zx_i}) 
  % = \diag_{1\leq i \leq n} \left(1 +  \frac1nx_i^TQ^zx_i\right) 
  = I_n + \frac{1}{zn}\diag(X^TQ^zX) = \diag(\check Q^z)
\end{align}
% That allows us to get a concentration that is better for the class of Lipschitz observations it concerns (the observation Lipschitz for the Frobenius norm $\|\cdot \|_F$) but worse for the observable diameter when $p\leq n$ and $|z| \geq 1 > \kappa_z = \frac{1 + |z|}{|z|}$.
% \begin{lemma}\label{lem:concentration_lambda_norm_frobenius}
%   Given $z\in \mathbb C \setminus S_{-0}^\varepsilon$:
%   \begin{align*}
%      (\Lambda^z \ | \ \mathcal A_Q) \in \hat \Lambda^z \pm \mathcal E_2(|z|/\sqrt n)&
%      &\text{in} \ \left( \mathcal D_n, \|\cdot \|_F \right).
%    \end{align*}
%    % since  This new 
% \end{lemma}
% \begin{proof}
%   We know from \eqref{eq:link_lambda_cQ} that $\Lambda^z = \frac{z}{\diag(\check Q^z)}$ and, as seen in the proof of Proposition~\ref{pro:concentration_resolvente_1}, one can show that the mapping $X \to \frac{z}{\diag(\check Q^z)}$ is a $O( |z|/\sqrt n)$-Lipschitz transformation of $X$.
% \end{proof}
To be able to use Proposition~\ref{pro:estimation_XDY} with $\hat \Lambda^z$, one further needs:
% We then have all the element to set:

\begin{lemma}\label{lem:lambda_lambda_hat_proche}
  $\| \mathbb E_{\mathcal A_Q} [\Lambda^z] - \hat \Lambda^z \|  \leq O (\kappa_z/ n)$.
\end{lemma}
% To prove this lemma, we first need and interesting identity resulting from 

This lemma that seems quite simple actually requires three preliminary results whose main aim is to show that $Q_{-i}^z$ is close to $Q^z$.
Let us first try and bound $\Lambda^z$ thanks to \eqref{eq:link_lambda_cQ}.
\begin{lemma}\label{lem:Borne_Lambda}
  % In the set of symmetric matrices, we have the inequality 
  Given $z \in \mathbb C \setminus S_{-0}^\varepsilon$: %$O \left(\frac{|z|}{1 +|z| }\right)I_n \leq |\check Q^z| \leq O \left(1\right)I_n$
  % \begin{align*}
  %   O \left(\frac{1}{1 +|z| }\right)I_n \leq |\check Q^z| \leq O \left(\frac{1}{1 +|z| }\right)I_n
  % \end{align*}
  % $\frac{I_p}{|z|^2 + \bar\nu^2} \leq |\check Q^z|^2 \leq \frac{I_p}{d(z,S_\varepsilon)^2}$ 
  % and:
  \begin{align*}
    O \left(|z|\right) I_n \leq O \left(\frac{|z|}{\check \kappa_z}\right) I_n\leq  \left\vert \Lambda^z \right\vert\leq  O \left(\frac{|z|}{\check \kappa_z}\right) I_n\leq O \left(1 +|z|\right)I_n
    % \frac{|z|}{|z|+ \bar \nu}  I_n\leq \left\vert \frac{I_n}{I_n - D^z}\right\vert = \left\vert E^z+I_n\right\vert  \leq \left(1 + \frac{\bar \nu}{d(z,S_\varepsilon)}
% \right)I_n
% = \left\vert \frac{I_n}{I_n - D^z}\right\vert
 \end{align*}
  
\end{lemma}
\begin{proof}%[Proof of 
The inequalities provided in \eqref{eq:valeur_propre_module_matrice}, \eqref{eq:borne_module_formme_q} and Lemma~\ref{lem:Borne_resolvante} imply:
  \begin{align*}
    O(\check \kappa_z)\leq \inf_{i\in [n]} \Sp(\check Q^z) \leq |\diag(\check Q^z) | = |\diag_{i \in [n]}(e_i^T \check Q^ze_i) | \leq \sup_{i\in [n]} \Sp(\check Q^z) \leq O(\check \kappa_z)
  \end{align*}
  where $e_1,\ldots, e_n$ are the $n$ vectors of the canonical basis of $\mathbb R^n$ ($e_i \in \mathbb R^n$ is full of $0$ except in the $i ^{\textit{th}}$ entry where there is a $1$). One can then deduce the result of the lemma thanks to \eqref{eq:link_lambda_cQ}.
  % We can then deduce from  that: $\Lambda^z \geq \frac{|z|}{\|\check Q \|} \geq O(|z|)$. 
\end{proof}
Then to be able to neglect the dependence relation between $x_i$ and $X$ under $\mathcal A_Q$ we introduce the following lemma.
\begin{lemma}[Independence under $\mathcal A_Q$]\label{lem:independence_under_A_Q}
  Given two mappings $f: \mathbb R^p \to \mathcal M_{p}$ and $g: \mathcal M_{p,n} \to \mathcal M_{p}$ such that under $\mathcal A_Q$, $\|f(x_i)\|_F \leq O(\kappa_f)$ and $\|g(X_{-i})\| \leq O(\kappa_g)$, we can approximate:
  % Given two normed vector spaces $(E, \|\cdot\|_E)$, $(F, \|\cdot \|_F)$ and two mappings $f: \mathbb R^p \to E$ and $g: \mathcal M_{p,n} \to F$ such that under $\mathcal A_Q$, $\|f(x_i)\|_E \leq O(\kappa_f)$ and $\|g(X_{-i})\|_F \leq O(\kappa_g)$, we can approximate:
  \begin{align*}
    \left\Vert \mathbb E_{\mathcal A_Q}[f(x_i)g(X_{-i})] - \mathbb E_{\mathcal A_Q}[f(x_i)] \mathbb E_{\mathcal A_Q}[g(X_{-i})] \right\Vert_F \leq O \left(\kappa_f\kappa_g e^{-cn}\right),
  \end{align*}
  for some constant $c \geq O(1)$.
\end{lemma}
\begin{proof}
% \textcolor{red}{Ã  mettre dans l'annexe} 
Let us continue $\restriction{f}{x_i(\mathcal A_Q)}$ and $\restriction{g}{X_{-i}(\mathcal A_Q)}$ respectively on $\mathbb R^p$ and on $\mathcal M_{p,n}$ defining for any $x \in \mathbb R^p$ and $M \in \mathcal M_{p,n}$:
    \begin{align*}
      \tilde f(x) = \left\{
      \begin{aligned}
        &f(x) \ \ \text{if} \ x \in x_i(\mathcal A_Q)\\
        & \ \ 0 \ \ \ \text{otherwise}
        % &0 \ \ \text{if} \ x \notin x_i(\mathcal A_Q)
      \end{aligned}\right.&
      &\text{and}&
      &\tilde g(M) = \left\{
      \begin{aligned}
        &g(M) \ \ \text{if} \ M \in X_{-i}(\mathcal A_Q)\\
        & \ \ 0 \ \ \ \text{otherwise}
        % &0 \ \ \text{if} \ M \notin X_{-i}(\mathcal A_Q)
      \end{aligned}\right.&
    \end{align*}
    % for $\theta_M = \inf\{\theta \in \mathbb R_+ \ | \ \theta_M M \in X_{-i}(\mathcal A_Q)\}$ and $\theta_x$ is defined the same way.
    % Noting that for all $M \in X_{-i}(\mathcal A_Q)$ and $x \in x_i(\mathcal A_Q)$:
    % Now, we can bound thanks to Lemma~\ref{lem:Borne_resolvante}:
    % \begin{align*}
    %    \sup_{M \in \mathcal M_{p,n}}\|\tilde f(M)\| = \sup_{M \in X_{-i}(\mathcal A_Q)}\|f(M)\| \leq O(\kappa_z) ,
    %  \end{align*}
    %  and the same way $\sup_{x \in \mathbb R^p} \|\tilde g(x)\|_F \leq O( n)$, therefore, 
  Let us estimate:
  \begin{align*}%\label{eq:independance_sous_A_q}
      \mathbb E_{\mathcal A_Q} \left[  f(x_i) g(X_{-i})\right]
      &= \frac{\mathbb E \left[ \un_{X \in X(\mathcal A_Q)} f(x_i) g(X_{-i})\right]}{\mathbb P(\mathcal A_Q)}\\
      &= \mathbb E \left[ \un_{X \in X(\mathcal A_Q)} \tilde f(x_i) \tilde g(X_{-i}) \right] + \frac{1 - \mathbb P(\mathcal A_Q)}{\mathbb P(\mathcal A_Q)}\mathbb E \left[ \tilde f(x_i) \tilde g(X_{-i}) \un_{X \in X(\mathcal A_Q)} \right].
      % &= \frac{\mathbb E \left[ \tilde f(x_i) \tilde g(X_{-i}) \right]}{\mathbb P(\mathcal A_Q)}\\
  \end{align*} 
  the far right hand term cancels since $\mathcal A_Q$ has a probability bigger than $1 -Ce^{-cn}$ for some constants $C,c>0$:
  \begin{align*}
    \frac{1 - \mathbb P(\mathcal A_Q)}{\mathbb P(\mathcal A_Q)}\mathbb E \left[ \tilde f(x_i) \tilde g(X_{-i}) \un_{X \in X(\mathcal A_Q)} \right] \leq \frac{C e^{-cn}}{1 - C e^{-cn}} \mathbb E \left[ \left\vert \tilde f(x_i) \tilde g(X_{-i}) \right\vert\right] \leq O \left( \kappa_f \kappa_g e^{-cn} \right).
  \end{align*}
  % Noting that for all $\omega \in \Omega$, $\tilde f(x_i(\omega)) \tilde g(X_{-i}(\omega)) = \un_{\mathcal A_Q}(w) \tilde f(x_i(\omega)) \tilde g(X_{-i}(\omega))$
  For all $\omega \in \Omega$, we besides know that:
  \begin{align*}
     \un_{X \in X(\mathcal A_Q)}(w) = \un_{X(\omega) \in X(\mathcal A_Q)}(\omega) \leq \un_{x_i \in x_i(\mathcal A_Q)}(\omega) \un_{X_{-i} \in X_{-i}(\mathcal A_Q)}(\omega),
   \end{align*}
   and the inequality $\un_{\mathcal A_Q}(\omega) \neq \un_{x_i \in x_i(\mathcal A_Q)}(\omega) \un_{X_{-i} \in X_{-i}(\mathcal A_Q)}(\omega)$ only happens for $\omega \in \mathcal A_Q^c$. 
   % for $\omega \in \{X_{-i} \in X_{-i}(\mathcal A_Q)\} \subset \{\frac{1}{n}\|X_{-i}X_{-i}^T\| \leq \nu + \varepsilon\}$, which is a set of probability lower than $C'e^{-c'n}$, for some constants $c', C' >0$. 
  % \begin{align*}
  %   &\un_{X \in \mathcal A_Q}(w) \neq \un_{x_i \in x_i(\mathcal A_Q)}(w) \un_{X_{-i} \in X_{-i}(\mathcal A_Q}(w)
  %   &\Longrightarrow
  %   w \ \mathcal A_Q^c
  % \end{align*}
  We can then bound:
  \begin{align*}
    &\left\vert \mathbb E \left[ \left( \un_{X \in \mathcal A_Q} - \un_{x_i \in x_i(\mathcal A_Q)} \un_{X_{-i} \in X_{-i}(\mathcal A_Q}) \right) \tilde f(x_i) \tilde g(X_{-i})\right] \right\vert
    &\hspace{2cm}\leq \kappa_f \kappa_g \mathbb E \left[  \un_{\mathcal A_Q} \right] 
    % &\hspace{2cm}\leq  \mathbb E \left[ \left\vert \un_{X \in \mathcal A_Q} - \un_{x_i \in x_i(\mathcal A_Q)} \un_{X_{-i} \in X_{-i}(\mathcal A_Q}) \right\vert\kappa_f \kappa_g\right] \right\vert
    \leq O \left( \kappa_f \kappa_g e^{-cn} \right),
  \end{align*}
  which allows us to set\footnote{for $x_p,y_p \in \mathcal M_{p}$ and $(a_p)_{p \in \mathbb N} \in \mathbb R_+^{\mathbb N}$ the notation $x_p = y_p + O_{\|\cdot \|_F}(a_p)$ signifies that $\|x_p - y_p \|_F \leq O(a_p)$} thanks to the independence between $X_{-i}$ and $x_i$:
  \begin{align*}
    \mathbb E_{\mathcal A_Q} \left[  f(x_i) g(X_{-i})\right] 
      &= \mathbb E \left[ \un_{x_i \in x_i(\mathcal A_Q)} \tilde f(x_i) \un_{X_{-i} \in X_{-i}(\mathcal A_Q)}\tilde g(X_{-i}) \right] + O_{\|\cdot \|_F}( \kappa_f \kappa_g e^{-cn})\\
      & = \mathbb E \left[   \tilde f(x_i) \right]\mathbb E \left[ \tilde g(X_{-i}) \right] + O_{\|\cdot \|_F}( \kappa_f \kappa_g e^{-cn})\\
      &= \mathbb E_{\mathcal A_Q} \left[   f(x_i) \right]\mathbb E_{\mathcal A_Q} \left[  g(X_{-i}) \right] + O_{\|\cdot \|_F}( \kappa_f \kappa_g e^{-cn})
      % &=\mathbb E_{\mathcal A_Q} \left[  Q^z_{-i} \right] \mathbb E_{\mathcal A_Q} \left[x_ix_i^T \right] + O_{\|\cdot \|_F}( \kappa_z n e^{-cn}),
    \end{align*}
\end{proof}
 % and deduce:
 As it was done in Proposition~\ref{pro:concentration_resolvente_1}, one can show that $u^TQ_{-i}^zx_i$ and $u^TQ_{-i}^zx_i$ are both $\kappa_z$-Lipschitz transformations of $X \propto \mathcal E_2$ and deduce:
\begin{lemma}\label{lem:concentration_xQu}
  Given a deterministic vector $u \in \mathbb R^p$, we have the concentration:
  \begin{align*}
    u^TQ_{-i}^zx_i \ | \ \mathcal A_Q \in O(\kappa_z) \pm \mathcal E_2(\kappa_z)
    % &\text{and}&
    % &u^TQ_{}^zx_i \ | \ \mathcal A_Q \in O(\kappa_z) \pm \propto \mathcal E_2(\kappa_z)
  \end{align*}
\end{lemma} 
\begin{proof}
  As it was done in Proposition~\ref{pro:concentration_resolvente_1}, one can show that $u^TQ_{-i}^zx_i$ is a $\kappa_z$-Lipschitz transformations of $X \propto \mathcal E_2$ and deduce the concentration.
  % \begin{align*}
  %   u^TQ_{-i}^zx_i \ | \ \mathcal A_Q \propto \mathcal E_2(\kappa_z)
  %   % &\text{and}&
  %   % &u^TQ_{}^zx_i \ | \ \mathcal A_Q \propto \mathcal E_2(\kappa_z).
  % \end{align*}
  Besides, one can bound thanks to Lemma~\ref{lem:independence_under_A_Q} and our assumptions:
  \begin{align*}
    \left\vert \mathbb E_{\mathcal A_Q}[u^TQ_{-i}^zx_i ] \right\vert 
    &\leq \left\vert u^T \mathbb E_{\mathcal A_Q}[Q_{-i}]m_i \right\vert + O \left( \frac{\kappa_z}{n} \right) \leq O(\kappa_z)
    % \mathbb E_{\mathcal A_Q}[u^TQ^zx_i ] 
    % & =  \mathbb E_{\mathcal A_Q} \left[ \frac{zu^T Q_{-i}x_i}{\Lambda^z_i}  \right]\\
    % & =  \mathbb E_{\mathcal A_Q} \left[ \frac{zu^T Q_{-i}x_i}{\mathbb E_{\mathcal A_Q}[\Lambda^z_i]}  \right] + \\
    % & \leq O(\kappa_z)
  \end{align*}
  % Besides, one can bound under $\mathcal A_Q$, $\left\vert u^T Q_{-i}^zx_i \right\vert\leq O(\kappa_z)$ and:
\end{proof}
\begin{lemma}\label{lem:Q_m_i_proche_Q}
  Given $z \in \mathbb C \setminus S_{-0}^\varepsilon$, for all $i \in [n]$, $\|\mathbb E_{\mathcal A_Q}[Q^z -Q^z_{-i}]\| \leq O(\frac{\kappa_z}{n}  )$, the same way, one has $\|\mathbb E_{\mathcal A_Q}[|Q^z|^2 -|Q^z_{-i}|^2]\| \leq O(\frac{\kappa_z^2}{n}  )$.
\end{lemma}
\begin{proof}
  As we saw with Lemma~\ref{lem:independence_under_A_Q}, we can consider that under $\mathcal A_Q$, $X_{-i}$ and $x_i$ are almost independent. We now omit the exponent ``$z$'' on $Q$ and $Q_{-i}$ for simplicity.
  % Given a deterministic matrix $A \in \mathcal M_{p,n}$ such that $\|A\|_F \leq 1$, that allows us to bound thanks to the bound on $|\Lambda^z|$ given by Lemma~\ref{lem:Borne_Lambda}, the pseudo independence between $x_i$ and $Q_{-i}$ under $\mathcal A_Q$ given by Lemma~\ref{lem:independence_under_A_Q} and \eqref{eq:borne_module_formme_q}:
  Given two deterministic vectors $u,v \in \mathbb R^p$, we can deduce from Lemma~\ref{lem:concentration_xQu} and the estimation of the product of concentrated random variables given in Lemma~\ref{lem:borne_moment_produit_m_variables}:
  \begin{align*}
    \left\vert u^T\mathbb E_{\mathcal A_Q}[Q -Q_{-i}]v\right\vert
    &\leq \left\vert \mathbb E_{\mathcal A_Q} \left[\frac{u^TQ_{-i}x_i x_i^TQ_{-i}v}{n\Lambda_i}\right] \right\vert \\
    &\leq \frac{\check \kappa_z}{n|z|}\mathbb E_{\mathcal A_Q} \left[| u^TQ_{-i}x_i | | x_i^TQ_{-i}v |\right]
    \leq O \left( \frac{\check\kappa_z\kappa_z}{n|z|} \right) \leq O \left( \frac{\kappa_z}{n} \right).
    % &\hspace{1cm}\leq \left\vert \mathbb E_{\mathcal A_Q} \left[\frac{x_i^TQ_{-i}A Q_{-i}x_i}{n \mathbb E_{\mathcal A_Q}[\Lambda_i]}\right] \right\vert + \left\vert \mathbb E_{\mathcal A_Q} \left[\frac{x_i^TQ_{-i}A Q_{-i}x_i \left( \mathbb E_{\mathcal A_Q}[\Lambda_i] - \Lambda_ i \right)}{n \mathbb E_{\mathcal A_Q}[\Lambda_i] \Lambda_ i}\right] \right\vert\\
    % &\hspace{1cm}\leq \left\vert \mathbb E_{\mathcal A_Q} \left[\frac{\tr(Q_{-i}A Q_{-i}\Sigma_i)}{n \mathbb E_{\mathcal A_Q}[\Lambda_i]}\right] \right\vert +  \frac{ \check\kappa_z^2}{n|z|^2}    \sqrt { \mathbb E_{\mathcal A_Q} \left[ \left\vert \mathbb E_{\mathcal A_Q}[\Lambda_i] - \Lambda_ i \right\vert ^2 \right]\mathbb E_{\mathcal A_Q}\left[ (x_i^T|Q_{-i}A Q_{-i}|x_i)^2 \right]} \\
    % &\hspace{1cm}\leq \left\vert \mathbb E_{\mathcal A_Q} \left[\frac{\tr(Q_{-i}A Q_{-i}\Sigma_i)}{n \mathbb E_{\mathcal A_Q}[\Lambda_i]}\right] \right\vert + O \left( \frac{\kappa_z^2 \check\kappa_z^2}{|z|^2} \right)  \mathbb E_{\mathcal A_Q} \left[\left\vert \mathbb E_{\mathcal A_Q}[\Lambda_i] - \Lambda_ i \right\vert\right] \\
    % &\hspace{1cm}\leq \mathbb E_{\mathcal A_Q} \left[\frac{\check \kappa_z\tr \left( \Sigma_i Q_{-i}A Q_{-i} \right)}{n|z|}\right] \\
    % &\hspace{1cm}\leq \left\vert \mathbb E_{\mathcal A_Q} \left[\frac{1}{n |\hat \Lambda_i|}\left\vert x_i^TQ_{-i}A Q_{-i}x_i - \mathbb E_{\mathcal A_Q}[x_i^TQ_{-i}A Q_{-i}x_i]\right\vert\right]\right\vert \\
    % &\hspace{1cm}+ \left\vert \frac{1}{n}\mathbb E_{\mathcal A_Q} \left[\frac1{ \Lambda_ i }\right]\tr \left(\Sigma_i\mathbb E_{\mathcal A_Q} \left[x_i^TQ_{-i}A Q_{-i}x_i \right] \right)\right\vert
    % &\hspace{1cm}\leq O \left(\frac{\check\kappa_z\kappa_z^2}{|z|\sqrt n}\right)
    % \leq \ O \left(\frac{\kappa_z}{\sqrt n}\right),
  \end{align*}
  thanks to the formula $\kappa_z \check \kappa_z = \frac{|z|}{1+ |z|}$.
  % (we also use the fact that $\mathbb E_{\mathcal A_Q} [x_ix_i^T] = \Sigma_i \pm O_{\|\cdot \|_F}(Ce^{-cn})$ for some constant $c>0$). Now, we know from the Hanson-wright concentration inequality (Proposition~\ref{pro:concentration_lineaire_YAX}) that:
  % \begin{align*}
  %   x_i^T|Q_{-i}A Q_{-i}|x_i \ | \ X_{-i} \propto \mathcal E_2(\kappa_z^2) + \mathcal E_1(\kappa_z^2),
  % \end{align*}
  % thus, since $\mathbb E_i[x_i^T|Q_{-i}A Q_{-i}|x_i] = \tr \left( \Sigma_i |Q_{-i}A Q_{-i}|\right) \leq \kappa_z^2 \sqrt n$, we can bound thanks to the moment characterization of concentrated random variables given in Proposition~\ref{pro:carcterisation_ac_moments_conc_q_expo} :
  % \begin{align*}
  %   \mathbb E_{i,\mathcal A_Q}\left[ (x_i^T|Q_{-i}A Q_{-i}|x_i)^2 \right] \leq \kappa_z^4 n
  % \end{align*}
  % One can eventually bound:
  % \begin{align*}
  %   &\left\vert \tr \left(A \mathbb E_{\mathcal A_Q}[Q -Q_{-i}]\right)\right\vert 
  %   \leq O \left(\frac{\check\kappa_z\kappa_z^2}{|z|\sqrt n}\right) + O \left(\frac{\check\kappa_z^2\kappa_z^3}{|z|^2\sqrt n}\right)
  %   \leq \ O \left(\frac{\kappa_z}{\sqrt n}\right)
  % \end{align*}

   For the difference of the squares, let us bound with the same justifications:
  \begin{align*}
    &\left\vert u^T \mathbb E_{\mathcal A_Q}[|Q|^2-|Q_{-i}|^2]v\right\vert = \left\vert u^T \mathbb E_{\mathcal A_Q}[\bar Q Q-  \bar Q_{-i}Q_{-i}]v\right\vert\\
    &\hspace{1cm}= \left\vert\mathbb E_{\mathcal A_Q} \left[\frac{u^TQ_{-i}x_i x_i^T\bar QQ_{-i}v}{n\Lambda_i}\right]\right\vert + \left\vert\mathbb E_{\mathcal A_Q} \left[\frac{u^T \bar Q_{-i}Q_{-i}x_i x_i^T\bar Q_{-i}v}{n\Lambda_i}\right]\right\vert \\
    % &\hspace{1cm}= \left\vert\mathbb E_{\mathcal A_Q} \left[\frac{x_i^TQ_{-i}A |Q_{-i}|^2 x_i}{n\Lambda_i}\right]\right\vert +  \left\vert\mathbb E_{\mathcal A_Q} \left[\frac{x_i^TQ_{-i}A \bar Q_{-i} x_ix_i^T |Q_{-i}| x_i}{n^2|\Lambda_i|^2}\right]\right\vert + O \left(\frac{\kappa_z^2}{\sqrt n}\right) \\
    &\hspace{1cm}\leq O \left(\frac{\check\kappa_z\kappa_z^3}{|z| n}\right)
    \leq \ O \left(\frac{\kappa_z^2}{n}\right),
  \end{align*}
   % and that for $n\geq p$, $\kappa_z \leq |z|$ and for $n<p$, $|z| \geq O(1)$ because $0 \in $
\end{proof}
\begin{proof}[Proof of Lemma~\ref{lem:lambda_lambda_hat_proche}]
The proof of the concentration of $\Lambda^z$ was already presented before the lemma. We are just left to bound:
\begin{align}\label{eq:borne_hlambda_Elambda}
  &\left\Vert \hat \Lambda^z - \mathbb E_{\mathcal A_Q}[\Lambda^z]\right\Vert \nonumber \\
  % &\hspace{1cm}\leq \sqrt{n} \left\Vert \hat \Lambda^z - \mathbb E_{\mathcal A_Q}[\Lambda^z]\right\Vert\nonumber\\
  &\hspace{1cm}\leq \frac{1}{n}\sup_{i\in [n]} \left( \left\vert \tr \left(\Sigma_i \mathbb E_{\mathcal A_Q}[Q - Q_{-i}] \right)\right\vert + \left\vert \tr \left((\Sigma_i- \mathbb E_{\mathcal A_Q}[x_ix_i^T]) \mathbb E_{\mathcal A_Q}[Q_{-i}] \right)\right\vert \right.\nonumber\\
  &\hspace{1cm}\left.+ \left\vert  \tr \left(\mathbb E_{\mathcal A_Q} \left[x_i x_i^T\right]\mathbb E_{\mathcal A_Q}[Q_{-i}] -\mathbb E_{\mathcal A_Q}[x_ix_i^T Q_{-i}]\right)\right\vert \right)\ \
  \leq  \ O \left(\frac{\kappa_z}{n} \right)
\end{align}
with the same arguments as in the proof of Lemma~\ref{lem:Q_m_i_proche_Q}.
\end{proof}
One can directly deduce from the concentration of $\Lambda^z$ and Lemma~\ref{lem:Borne_Lambda} a bound on its expectation $\hat \Lambda^z$.
\begin{lemma}\label{lem:Borne_Lambda_hat}
  % In the set of symmetric matrices, we have the inequality 
  Given $z \in \mathbb C \setminus S_{-0}^\varepsilon$: %$O \left(\frac{|z|}{1 +|z| }\right)I_n \leq |\check Q^z| \leq O \left(1\right)I_n$
  % \begin{align*}
  %   O \left(\frac{1}{1 +|z| }\right)I_n \leq |\check Q^z| \leq O \left(\frac{1}{1 +|z| }\right)I_n
  % \end{align*}
  % $\frac{I_p}{|z|^2 + \bar\nu^2} \leq |\check Q^z|^2 \leq \frac{I_p}{d(z,S_\varepsilon)^2}$ 
  % and:
  \begin{align*}
    O \left(|z|\right) I_n \leq O \left(\frac{|z|}{\check \kappa_z}\right) I_n\leq \left\vert \hat \Lambda^z  \right\vert\leq  O \left(\frac{|z|}{\check \kappa_z}\right)I_n\leq O \left(1 +|z|\right)I_n
    % \frac{|z|}{|z|+ \bar \nu}  I_n\leq \left\vert \frac{I_n}{I_n - D^z}\right\vert = \left\vert E^z+I_n\right\vert  \leq \left(1 + \frac{\bar \nu}{d(z,S_\varepsilon)}
% \right)I_n
% = \left\vert \frac{I_n}{I_n - D^z}\right\vert
 \end{align*}
  
\end{lemma}
\begin{proof}%[Proof of Lemma~\ref{lem:Borne_Lambda_hat}]
One already know from Lemma~\ref{lem:Borne_Lambda} that $O \left(\frac{|z|}{\check \kappa_z}\right) \leq \left\vert \Lambda^z  \right\vert\leq  O \left(\frac{|z|}{\check \kappa_z}\right)$ then it suffices to bound thanks to \eqref{eq:borne_hlambda_Elambda}: $\left\Vert \hat \Lambda^z - \mathbb E_{\mathcal A_Q} [\Lambda^z]\right\Vert \leq O \left(\frac{\kappa_z}{n}  \right) \leq O \left(\frac{|z|}{n\check \kappa_z}\right)$.
\end{proof}
% Let us add a simple corollary that will be of multiple use since $\Lambda_i^z$ is generally appearing in the denominator.
% \begin{corollary}\label{cor:concentration_1_s_Lambda}
%   % Given $i \in [n]$ and 
%   Given $z \in \mathbb C \setminus S^\varepsilon_{-0}$:
%   \begin{align*}
%     \frac{1}{\Lambda_i^z} \ | \ \mathcal A_Q \in \frac{1}{\hat \Lambda_i^z} \pm \mathcal E_2 \left( \frac{\check \kappa_z}{\sqrt n|z|} \right)&
%     &\text{in}&
%     &(\mathcal D_n, \|\cdot\|_F).
%   \end{align*}
%   % and $\|\mathbb E_{\mathcal A_Q}[\frac{1}{\Lambda_i^z}] - \frac{1}{\hat \Lambda_i^z} \|_F \leq O \left( \frac{\check \kappa_z}{\sqrt n|z|} \right)$
% \end{corollary}
% \begin{proof}
%   The concentration is just a consequence of identity~\ref{eq:link_lambda_cQ} and the concentration of $\check Q^z$ given in Proposition~\ref{pro:concentration_resolvente_1}. 
%   We can further bound for any deterministic diagonal matrix $D \in \mathcal{M}_{n}$ such that $\|D\|_F \leq 1$:
%   % We can further bound thanks to the concentration of $\Lambda^z$ given by Lemma~\ref{lem:Concentration_lambda}, the bounds given in lemma:
%   \begin{align*}
%     \left\vert \tr \left( D \left( \mathbb E_{\mathcal A_Q} \left[ \frac{1}{\Lambda^z}  \right] - \frac{1}{\hat \Lambda^z} \right) \right)  \right\vert
%     &\leq \sqrt{\sum_{i=1}^n \left( \mathbb E_{\mathcal A_Q} \left[  \frac{|D_i|\left\vert \Lambda^z_i - \mathbb E_{\mathcal A_Q}[ \Lambda^z_i] \right\vert}{\left\vert \Lambda^z_i\mathbb E_{\mathcal A_Q}[ \Lambda^z_i] \right\vert}  \right] \right)^2 } + \left\Vert \frac{\mathbb E_{\mathcal A_Q}[\Lambda^z] - \hat \Lambda^z}{\mathbb E_{\mathcal A_Q}[\Lambda^z]\hat \Lambda^z}  \right\Vert_F  \\
%     &\leq \sqrt{\sum_{i=1}^n \mathbb E_{\mathcal A_Q} \left[\left(  D_i \frac{\Lambda^z_i - \mathbb E_{\mathcal A_Q}[ \Lambda^z_i]}{\Lambda^z_i\mathbb E_{\mathcal A_Q}[ \Lambda^z_i]}   \right)^2\right] } + O \left( \frac{\kappa_z\check \kappa_z^2}{|z|^2 \sqrt n} \right) \leq O \left( \frac{\check \kappa_z}{|z| \sqrt n} \right),
%     &\leq O \left( \frac{\check \kappa_z^2}{|z| \sqrt n} \right) + O \left( \frac{\kappa_z\check \kappa_z^2}{|z|^2 \sqrt n} \right) \leq O \left( \frac{\check \kappa_z}{|z| \sqrt n} \right),
%   \end{align*}
%   thanks to Lemma~\ref{lem:concentration_lambda_norm_frobenius}, \ref{lem:Borne_Lambda}, \ref{lem:lambda_lambda_hat_proche} and~\ref{lem:Borne_Lambda_hat}.
% \end{proof}
We can now prove the main result of this subsections that allows us to set that $\tilde Q^{\hat \Lambda^z}$ is a deterministic equivalent of $Q^z$ (thanks to Lemma~\ref{lem:diametre_observable_pivot}).
\begin{proposition}\label{pro:borne_EQ_m_tQ}
  % There exist a constant $C>0$ such that:
  Given $z\in \mathbb C \setminus S_{-0}^\varepsilon$:
  \begin{align*}
     \left\Vert \tilde Q^{\hat \Lambda^z}\right\Vert \leq O(\kappa_z)&
    % O(1) \leq \tilde Q^{z} \left(\frac{I_n}{I_n - \Delta^z}\right) \leq O(1)&
    &\text{and}&
    &\left\Vert \mathbb{E}_{\mathcal A_Q}[Q^z] - \tilde Q^{\hat \Lambda^z} \right\Vert_F \leq  O \left(\frac{\kappa_z}{\sqrt{n}} \right).
  \end{align*}
\end{proposition} 
% To prove this proposition, we will need several results. First 
To prove this proposition, we will bound the different elements of the decomposition \eqref{eq:definition_epsilon_1_2}. To bound $\varepsilon_1$, we will need the following lemma. The concentration is quit sharp since we have:
\begin{align*}
  \min(\kappa_z, \check \kappa_z) = \kappa_z \check \kappa_z = \frac{|z|}{1+|z|}
\end{align*}
% Let us provide below some chosen properties taken from \ref{} that will be useful later
% the following lemma:
\begin{lemma}\label{lem:concentration_QX_s_z}
  Given $z \in \mathbb C \setminus S_{-0}^\varepsilon$, under $\mathcal A_Q$,
   % $\|\frac{1}{z\sqrt n}Q^z X \| \leq O(1)$ and:
  \begin{align*}
    Q^z X =  X^T \check Q^z \ |\ \mathcal A_Q \propto \mathcal E_2 \left( \frac{|z|}{1+|z|} \right)
    % &\text{and}&
    % &\frac{1}{z\sqrt n} X^T \check Q^z\propto \mathcal E_2 \left(\frac{1}{\sqrt n}\right)  
  \end{align*}
  and $\forall i \in [n]$, $\|\mathbb E_ {\mathcal A_Q}[Q^zx_i]\| \leq O \left( \frac{|z|}{1+|z|} \right)$. 
\end{lemma}
\begin{proof}
  % We already know that $\frac{X}{}$hen $p \leq n$, we know that $$
  We follow the steps of the proof of Proposition~\ref{pro:concentration_resolvente_1}. Depending on the sign of $p-n$, it is more convenient to work with the expression $Q^z X$ (when $p\leq n$) or with $ X^T \check Q^z$ (when $p\geq n$). 
  We just treat here the case $p\leq n$ and therefore look at the variations of the mapping $\Psi : \mathcal M_{p,n} \to \mathcal M_{p, n}(\mathbb C)$ defined as:
  \begin{align*}
     \Psi(M) =  \frac{1}{z }\left(I_p - \frac{MM^T}{zn}\right)^{-1} M.
     % &\text{and}&
     % &\check \Phi(M) =  \left(I_n - \frac{M^TM}{zn}\right)^{-1},
   \end{align*}
   to show the concentration of $Q^z X  = \Psi(X)$. %(when $p\geq n$ we rather start from the expression $\frac{1}{z\sqrt n}X^T \check Q^z $, but we leave this part of the proof for the reader since it is rigourously analog).
   % it is sufficient to show that $\Phi$ and $\check \Phi$ are $O(1/\sqrt n)$-Lipschitz on $\mathcal M_{n,p}^{\mathcal A_Q} \equiv X(\mathcal A_Q)$\footnote{$\mathcal M_{n,p}^{\mathcal A_Q} \subset \{ M \in \mathcal M_{n,p}, \frac{1}{n}\|MM^T\| \leq 1 -\varepsilon \}$}. For any $M \in \mathcal M_{n,p}^{\mathcal A_Q}$ and any $H \in \mathcal M_{p,n}$, $\|M\|\leq O((\nu + \varepsilon) \sqrt n)$ and:
   For all $H, M \in \mathcal M_{n,p}^{\mathcal A_Q} \equiv X(\mathcal A_Q)$ (and with the notation $\Phi(M) = \left(I_p - \frac{MM^T}{zn}\right)^{-1} $ given in the proof of Proposition~\ref{pro:concentration_resolvente_1}):
  \begin{align*}
    \|\restriction{d\Psi }{M} \cdot H\| 
    & \leq \left\Vert \Psi \left(M\right)\frac{1}{nz}(MH^T + HM^T) \Psi \left(M\right) M\right\Vert + \left\Vert \Psi \left(M\right)H\right\Vert\\
    &\leq O \left(\frac{|z|\|H\|}{(1+|z|)^ 2}\right) + O \left(\frac{|z|\|H\|}{1+|z|}\right) \leq O \left(\kappa_z\check\kappa_z\|H\|\right).
  \end{align*}
  Thus, under $\mathcal A_Q$, $\Psi$ is $O(\kappa_z\check\kappa_z)$-Lipschitz (for the Frobenius norm) and therefore $Q^zX \propto \mathcal E_2(\kappa_z\check\kappa_z)$. 

  To control the norm of $ \mathbb E_{\mathcal A_Q}[Q^z x_i]$, let us employ Schur identities~\eqref{eq:lien_q_qj_schur} and bound for any deterministic $u \in \mathbb R^p$ such that $\|u\|\leq 1$:
  \begin{align*}
    \left\vert \mathbb E_{\mathcal A_Q}[u^TQ^z x_i] \right\vert
    = |z|\left\vert \mathbb E_{\mathcal A_Q} \left[ \frac{ u^TQ_{-i}^z x_i}{\Lambda_i^z} \right] \right\vert
    \leq |z| \mathbb E_{\mathcal A_Q}[ |u^TQ_{-i}^z x_i|]\frac{\check \kappa_z}{|z|} \leq O(\kappa_z\check \kappa_z),
  \end{align*}
  thanks to Lemmas~\ref{lem:concentration_xQu} and~\ref{lem:Borne_Lambda}.% and Corollary~\ref{cor:concentration_1_s_Lambda} to obtain:
  % (). Then, we apply Lemma~\ref{lem:borne_moment_produit_m_variables} to the concentrations given by Lemma~\ref{lem:concentration_xQu} and Corollary~\ref{cor:concentration_1_s_Lambda} to obtain:
  % \begin{align*}
  %   \left\vert \mathbb E_{\mathcal A_Q}[u^TQ^z x_i] \right\vert
  %   = |z|\left\vert \frac{ \mathbb E_{\mathcal A_Q}[u^TQ_{-i}^z x_i]}{\hat \Lambda_i^z} \right\vert + O \left( \frac{ |z| \kappa_z \check \kappa_z}{|z| \sqrt n} \right) 
  %   \leq O \left( \frac{ \kappa_z \check \kappa_z }{\sqrt n} \right)
  % \end{align*}
\end{proof}
% Finally to be able to bound $\delta_1$, we will need:
% \begin{lemma}\label{lem:independance_conditrionnee}
%   Given two mappings
% \end{lemma}
 \begin{proof}[Proof of Proposition~\ref{pro:borne_EQ_m_tQ}]
 Let us note for simplicity $\kappa_{\tilde Q} \equiv \|\tilde Q^{\hat \Lambda^z}\|$.
  % With the notation introduced in \eqref{eq:definition_epsilon_1_2}, note that we have to bound $\|\mathbb E_{\mathcal A_Q}[\varepsilon_1] \|_F$ and $\|\mathbb E_{\mathcal A_Q}[\varepsilon_2]\|_F$. 
  Looking at decomposition \eqref{eq:definition_epsilon_1_2} we can start with the bound:% thanks to Proposition~\ref{pro:estimation_XDY}:
  \begin{align*}
     \|\varepsilon_1 \|_F = \left\Vert \frac{1}{zn} \mathbb{E}_{\mathcal A_Q}\left[Q^zX \left(\hat \Lambda^z - \Lambda^z\right)(\hat \Lambda^z)^{-1}X^T \right]\tilde{Q}^{\Lambda^z}\right\Vert_F \leq O \left(\frac{\kappa_ {\tilde Q} \kappa_z^2\check\kappa_z^2}{|z|^2\sqrt{n}}\right)\leq O \left(\frac{\kappa_ {\tilde Q}}{\sqrt{n}}\right)
   \end{align*}
   obtained with the bound $\frac{1}{\hat \Lambda^z} \leq O(\frac{\check \kappa_z}{|z|})\leq O(1)$ given by Lemma~\ref{lem:Borne_Lambda_hat} and applying Proposition~\ref{pro:estimation_XDY} with the hypotheses:
   \begin{itemize}
      \item $X \ | \ \mathcal A_Q \propto \mathcal E_2$ and $\|\mathbb E_{\mathcal A_Q}[x_i]\| \leq O(1)$ Assumption~\ref{ass:concentration_X},
      \item $Q^zX \ | \ \mathcal A_Q \propto \mathcal E_2(\kappa_z\check\kappa_z) $ and $\|\mathbb E_{\mathcal A_Q}[Q^zx_i]\|\leq O(\kappa_z\check\kappa_z)$ given by Lemma~\ref{lem:concentration_QX_s_z},
      \item $ \Lambda^z \ | \ \mathcal A_Q\in \mathbb E_{\mathcal A_Q}[\Lambda^z] \pm \mathcal E_2 \left(\frac{\kappa_z}{\sqrt n}\right)$ in $(\mathcal{D}_{n}, \| \cdot \|)$ given by Lemma~\ref{lem:Concentration_lambda},
      \item $\|  \mathbb E_{\mathcal A_Q}[\Lambda^z] - \hat \Lambda^z\|_F \leq O(\kappa_z/\sqrt n)$ thanks to Lemma~\ref{lem:lambda_lambda_hat_proche}
      % \item $|\hat \Lambda_i^z| \geq O(|z|/\check \kappa_z)$ given by Lemma~\ref{lem:Borne_Lambda_hat},
    \end{itemize}
    % and bounding thanks to .
  Second, for any matrix $A\in \mathcal{M}_p(\mathbb C)$ satisfying $\|A\|_F \leq 1$, let us bound thanks to Cauchy-Schwarz inequality:
  \begin{align*}
    \left\vert \mathbb \tr(A\varepsilon_2) \right\vert
    &\leq\sqrt{\frac{1}{|z|^2n^2} \mathbb{E}_{\mathcal A_Q}\left[\tr \left(AQ^z X |\hat \Lambda^z_n |^{-2} X^T\bar Q^z \bar A^T\right) \right]}\\
    &\hspace{1cm}\cdot \sqrt{\frac{1}{n^2}\sum_{i=1}^n \mathbb{E}_{\mathcal A_Q}\left[\tr \left(\tilde{Q}^{\hat \Lambda^z}\Sigma_ i Q_{-i}^zx_ix_i^T Q_{-i}^z \Sigma_i\bar{\tilde{Q}}^{\hat \Lambda^z}\right)\right]} \\
    &\leq O \left(\frac{\kappa^4_z \check \kappa_z^4}{|z|^2}\sqrt{\frac{\|A\|_F^2 }{ n}\frac{ \sup_{i\in[n]}\tr \left(\Sigma_i^3\right) \kappa_{\tilde Q}^2 }{ n}}\right) \leq O \left(\frac{\kappa_{\tilde Q}}{\sqrt n}\right)
    \end{align*}
    thanks to the bounds provided by our assumptions, and Lemmas~\ref{lem:Borne_resolvante},~\ref{lem:Borne_Lambda_hat} and~\ref{lem:concentration_QX_s_z}. 

    Third, we bound easily with Lemma~\ref{lem:independence_under_A_Q} the quantity:
    \begin{align*}
      \left\Vert \tr(A\delta_1) \right\Vert 
      &\equiv \frac{1}{n}\sum_{i=1}^n
      \frac{1}{|\hat \Lambda^z _i|} \left\Vert \tr \left( \tilde{Q}^{\hat \Lambda^z}  A \mathbb E_{\mathcal A_Q} \left[Q^z_{-i} x_ix_i^T \right]\right) \right. \\
      &\hspace{2.3cm} \left.- \tr \left(\tilde{Q}^{\hat \Lambda^z}  A\mathbb E_{\mathcal A_Q} \left[Q^z_{-i}\right] \mathbb E_{\mathcal A_Q} \left[ x_ix_i^T\right]\right)\right\Vert \leq O \left(\frac{\kappa_{\tilde Q}}{\sqrt n}\right).
    \end{align*}
    And we can bound $\left\Vert \tr(A\delta_2) \right\Vert \leq O \left(\frac{\kappa_{\tilde Q}}{n}\right)$ since $\|\Sigma_i - \mathbb E_{\mathcal A_Q}[x_ix_i^T]\| \leq O(\frac{1}{n}) $ (as explained in the proof of Lemma~\ref{lem:Q_m_i_proche_Q}).


    Taking the supremum on $A \in \mathcal M_{p,n}(\mathbb C)$ and putting the bounds on $\left\Vert \varepsilon_1 \right\Vert_F$, $\left\Vert \varepsilon_2 \right\Vert_F$, $\left\Vert \delta_1 \right\Vert_F$ and $\left\Vert \delta_2 \right\Vert_F$ together, we obtain:
    \begin{align*}
      \left\Vert \mathbb{E}_{\mathcal A_Q} \left[Q^z\right] - \tilde Q^{\hat \Lambda^z} \right\Vert_ F \leq O \left(\frac{\kappa_{\tilde Q}}{\sqrt{n}}\right)
    \end{align*}
    So, in particular $\kappa_{\tilde Q} \equiv\left\Vert \tilde Q^{\hat \Lambda^z} \right\Vert \leq  \left\Vert \mathbb{E}_{\mathcal A_Q} \left[Q^z\right] \right\Vert + O \left(\frac{\kappa_{\tilde Q}}{\sqrt{n}}\right)$,
    % \begin{align*}
    %   \kappa_{\tilde Q} \equiv\left\Vert \tilde Q^{\hat \Lambda^z} \right\Vert \leq  \left\Vert \mathbb{E}_{\mathcal A_Q} \left[Q^z\right] \right\Vert + O \left(\frac{\kappa_{\tilde Q}}{\sqrt{n}}\right),
    % \end{align*}
    which implies that $\kappa_{\tilde Q} \leq O(\kappa_z)$ as $\Vert \mathbb{E}_{\mathcal A_Q} \left[Q^z\right] \Vert$ since $\frac{1}{\sqrt n} = o(1)$. We obtain then directly the second bound of the proposition.
    % We obtain then directly $\left\Vert \mathbb{E}_{\mathcal A_Q}Q^z - \tilde Q^{z} \left(\frac{I_n}{I_n - \Delta^z}\right) \right\Vert_ F \leq O \left(N_{\tilde Q}\sqrt{\frac{\log n}{n}}\right)$ and $\tilde Q^{z} \left(\frac{I_n}{I_n - \Delta^z}\right) \geq \mathbb{E}_{\mathcal A_Q}Q^z  + O \left(N_{\tilde Q}\sqrt{\frac{\log n}{n}}\right)$.
\end{proof}













































% \subsection{A second deterministic equivalent}
\subsection{Definition of the second deterministic equivalent thanks to the semi-metric $d_s$}

Proposition~\ref{pro:borne_EQ_m_tQ} slightly simplified the problem because while we initially had to estimate the expectation of the whole matrix $Q^z$, now, we just need to approach the diagonal matrix $\hat \Lambda^z \equiv \diag(z - \frac{1}{n}\tr \left( \Sigma_i Q_{-i}^z \right)])_{i \in [n]}$. 
One might be tempted to introduce from the pseudo identity (where $\tilde Q$ was defined in \eqref{eq:definition_of_tilde_Q}):
\begin{align}\label{eq:fixed_point_equation_Delta}
  \hat \Lambda_i^z 
  = z-  \frac{1}{n} \tr(\Sigma_i \mathbb E_{\mathcal A_Q} [Q^{z}])
  \approx z-  \frac{1}{n} \tr(\Sigma_i \tilde Q^{\hat \Lambda^z})
  % \approx \frac{1}{n} \tr \left(\Sigma_i\tilde Q^z_{-i} \left(\frac{I_n}{I_n - \Delta^z}\right)\right)\approx \frac{1}{n} \tr \left(\Sigma_i\tilde Q^z \left(\frac{I_n}{I_n - \Delta^z}\right)\right) ,
\end{align}
% (where, $\tilde Q^z_{-i}(\Gamma) = (zI_p - \frac{1}{n} \sum_{\genfrac{}{}{0pt}{2}{1\leq j\leq n}{j \neq i}} \Gamma_j \Sigma_j)^{-1}$)
a fixed point equation whose solution would be a natural estimate for $\hat \Lambda^z$. This equation is given in Theorem~\ref{the:definition_existence_tilde_Lambda}: we chose $\tilde \Lambda^z$ satisfying
\begin{align*}
  \tilde \Lambda_i^z = z - \frac{1}{n} \tr \left(\Sigma_i \tilde Q^{\tilde \Lambda^z}\right).
\end{align*}
We are now going to prove that $\tilde \Lambda^z$ is well defined for any $z \in \mathbb H$ (where we recall that $\mathbb H \equiv \{z \in \mathbb C, \Im(z) >0\}$) to prove Theorem~\ref{the:definition_existence_tilde_Lambda}.
Introducing the mapping:
\begin{align*}
  % \tilde Q_{-i}^z(D) \equiv \left(zI_p-\frac{1}{n}\sum_{j=1}^n \frac{\Sigma_j}{1- D_j} \right)^{-1}&
  % &\text{and}&
  \forall L \in \mathcal D_n(\mathbb H): \  \mathcal I^z(L) \equiv zI_ n - \diag \left(\frac{1}{n}\tr\left(\Sigma_i \tilde Q^L)\right)  \right)_{1\leq i \leq n},
\end{align*}
we want to show that $\mathcal I^z$ admits a unique fixed point.
For that purpose, we are going to employ the Theorem~\ref{the:fixed_point_theorem} on the mapping $ \mathcal I^z$ ($z \in \mathbb H$), that is, as we will see in Proposition~\ref{pro:I_z_contractante} below, contractive for semi-metric $d_s$ presented in last chapter and defined for any $D, D' \in \mathcal D_n(\mathbb H)$ as:
\begin{align*}
  d_s(D,D') = \sup_{1\leq i \leq n} \frac{|D_i- D_i'|}{\sqrt{\Im(D_i) \Im(D_i')}}.
\end{align*}
We first need to restrict our study on a subset of $\mathcal D_n(\mathbb H)$:
\begin{align*}
  \mathcal D_{I^z} \equiv \left\{ D \in \mathcal D_n(\mathbb H),  D/z \in \mathcal D_n(\mathbb H) \right\}
\end{align*}
\begin{lemma}\label{lem:J_stable_sur_DJ}
  % There exists a constant $0< K \leq O(1)$ such that for any $z \in \mathbb H$:
  % \begin{align*}
    For any $z \in \mathbb H$, $\mathcal I^z(\mathcal D_{\mathcal I^z} ) \subset \mathcal D_{\mathcal I^z} $.
  % \end{align*}
\end{lemma}
% Note in particular that we do not need any threshold restriction on the values of $z$ ($ \Im(z)$ just needs to be positive but the conjugate of the satement is also valid and we can then extend the study to the $\mathbb R$ axis with continuity arguments).
% {\color{red} no commutation !!
\begin{proof}
  \sloppypar{Considering $z \in \mathbb H$, and $L \in \mathcal D_ {\mathcal I^z}$ and $i\in [n]$, the decomposition $\tilde Q^L = \left( I_p - \frac{1}{n}\sum_{i=1}^n \frac{\Re(L_j)\Sigma_i}{|L_j|^2} - \frac{i}{n} \sum_{i=1}^n \frac{\Im(L_j)\Sigma_i}{|L_j|^2} \right)^{-1}$ allows us to set thanks to the resolvent identity~\eqref{eq:resolvent_identity}:}
  \begin{align*}
    \Im \left(\mathcal I^z \left(L\right)_i\right) 
    &= \Im(z) + \frac{1}{2in}\tr\left(\Sigma_i \left( \tilde Q^L + \bar{\tilde Q}^L \right) \right)\\
    &= \Im(z) + \frac{1}{n}\tr\left(\Sigma_i \tilde Q^L \sum_{i=1}^n \frac{\Im(L_j)\Sigma_i}{|L_j|^2} \bar {\tilde Q}^L \right) >0
  \end{align*}
  (since $\bar {\tilde Q}^L\Sigma_i \tilde Q^L$ is a non negative Hermitian matrix).
  The same way, one can show:
  \begin{align*}
    \Im \left(\mathcal I^z \left(L\right)_i/z\right) = \frac{1}{n|z|^2}\tr\left(\Sigma_i \tilde Q^L \left(\Im(z) + \sum_{i=1}^n \frac{\Im(L_j/z)\Sigma_i}{|L_j/z|^2} \right)\bar {\tilde Q}^L \right)> 0
  \end{align*}
\end{proof}

Let us now express the Lipschitz parameter of $\mathcal I^z$ for the semi metric $d_s$.
\begin{proposition}\label{pro:I_z_contractante}
  For any $z \in \mathbb H$, the mapping $\mathcal I^z$ is $1$-Lipschitz for the semi-metric $d_s$ on $\mathcal D_{\mathcal I^z}$ and satisfies for any $L,L' \in \mathcal D_{\mathcal I^z}$:
  \begin{align*}
    d_s(\mathcal I^z(L), \mathcal I^z(L') )
    \leq \sqrt{(1-\phi(z,L))(1-\phi(z,L'))} d_s(L, L' ),
    %\left(1 - \frac{-\Im(z)^3}{2|z|^2 + 4 \sup_{1\leq i\leq n} \|\Sigma_i\|}\right)
  \end{align*}
  where for any $w \in \mathbb H $ and $L \in\mathcal D_{\mathcal I^z}$:
  \begin{align*}
    \phi(w,L) =     \frac{\Im(w)}{\sup_{1\leq i \leq n}\Im(\mathcal I^w(L))_i} \in (0,1).
  \end{align*}
\end{proposition}
\begin{proof}
  Let us bound for any $L,L' \in \mathcal D_{\mathcal I^z}$:
  \begin{align}\label{eq:borne_lipschitz_I^z}
    \left\vert \mathcal I^z(L)_i - \mathcal I^z(L')_i \right\vert
    &= \frac{1}{n}\tr\left(\Sigma_i \tilde Q^L \left(\frac{1}{n}\sum_{j=1}^n \frac{ L_j - L'_j}{L_j L'_j}\Sigma_j  \right)\bar{\tilde Q}^{L'}\right) \nonumber \\
    &= \frac{1}{n}\tr\left(\Sigma_i \tilde Q^L \left(\frac{1}{n}\sum_{j=1}^n \frac{ L_j - L'_j}{\sqrt{\Im(L_j)\Im(L'_j)}}\frac{\sqrt{\Im(L_j)\Im(L'_j)}}{L_j L'_j}\Sigma_j  \right)\bar{\tilde Q}^{L'}\right) \nonumber \\
    &\leq d_s(L,L') \sqrt{\frac{1}{n}\tr\left(\Sigma_i \tilde Q^L \left(\frac{1}{n}\sum_{i=1}^n \frac{\Im(L_j)\Sigma_i}{|L_j|^2}\right)\bar {\tilde Q}^L\right)}\nonumber\\
    &\hspace{2.5cm}\cdot \sqrt{\frac{1}{n}\tr\left(\Sigma_i \bar {\tilde Q}^{L'} \left(\frac{1}{n}\sum_{i=1}^n \frac{\Im(L_j')\Sigma_i}{|L_j'|^2}\right)\tilde Q^{L'}\right) } \nonumber\\
    & \leq d_s(L,L') \sqrt{\left(\Im(\mathcal I^z(L)_i) - \Im(z)\right)(\Im(\mathcal I^z(L')_i) - \Im(z))},
  \end{align}
  thanks to Cauchy-Schwarz inequality and the identity
  \begin{align*}%\label{eq:identite_I_im_z_2}
    0 \leq \frac{1}{n}\tr\left(\Sigma_i \tilde Q^L\left(\sum_{i=1}^n \frac{\Im(L_j')\Sigma_i}{|L_j'|^2}\right)\bar{\tilde Q}^z(L) \right) = \Im(\mathcal I^z(L)_i) - \Im(z)
  \end{align*}
  issued from the proof of Lemma~\ref{lem:J_stable_sur_DJ}.
  Dividing both sides of \eqref{eq:borne_lipschitz_I^z} by $\sqrt{\Im(\mathcal I^z(L)_i)\Im(\mathcal I^z(L')_i)}$, we retrieve the wanted Lipschitz parameter.

\end{proof}

The contractivity of $I^z$ is not fully stated in the previous proposition because, the Lipschitz parameter depends on the values of $L,L'$ and we want a bound uniform on $\mathcal D_ {I^z}$. This will be done thanks to the two lemmas. 
% The first one is provided with out proof since it is just a consequence of the stability of the conjugate operation towards inversion.
\begin{lemma}[Commutation between inversion and modulus of matrices]\label{lem:inverse_module_matrice_commute}
  Given an invertible matrix $M \in \mathcal M_{p}$, 
  % such that $\Im(M)$ and $\Re(M)$ commute,
  $|M^{-1}| = |M|^{-1}$ and for any $K>0$:
  \begin{align*}
    % |M^{-1}| \geq K I_p&
    % &\Longleftrightarrow&
    % & |M| \leq K I_p.
    \Im M^{-1} \geq K I_p \ \text{or} \ \Re M^{-1} \geq K I_p&
    &\Longrightarrow&
    & |M| \leq \frac{1}{K} I_p.
  \end{align*}
\end{lemma}
\begin{proof}
  % introducing $A,B \in \mathcal M_{p}(\mathbb R)$ such that $M^{-1} = A + iB$, 
  We have the identity:
  \begin{align*}
    |M^{-1}|^2 = M^{-1} \bar{M}^{-1} = (\bar M M)^{-1} =  (|M|^2)^{-1}.
  \end{align*}
  then we take the square root on both sides to obtain the first identity (recall that the modulus of a matrix is a non negative hermitian matrix). Now let us assume that $\Im(M^{-1}) \geq K$, we know that:
  \begin{align*}
    |M^{-1}|^2 
    &= \Im(M^{-1})\Im(M^{-1})^T + \Re(M^{-1})\Re(M^{-1})^T  \\
    &\hspace{1cm}- i \Re(M^{-1})\Im(M^{-1})^T +i \Im(M^{-1})\Re(M^{-1})^T,
  \end{align*}
  is a nonnegative hermitian matrix satisfying for all $x \in \mathbb C^p$ (the cross terms cancel):
  \begin{align*}
    \bar x^T |M^{-1}|^2 x 
    &= \bar x^T \Im(M^{-1})\Im(M^{-1})^T x + \bar x^T \Re(M^{-1})\Re(M^{-1})^T x \\
    &\geq \bar x^T \Im(M^{-1})\Im(M^{-1})^T x \geq K^2 \|x\|^2.
  \end{align*}
  Thus the lower eigen value of $|M^{-1}| = |M|^{-1}$ is bigger than $K$ and therefore $|M| \leq \frac{1}{K}I_p$.

\end{proof}
\begin{lemma}\label{lem:borne_L_I^z}
  Given $L \in \mathcal D_{I^z}$, we can bound:
  \begin{align*}
    \Im(z) I_n \leq |\mathcal I^z(L)| \leq O \left(|z| + \frac{|z|}{\Im(z)}\right) I_n
    % \Im(z) I_n \leq |I^z(L)| \leq |z| \left(1+ \frac{1}{n}\frac{\sup_{i\in[n]}\tr(\Sigma_i)}{\Im(z)}\right)I_n  \leq O \left(|z| + \frac{|z|}{\Im(z)}\right) I_n
    % \frac{\Im(z)}{|z|} I_n \leq |I^z(L)| \leq I_n + \frac{1}{n}\frac{\sup_{i\in[n]}\tr(\Sigma_i)}{\Im(z)}I_n
  \end{align*}
  and:
  \begin{align*}
    O \left(\frac{\Im(z)}{1+\Im(z)}\right) I_p 
    % \leq \frac{I_p}{1 + \frac{\nu}{\Im(z)} } 
    \leq \left\vert Q^{I^z(L)}\right\vert \leq \frac{|z|I_p}{\Im(z)}.
  \end{align*}
\end{lemma}
\begin{proof}
The lower bound of $\mathcal I^z(L)$ is immediate (see the proof of Lemma~\ref{lem:J_stable_sur_DJ}).
  If $L \in \mathcal D_{I^z}$, then we know that $L/z \in \mathcal D_n(\mathbb H)$, and therefore, noting that:
  \begin{align*}
     \Im \left( (\tilde Q^L/z)^{-1}\right) = \Im\left(zI_p - \frac{1}{n } \sum_{i=1}^n \frac{\Sigma_i}{L_i/z}\right) = \Im(z)I_p + \frac{1}{n } \sum_{i=1}^n \frac{\Im(L_i/z)\Sigma_i}{|L_i/z|^2} \geq \Im(z)I_p,
   \end{align*}
   we can deduce from Lemma~\ref{lem:inverse_module_matrice_commute} that $|\tilde Q^L/z| \leq \frac{1}{\Im(z)}$ and thus $\|\tilde Q^L\| \leq \frac{|z|}{\Im(z)}$ which gives us directly the upper bound on $\mathcal I^z(L)$ since $\tr(\Sigma_i) \leq O \left(|z| + \frac{|z|}{\Im(z)}\right)$.
    % $|z| \left(1+ \frac{1}{n}\frac{\sup_{i\in[n]}\tr(\Sigma_i)}{\Im(z)}\right)  \leq O \left(|z| + \frac{|z|}{\Im(z)}\right)$.


   % \begin{align*}
   %   |I^z(L) | \leq |z|
   % \end{align*}
   % with the identities given in the proof of Lemma~\ref{lem:J_stable_sur_DJ} $\Im(zI^z(L)) \geq \Im(z)I_n$, which implies $|I^z(L)| \geq \frac{\Im(z)}{|z|} I_n$.


  % Besides, one can bound thanks to Lemma~\ref{lem:inverse_module_matrice_commute} $\|\tilde Q^z(L)\| \leq \frac{1}{\Im(z)}$ and therefore $|I^z(L)| \leq I_n + \frac{1}{n}\frac{\sup_{i\in[n]}\tr(\Sigma_i)}{\Im(z)}I_n$. 

  % Finally, since $\|\frac{1}{n}\sum_{i=1}^n \Sigma_i \|\leq  \mathbb E \left[\frac{1}{n}\left\Vert XX^T\right\Vert\right] \leq \nu $, w
  Finally, we can bound:
  \begin{align*}
    \left\Vert I_n - \frac{1}{n} \sum_{i=1}^n \frac{\Sigma_i}{\mathcal I^z(L)_i}\right\Vert
    \leq 1 + \frac{1}{n} \sum_{i=1}^n \frac{\left\Vert \Sigma_i \right\Vert}{ | \Im(\mathcal I^z(L)_i)|} 
    \leq 1 + O \left( \frac{1}{\Im(z)} \right),
  \end{align*}
  which provides the lower bound on $|\tilde Q^{\mathcal I^z(L)}|$ since $O \left(\frac{\Im(z)}{1+\Im(z)}\right)  \leq \frac{1}{1 + O(\frac{1}{\Im(z)} )} $.
\end{proof}
 % combined with Lemma~\ref{lem:I_z_bornee_stable_sur_D_C_+} and Proposition~\ref{pro:I_z_contractante} then allows us to set:
% \begin{proposition}\label{pro:Lambdaz_well_defined_onC--}
%   Given a complex number $z \in \mathbb C^{+}$, there exists a unique diagonal matrix $\tilde \Lambda^z \in \mathcal D_n(\mathbb C^{+}_{-})$ satisfying $\tilde \Lambda^z = \mathcal I^z(\tilde \Lambda^z)$.
% \end{proposition}
% We now have all the elements to prove Theorem~\ref{the:definition_existence_tilde_Lambda}:

\begin{theorem}\label{the:definition_existence_tilde_Lambda}
  Given $n$ nonnegative symmetric matrices $\Sigma_1,\ldots, \Sigma_n \in \mathcal M_{p}$, for all $z\in \mathbb H$, the equation:
  \begin{align}\label{eq:fixed_point_equation_tilde_lambda_theorem}
    \forall i \in [n], L_i = z - \frac{1}{n} \tr \left(\Sigma_i \left(I_p - \frac{1}{n}\sum_{i=1}^n \frac{\Sigma_i}{L_i}\right)^{-1}\right)
  \end{align}
  admits a unique solution $L \in \mathcal D_n(\mathbb H)$ that we denote $\tilde \Lambda^z$.
\end{theorem}

\begin{proof}
On the domain $\mathcal I^z(\mathcal D_{\mathcal I^z})$, the mapping $\mathcal I^z$ is bounded and contracting for the semi-metric $d_s$ thanks to Proposition~\ref{pro:I_z_contractante} and Lemma~\ref{lem:borne_L_I^z}. The hypotheses of Theorem~\ref{the:fixed_point_theorem} are thus satisfied, and we know that there exists a unique diagonal matrix $\tilde \Lambda^z \in I^z(\mathcal D_{I^z})$ such that $I^z(\tilde \Lambda^z) = \tilde \Lambda^z$. There can not exist a second diagonal matrix $\Lambda' \in  \mathcal D_n(\mathbb H)$ such that $\Lambda' = I^z(\Lambda')$ because then Proposition~\ref{pro:I_z_contractante} (true on the whole domain $\mathcal D_n(\mathbb H)$) would imply that $d_s(\Lambda' ,\tilde \Lambda^z) < d_s(\Lambda' ,\tilde \Lambda^z)$.
\end{proof}

We end this section with an interesting result on $\tilde \Lambda^z$ that will however not have any use for our main results.
\begin{lemma}\label{lem:Lambda^z_tilde_borne}
  $\sup_{i\in [n]} |\tilde \Lambda^z_i | \leq O(1+|z|)$.
\end{lemma}
\begin{proof}%{\color{red} Ã  mettre dans l'appendice}
  % Given a parameter $\theta\in (0,1)$, i
  If we assume that $\forall i\in [n], |\tilde \Lambda^z_i | \geq 2\nu $, then we deduce that $\frac{1}{n}\sum_{i= 1}^n \frac{1}{\vert\tilde\Lambda^z_i\vert} \leq \frac{1}{2\nu}$ and 
  % \begin{align*}
  %    \frac{1}{n}\sum_{i= 1}^n \frac{1}{\vert\tilde\Lambda^z_i\vert} \leq \frac{2}{\nu},
  % \end{align*}
  $|\frac{1}{n}\sum_{i= 1}^n \frac{\Sigma_i}{\tilde\Lambda^z_i}| \leq \frac{1}{2}$, and therefore, $|\tilde Q^{\tilde \Lambda^z}| \leq 2$. As a consequence, $\forall i \in [n]$:
  \begin{align*}
    \left\vert \tilde \Lambda^z_i\right\vert \leq \left\vert z\right\vert + \frac{1}{n} \tr \left(\Sigma_i |\tilde Q^{\tilde \Lambda^z}|\right) \leq |z| + \frac{2p\nu}{n} 
    % \underset{2 \to 0}{\longrightarrow} |z| + \frac{p\nu}{n} \leq O(1),
  \end{align*}
  We can conclude that:
  \begin{align*}
    \sup_{i\in [n]} \vert\tilde\Lambda^z_i\vert \leq \max \left(\frac{\nu}{2},|z| + \frac{2p\nu}{n} \right) \leq O(1 + | z|). 
  \end{align*}
\end{proof}





\subsection{Convergence of $\hat \Lambda^z$ towards $\tilde \Lambda^z$}
To show the convergence of $\hat \Lambda^z$ towards $\tilde \Lambda^z = I^z(\tilde \Lambda^z)$, we need Proposition~\ref{pro:equation_proche_implique_solution_proche_version2} bounding the distance to a fixed point of a contracting mapping for the semi-metric $d_s$. This sets what we call the stability of the equation. First allowing us to bound $\| \hat \Lambda^z -\tilde \Lambda^z\|$, it will then be employed to show the continuity of $z \mapsto \tilde \Lambda^z$. 
  In the former application, the convergence parameter is $n$, while in the latter application it is a parameter $t \in \mathbb C$ in the neighbourhood of $0$. 



To be employ Proposition~\ref{pro:equation_proche_implique_solution_proche_version2} on the matrices $\tilde \Gamma^n = \tilde \Lambda^z$ and $\Gamma^n = \hat \Lambda^z$ and on the mapping $f^n = \mathcal I^z$, we first need to set the following proposition. Unfortunately, we need to assume here that $d(z,S^\varepsilon)\geq O(1)$ (and not $ d(z,S_{-0}^\varepsilon)\geq O(1)$).
\begin{proposition}\label{pro:2_hypo_pour_proposition_equation_proche_pt_fixe_proche}
  % Given a compact set $K \subset \mathbb C^-$ such that $\sup_{w \in K} |w| \leq O(1)$ and $O(1) \leq \inf_{w\in K} d(w,[0,\bar \nu])$, we can bound:
  Given $z \in \mathbb C \setminus S^\varepsilon$: 
  \begin{align*}
    % \sup_{w\in K}
    d_s \left(\Im(\mathcal I^z(\hat \Lambda^z)), \Im(\hat \Lambda^z)\right)  \leq O \left(\frac{1}{n}\right)
  \end{align*}
\end{proposition}
\begin{remark}\label{rem:borne_kappa_z_z_sur_S}
The bound $O(\frac{1}{n})$ comes from the fact that for any $z \in \mathbb C \setminus S^ \varepsilon$, if $n<p$ then $0 \in S$ and $|z| \geq \varepsilon$ and if $n\geq p$ then $\kappa_z = \frac{|z|}{1+ |z|}$. Therefore, in all cases $\frac{\kappa_z}{|z|} \leq O(1)$.
\end{remark}
To prove Proposition~\ref{pro:2_hypo_pour_proposition_equation_proche_pt_fixe_proche} but also to show later that the mapping $\mathcal I^z$ is contracting, we will need:

\begin{lemma}\label{lem:hat_Lambda_n_borne_par_Im_z}
        Given $z \in \mathbb C \setminus S_{-0}^\varepsilon$:
         % such that $d(z, S_\varepsilon ) \geq O(1)$:
        \begin{align*}
         \Im(z)
          % O \left(\frac{\Im(z)}{\max(1, |z|^2)}\right)  
      \leq \inf_{i\in[n]} \Im \left(\hat \Lambda^z_i\right)
      \leq \sup_{i\in[n]} \Im \left(\hat \Lambda^z_i\right) \leq O \left(\Im(z)\right)  
        \end{align*}
      \end{lemma}
    \begin{proof}
  The lower bound is obvious since for all $i\in[n]$:
  \begin{align*}
    \Im(\hat \Lambda^z_i) = \Im(z) +\frac{\Im(z)}{|z|^2n^2}\mathbb E_{\mathcal A_Q}[\tr \left( Q^z_{-i}  X_{-i}X_{-i}^T\bar Q^z_{-i} \Sigma_i \right)] \geq \Im(z).
  \end{align*}
  The upper bound is obtained thanks to the bound, valid under $\mathcal A_Q$, $Q^z_{-i}  X_{-i}/|z|\sqrt n \leq O(1)$ provided by Lemma~\ref{lem:concentration_QX_s_z}.
     
  \end{proof}

% This proposition partly relies on:
\begin{proof}[Proof of Proposition~\ref{pro:2_hypo_pour_proposition_equation_proche_pt_fixe_proche}]
We can bound thanks to Lemma~\ref{lem:hat_Lambda_n_borne_par_Im_z}:
\begin{align*}
  % \left\Vert\frac{ \Im \left(\mathbb E_{\mathcal A_Q} \left[ Q^w\right] \right) }{\Im(w)} - \frac{ \Im \left(\tilde Q^w(\chi(\Delta^w)) \right) }{\Im(w)}\right\Vert_F
  % \geq O \left(\left\Vert\frac{ \Im \left(\mathcal I^w\circ  \chi(\Delta^w) - \Delta^w\right) }{\Im(\Delta^w)}\right\Vert\right)
  % \left\Vert\frac{ \Im \left(f^n(\Gamma^n) - \Gamma^n\right) }{\Im(\Gamma^n)}\right\Vert
  d_s \left(\Im(\mathcal I^z(\hat \Lambda^z)) ,\Im(\hat \Lambda^z)\right)
  &=\sup_{1\leq i \leq n}\left\vert\frac{ \frac{1}{n}\tr \left(\Sigma_i \Im \left(\tilde Q^{\hat \Lambda^z} - \mathbb E_{\mathcal A_Q} \left[ Q^z\right] \right)\right) }{\sqrt{\Im(\hat \Lambda^z_ i)\Im(\mathcal I^z(\hat \Lambda^z)_i)}}\right\vert 
  \leq O \left(\frac{1}{\sqrt n}\left\Vert\frac{ \Im (\tilde Q^{\hat \Lambda^z} ) }{\Im(z)} - \frac{ \Im \left(\mathbb E_{\mathcal A_Q} \left[ Q^z\right] \right) }{\Im(z)}\right\Vert_F\right),
\end{align*}
since $\|\Sigma_i\|_F \leq O(\sqrt n)$.
  The identity $\frac{1}{\bar zn}  XX^T \bar Q^z = \bar Q^z - I_n$ allows us to write:
  \begin{align}\label{eq:identite_IQ_Q}
     \frac{\Im(\mathbb E_{\mathcal A_Q}[Q^z])}{\Im(z)}
    = \frac{1}{\Im(z)} \mathbb E_{\mathcal A_Q} \left[ Q^z\left( \frac{\Im(z)}{n|z|^2} XX^T \right)\bar Q^z \right]
    = \frac{1}{\ z}\mathbb E_{\mathcal A_Q}[|Q^z|^2 -  Q^z] (= \frac{1}{  \bar z}\mathbb E_{\mathcal A_Q}[|Q^z|^2 -   \bar Q^z]).
   \end{align} 
  We already know how to estimate $\mathbb E_{\mathcal A_Q}[ Q^z]$ thanks to Proposition~\ref{pro:borne_EQ_m_tQ}, we are thus left to estimate $\mathbb E_{\mathcal A_Q}[|Q^z|^2] $. We do not give the full justifications that are closely similar to those presented in the proof of Proposition~\ref{pro:borne_EQ_m_tQ} -- mainly application of Schur identities~\eqref{eq:lien_q_qj_schur}, Proposition~\ref{pro:estimation_XDY} and Lemmas~\ref{lem:Concentration_lambda},~\ref{lem:Q_m_i_proche_Q}. To complete this estimation, we consider a deterministic matrix $A\in \mathcal M_{p}$, and we estimate:
  \begin{align*} 
    &\tr \left(A \mathbb E_{\mathcal A_Q} \left[\bar Q^z\left(Q^z - \tilde Q^{\hat\Lambda^z})\right)\right]\right)\\
    &\hspace{1.5cm}= \frac{1}{n} \sum_{i=1}^n \tr \left(A \mathbb E_{\mathcal A_Q} \left[\bar Q^z Q^z \left( \frac{x_ix_i^T }{z}  - \frac{\Sigma_i}{\hat \Lambda_i^z} \right) \tilde Q^{\hat\Lambda^z}\right]\right)\\
    &\hspace{1.5cm}= \frac{1}{n} \sum_{i=1}^n \tr \left(A \mathbb E_{\mathcal A_Q} \left[\frac{\bar Q^z Q^z_{-i} x_ix_i^T \tilde Q^{\hat\Lambda^z} }{\Lambda_i^z}\right]\right) - \frac{1}{n} \sum_{i=1}^n \tr \left(A \mathbb E_{\mathcal A_Q} \left[\frac{\bar Q^z Q^z \Sigma_i \tilde Q^{\hat\Lambda^z}}{\hat \Lambda_i^z}\right]\right)\\
    &\hspace{1.5cm}= \frac{1}{n} \sum_{i=1}^n \tr \left(A \mathbb E_{\mathcal A_Q} \left[\frac{\bar Q_{-i}^z Q^z_{-i} x_ix_i^T \tilde Q^{\hat\Lambda^z} }{\hat \Lambda_i^z}\right]\right) -  \frac{1}{n^2}\sum_{i=1}^n  \tr \left(A \mathbb E_{\mathcal A_Q} \left[\frac{\bar Q^z x_i x_i^T |Q^z_{-i}|^2 x_ix_i^T \tilde Q^{\hat\Lambda^z} }{z\hat \Lambda_i^z}\right]\right) \\
    &\hspace{2cm} -\frac{1}{n} \sum_{i=1}^n \tr \left(A \mathbb E_{\mathcal A_Q} \left[\frac{\bar Q_{-i}^z Q_{-i}^z \Sigma_i \tilde Q^{\hat\Lambda^z}}{\hat \Lambda_i^z}\right]\right)+ O \left(\frac{\kappa_z}{\sqrt{n}}\right)\\
    &\hspace{1.5cm}= -\mathbb E_{\mathcal A_Q} \left[\frac{1}{n}  \tr \left(A \bar Q^z X\frac{\Delta^z}{z\hat \Lambda_i^z} X^T \tilde Q^{\hat\Lambda^z} \right) \right]+ O \left(\frac{\kappa_z}{\sqrt{n}}\right)
    \end{align*}
    with the introduction of the notation:
    \begin{align*}
       \Delta^z \equiv \diag_{i\in [n]} \left( \frac{1}{n}x_i^T |Q_{-i}^z|^2x_i \right).
     \end{align*} 
    The random diagonal matrix $\Delta^z$ being a $O(\kappa_z^2/\sqrt n)$ Lipschitz transformation of $X$ for the spectral norm $\|\cdot\|$ on $\mathcal D_n$, we know that $\Delta^z \ | \ \mathcal A_Q \in \hat \Delta^z \pm \mathcal E_2(\kappa_z/\sqrt n)$, where we noted $\hat\Delta^z \equiv \mathbb E_{\mathcal A_Q}[\Delta^z]$. One can then pursue the estimation, thanks again to Proposition~\ref{pro:estimation_XDY}:
    % From the identity:
    
    % one can deduce that $ \Delta^z | \mathcal A_Q \in \hat \Delta^z \pm \mathcal E_2(\kappa_z/\sqrt n)  $, with the classical notation $\hat \Delta^z = \mathbb E_{\mathcal A_Q}[\Delta^z]$.
    % Note 
    % Returning to our estimation, we obtain thanks to Proposition~\ref{pro:estimation_XDY}:
    \begin{align*}
    \tr \left(A \mathbb E_{\mathcal A_Q} \left[\bar Q^z\left(Q^z - \tilde Q^{\hat\Lambda^z})\right)\right]\right)
    &=\frac{1}{n}\sum_{i=1}^n  \frac{\hat \Delta_i^z}{\hat \Lambda_i^z}\tr \left(A \mathbb E_{\mathcal A_Q} \left[\frac{\bar Q^z_{-i} x_i x_i^T \tilde Q^{\hat\Lambda^z} }{\bar \Lambda^z_i}\right]\right)+ O \left(\frac{\kappa_z}{\sqrt{n}}\right)\\
    &=\frac{1}{n}\sum_{i=1}^n  \frac{\hat \Delta_i^z}{\left\vert \hat \Lambda_i^z\right\vert^2}\tr \left(A \mathbb E_{\mathcal A_Q} \left[\bar Q^z_{-i} \Sigma_i \tilde Q^{\hat\Lambda^z} \right]\right)+ O \left(\frac{\kappa_z}{\sqrt{n}}\right)
  \end{align*} 
  Now, taking the expectation under $\mathcal A_Q$ on the identity valid for any $i\in[n]$:
  \begin{align}\label{eq:relation_Lambda_Delta}
      \Im(\Lambda^z_i) 
      &= \Im(z) -\frac{1}{n}\Im(x_i^TQ^z_{-i}x_i)
      = \Im(z)\left(1+\frac{1}{n  z}\left(x_i^T|Q^z_{-i}|^2x_i - x_i^T  Q^z_{-i}x_i\right)\right) 
      = \frac{\Im(z)}{ z} \left( \Delta_i^z +\Lambda^z_i\right),
    \end{align}
    we deduce that $\hat \Delta^z =  \frac{z}{\Im(z)} \Im(\hat \Lambda^z) - \hat \Lambda^z + O(\kappa_z/n)$. Therefore, with the identity $\mathbb E_{\mathcal A_Q}[\bar Q^z \tilde Q^{\hat \Lambda^z}] = |\tilde Q^{\hat\Lambda^z}|^2 + O_{\|\cdot \|_F}(\kappa_z/\sqrt n)$, we can estimate (see the proof of Lemma~\ref{lem:J_stable_sur_DJ} for the identification of $\Im(\tr(\tilde Q^{\hat \lambda^z}))$):
    \begin{align*}
    \tr \left(A \mathbb E_{\mathcal A_Q} \left[|Q^z|^2\right]\right)
    % &\hspace{0.5cm}
    &=\frac{1}{n}\sum_{i=1}^n  \left(\frac{z}{\Im(z)}\frac{\Im(\hat \Lambda_i^z)}{\left\vert \hat \Lambda_i^z\right\vert^2}  - \frac{1}{ \bar{\hat \Lambda}_i^z}\right)\tr \left(A \mathbb E_{\mathcal A_Q} \left[\bar Q^z_{-i} \Sigma_i \tilde Q^{\hat\Lambda^z} \right]\right)\\
    &\hspace{1cm}+ \tr \left(A |\tilde Q^{\hat\Lambda^z}|^2 \right)+ O \left(\frac{\kappa_z}{\sqrt{n}}\right) \\%+ O \left(\frac{\kappa_z}{\sqrt{n}}\right) \\
    &= \frac{z}{\Im(z)} \Im \left(\tr \left(A \tilde Q^{\hat \Lambda^z}\right) \right) + \frac{1}{n} \tr \left(A \tilde Q^{\hat \Lambda^z}\right)  + O \left(\frac{\kappa_z}{\sqrt{n}}\right)
    % &= \frac{1}{n} \tr \left(A \tilde Q^{\hat \Lambda^z}\right) - \frac{1}{n}\sum_{i=1}^n  \frac{z \left(1 + \frac{\Im(\hat \Lambda_i^z)}{\Im(z)}\right)}{\left\vert \hat \Lambda_i^z\right\vert^2}  \tr \left(A \bar{\tilde Q}^{\hat \Lambda^z} \Sigma_i \tilde Q^{\hat\Lambda^z} \right) + O \left(\frac{\kappa_z}{\sqrt{n}}\right)
    \end{align*}
    and therefore, we can deduce from Proposition~\ref{pro:borne_EQ_m_tQ} and \eqref{eq:identite_IQ_Q}:
    \begin{align*}
      \frac{\Im \left(\tr \left(A Q^{z}\right)\right)}{\Im(z)} = \frac{1}{z}\tr \left(A \mathbb E_{\mathcal A_Q} \left[|Q^z|^2 - Q^z\right]\right) = \frac{\Im \left(\tr \left(A \tilde Q^{\hat \Lambda^z}\right)\right)}{\Im(z)} + O \left(\frac{\kappa_z}{|z|\sqrt{n}}\right).
    \end{align*}
  % where we recall the notation $\Sigma_{\Gamma} \equiv \frac{1}{n}\sum_{i=1}^n \Gamma \Sigma_i$ for any diagonal matrix $\Gamma \in \mathcal D_{n}$.
  % thanks again to Proposition~\ref{pro:equivalent_deterministe_XDX}. i
  % (note that $|z|/\Im(z)\leq 1$). 
  we can bound thanks to identity~\ref{eq:identite_IQ_Q} and inequality $\frac{\kappa_z}{|z|} \leq O(1)$ given by Remark~\ref{rem:borne_kappa_z_z_sur_S}:
   % note that if $|z|/\Im(z)\leq 1$ 
  % In conclusion:
  \begin{align*}
    \left\Vert \frac{\Im( \mathbb{E}_{\mathcal A_Q} \left[Q^z\right]) - \Im(\tilde Q ^{\hat \Lambda^z})}{\Im(z)} \right\Vert_F \leq  O \left(\frac{\kappa_z}{|z|\sqrt{n}}\right)\leq O \left(\frac{1}{\sqrt{n}}\right),
  \end{align*}
  and we retrieve the result of the proposition.
\end{proof}


  We now have all the elements to show the convergence of $\hat \Lambda^z$ to $\tilde \Lambda^z$. Here again, we need to assume as in Proposition~\ref{pro:2_hypo_pour_proposition_equation_proche_pt_fixe_proche} that $z \in \mathbb C \setminus S^{\varepsilon}$.
  \begin{proposition}\label{pro:hat_lambda_vers_tilde_lambda}
    For any $z \in \mathbb H$ such that $d(z, S) \geq \varepsilon$:% $$ and:
    \begin{align*}
      % O(\Im(z)) \leq \Im(\Lambda^z) \leq O(\Im(z))&
      % &\text{and}&
      &\| \hat \Lambda^z - \tilde \Lambda^z\| \leq O \left(\frac{\kappa_z}{n}\right)&
      &\text{and}&
      &O \left(\frac{|z|}{\check \kappa_z} \right)\leq |\tilde \Lambda^z| \leq O \left(\frac{|z|}{\check \kappa_z} \right)
    \end{align*}
    % As a consequence, $\tilde S \subset S_\varepsilon$.
  \end{proposition}
  \begin{proof}
    We already know from Proposition~\ref{pro:2_hypo_pour_proposition_equation_proche_pt_fixe_proche} that $d_s \left(\Im(\mathcal I^z(\hat \Lambda^z)), \Im(\hat \Lambda^z)\right)  \leq o(1)$. Besides, the Lipschitz parameter $\lambda$ of $\mathcal I^z$ on the set $\{\tilde \Lambda^z, \hat \Lambda^z, n \in \mathbb N\}$ is such that $1-\lambda \geq O(1)$. Recall indeed from Proposition~\ref{pro:I_z_contractante} that:
    \begin{align*}
       \lambda 
       &\leq \sqrt{\left(1 - \frac{\Im(z)}{\sup_{i\in [n]} \Im(\tilde \Lambda_i^z)}\right) \left(1 - \frac{\Im(z)}{\sup_{i\in [n]} \Im(\hat \Lambda_i^z)}\right)}
        \leq \sqrt{1 - O(1)} \leq 1 - O(1),
     \end{align*} 
     thanks to Lemma~\ref{lem:hat_Lambda_n_borne_par_Im_z}.
     Therefore, we can employ Proposition~\ref{pro:equation_proche_implique_solution_proche_version2} to set that:% there exists a constant $\kappa>0$ such that for all $n \in \mathbb N$:
      \begin{align*}
         \left\Vert \frac{\hat \Lambda^z - \tilde \Lambda^z}{\sqrt{\Im(\hat \Lambda^z) \Im(\tilde \Lambda^z)}}\right\Vert =
         d_s(\hat \Lambda^z, \tilde \Lambda^z) 
         % &\leq \kappa    d_s(\hat \Lambda^z, \mathcal I^z(\hat \Lambda^z))
         & \leq O \left(\left\Vert  \frac{\hat \Lambda^z - \mathcal I^z(\hat \Lambda^z)}{\sqrt{\Im(\hat \Lambda^z) \Im(\tilde \Lambda^z)}}\right\Vert\right),
         % &\leq \kappa \left\Vert  \frac{\hat \Lambda^z - \mathcal I^z(\hat \Lambda^z)}{\sqrt{\hat \Lambda^z \tilde \Lambda^z}}\right\Vert \left(1 + d_s(\hat \Lambda^z, \tilde \Lambda^z)\right)
       \end{align*} 
       which implies thanks to Lemma~\ref{lem:hat_Lambda_n_borne_par_Im_z} that:
       \begin{align*}
         \left\Vert\hat \Lambda^z - \tilde \Lambda^z \right\Vert 
         &\leq  O \left(\sqrt{\frac{\sup_{i\in [n]}\Im(\tilde \Lambda^z_i)}{\inf_{i\in [n]}\Im(\tilde \Lambda^z_i)}}\left\Vert \hat \Lambda^z - \mathcal I^z(\hat \Lambda^z)\right\Vert \right).
         % &\leq \frac{\sqrt{3}\kappa K}{n}\sup_{i\in[n]} \left\vert \tr \left(\Sigma_i(\mathbb E_{\mathcal A_Q}[Q^z] - \tilde Q^{\hat \Lambda^z})\right)\right\vert \leq O \left(\frac{\kappa_z}{n}\right) \leq O \left(\frac{1}{n}\right)
       \end{align*}
       We reach here the only point of the whole proof where we will employ Assumption~\ref{ass:Sigma_borne_inferieurement}. It is to set that:
       \begin{align*}
         \inf_{i\in [n]}\Im(\tilde \Lambda^z_i) 
         &= \Im(z) + \inf_{i\in [n]}\sum_{j=1}^n\frac{\Im(\tilde\Lambda_j^z)}{n|\tilde \Lambda_j^z|^2} \tr \left(\Sigma_i \tilde Q^{\tilde \Lambda^z} \Sigma_j \bar{\tilde Q}^{\tilde \Lambda^z}\right)\\
         &\geq  \Im(z) + \sum_{j=1}^n\frac{\Im(\tilde\Lambda_j)}{n^z|\tilde \Lambda_j|^2}^z O \left(\tr \left( \tilde Q^{\tilde \Lambda^z} \Sigma_j \bar{\tilde Q}^{\tilde \Lambda^z}\right)\right)
         \ \geq O \left(\sup_{i\in [n]}\Im(\tilde \Lambda^z_i)\right)
       \end{align*}

       As a conclusion:
       \begin{align*}
         \left\Vert\hat \Lambda^z - \tilde \Lambda^z \right\Vert 
         &\leq  O \left(\left\Vert \hat \Lambda^z - \mathcal I^z(\hat \Lambda^z)\right\Vert \right)
         \leq O \left(\frac{1}{\sqrt n} \left\Vert \hat Q - \tilde Q^{\hat \Lambda^z}\right\Vert\right) \leq O \left(\frac{\kappa_z}{n}\right).
       \end{align*}

      we can further deduce that $ \Lambda^z$ and $\tilde \Lambda^z$ have the same upper and lower bound of order $O(|z|/\check \kappa_z)$ since $\kappa_z \leq O(|z|/\check \kappa_z)$.
  \end{proof}


\subsection{Concentration and final estimation of the resolvent}

The estimation of $Q^z$ is a simple consequence of the convergence of $\hat\Lambda^z$ towards $\tilde \Lambda^z$.
\begin{corollary}\label{cor:deux_eq_deterministes_proches}
  For any $z \in \mathbb C \setminus S_\varepsilon$, $\|\tilde Q^{\tilde \Lambda^z}\| \leq O(\kappa_z)$ and:
  \begin{align*}
    \left\Vert \mathbb{E}_{\mathcal A_Q} \left[Q^z\right] - \tilde Q^{\tilde \Lambda^z}\right\Vert_F \leq O \left(\frac{\kappa_z}{\sqrt{n}}\right)
  \end{align*}
\end{corollary}
\begin{proof}
  We already know from Proposition~\ref{pro:borne_EQ_m_tQ} that $\left\Vert \mathbb{E}_{\mathcal A_Q} \left[Q^z\right] - \tilde Q^{\hat \Lambda^z} \right\Vert_F \leq O(\kappa_z/\sqrt n)$, thus we are left to bound:
  % for any deterministic $A \in \mathcal M_{p}$:
  \begin{align*}
    \left\Vert \tilde Q^{\hat \Lambda^z} - \tilde Q^{\tilde \Lambda^z} \right\Vert_F
    & \leq \left\Vert \tilde Q^{\hat \Lambda^z} \left(\frac{1}{n} \sum_{i=1}^n \frac{\hat \Lambda_i^z - \tilde \Lambda_i^z}{\hat \Lambda_i^z\tilde \Lambda_i^z} \Sigma_i\right) \tilde Q^{\tilde \Lambda^z} \right\Vert_F\\
    & \leq  \sup_{i\in [n]} \left\vert \frac{\hat \Lambda_i^z - \tilde \Lambda_i^z}{\hat \Lambda_i^z\tilde \Lambda_i^z}\right\vert\left\Vert  \Sigma_i \right\Vert_F \left\Vert  \tilde Q^{\hat \Lambda^z}\right\Vert\left\Vert  \tilde Q^{\tilde \Lambda^z}\right\Vert\\
    &\leq O \left(\frac{\kappa_z^3 \check \kappa_z^2 \sqrt{p}}{|z|^2n}\right) \leq O \left(\frac{\kappa_z}{\sqrt n}\right)
    % & = \left\Vert \tilde Q^z \left(\frac{I_n}{I_n - \Delta^z}\right) - \tilde Q^z \left(\frac{zI_n}{\Lambda^z} \right)\right\Vert\\
    % &\leq \left\Vert \tilde Q^z \left(\frac{I_n}{I_n - \Delta^z}\right) \left(\frac{1}{n}\sum_{i=1}^n \left(\frac{1  - \Delta^z_i - \frac{1}{z}\Lambda^z_i}{\frac{1}{z} \Lambda_i^z(1- \Delta_i^z)}\right)\Sigma_i\right)\frac{1}{z}R(\Lambda^z)\right\Vert\\
    % &\leq \frac{\nu_z}{z} \|R(\Lambda^z)\|  \left\Vert I_n - \frac{1}{z}\Lambda^z - \Delta^z\right\Vert 
    % \leq O \left(\|R(\Lambda^z)\|\frac{\sqrt{\log n}}{n}\right).
  \end{align*}
  (thanks to Lemma~\ref{lem:Borne_Lambda},~\ref{lem:Borne_resolvante},~\ref{lem:Lambda^z_tilde_borne} and Proposition~\ref{pro:hat_lambda_vers_tilde_lambda})
  We can then deduce that:
  \begin{align*}
    \left\Vert \tilde Q^{\tilde \Lambda^z}\right\Vert_F
    &\leq \Vert \tilde Q^{\hat \Lambda^z} - \tilde Q^{\tilde \Lambda^z} \Vert_F + \Vert \tilde Q^{\hat \Lambda^z} \Vert_F \leq O(\kappa_z).
    % &\leq |z|\|\tilde Q^z \left(\frac{I_n}{I_n - \Delta^z}\right)\| + |z| \|\tilde Q^z \left(\frac{I_n}{I_n - \Delta^z}\right) - \frac{1}{z}R(\Lambda^z)\|_F \\
    % &\leq O(1) + O \left(\|R(\Lambda^z)\|\sqrt{\frac{\log n}{n}}\right)
  \end{align*}
  % Therefore $\|R(\Lambda^z)\| \leq O(1)$ and $\|\tilde Q^z \left(\frac{I_n}{I_n - \Delta^z}\right) - \frac{1}{z}R(\Lambda^z)\| \leq O(\sqrt{\log n}/n)$.% which implies the result of the Theorem.{\color{orange} mais d'ou Q tilde est bornÃ©e ?}
  % since  thanks to the Cauchy Schwarz inequality.

\end{proof}

% We can now prove our second main Theorem (on the linear concentration of $\frac{1}{z}Q^z$ around $\frac{1}{z}\tilde Q^{\tilde \Lambda^z}$):

The concentration of $Q^z$ natturally implies the concentration of $R: z \mapsto \frac{1}{z}Q^z$ around $\tilde R: z \mapsto \frac{1}{z}\tilde Q^{\tilde \Lambda^z}$ that for integration purpose, we set with  the semi-norm $\| \cdot \|_{F,S^\varepsilon}$, defined for every $f \in \mathcal F(\mathbb C,\mathcal M_{p})$ as:
  \begin{align*}
    \| f \|_{F,S^\varepsilon} = \sup_{z \in \mathbb C \setminus S^\varepsilon} \|f(z)\|_F.
  \end{align*}

% provides inferences on eigenvectors thanks to the approximation of the mapping $ R : z \mapsto \left(\frac{1}{n}XX^T - zI_p \right)^{-1}$. Here $z$ must be far from zero when $0 \in S$ (even if $0 \notin S_{-0}$). % is in the spectrum of $\frac{1}{n}XX^T$ and $\frac{1}{n}X^TX$.

\begin{theorem}\label{the:concentration_resolvente_main_res}
  $R \ | \ \mathcal A_Q \in \tilde R \pm \mathcal E_2(1/\sqrt n)$ in $(\mathcal{M}_{p,n}^{\mathbb C \setminus S^{\varepsilon}}, \| f \|_{F,S^\varepsilon})$.
  % Under Assumptions~\ref{ass:n_p_commensurable}-\ref{ass:Sigma_borne_inferieurement}, given $\varepsilon>0$, there exist two constants $C,c>0$, such that for all linear form $u: \mathcal F(\mathbb C,\mathcal M_{p}) \to \mathbb R$, $1$-Lipschitz for the norm $\|\cdot \|_{F, S^\varepsilon }$:
  % \begin{align*}
  %   \mathbb P \left( \left\vert u \left(R - \tilde R\right)\right\vert \geq t\right) \leq C e^{-cnt^2} + C e^{-cn}.
  %   % \mathbb P \left( \left\vert u \left(\left(zI_p - \frac{1}{n}XX^T\right)^{-1} - \left(zI_p - \frac{1}{n}\sum_{i=1}^n \frac{z\Sigma_i}{\Lambda_i}\right)^{-1}\right)\right\vert \geq t\right) \leq C e^{-cnt^2} + C e^{-cn}.
  % \end{align*}
\end{theorem}

\begin{proof}[Proof of Theorem~\ref{the:concentration_resolvente_main_res} ]
  % If $n \geq p$, w
  We saw in the proof of Proposition~\ref{pro:concentration_resolvente_1} that the mapping $R \in (\mathcal F(\mathbb C \setminus S^\varepsilon, \mathcal M_p), \|\cdot \|_{F,S^\varepsilon}) $ defined, under $\mathcal A_Q$, for any $z \in \mathbb C \setminus S^\varepsilon$ as $R(z) = -\frac{1}{z} Q^z$ has a Lipschitz parameter bounded by:
  \begin{align*}
     \sup_{z \in \mathbb C \setminus S^\varepsilon}O \left(\frac{\kappa_z}{|z|\sqrt n}  \right) = O \left(\frac{1}{\sqrt n}\right)
   \end{align*}
   % (since when $n\geq p$, $\kappa_z = \frac{|z|}{1+|z|}$, and when $n <p$, $\kappa_z = 1$ but $\mathbb E[\lambda_p] = 0$ and therefore $ \inf_{z \in \mathbb C \setminus S^\varepsilon} 1/|z| \geq O(1)$).
   Thanks to the bound $\frac{\kappa_z}{|z|} \leq O(1)$ justified in Remark~\ref{rem:borne_kappa_z_z_sur_S}.
   As a $O(1/\sqrt n)$-Lipschitz transformation of $X\propto \mathcal E_2$, $(R \ | \ \mathcal A_Q) \propto \mathcal E_2(1/\sqrt n)$, we can then conclude thanks to Corollary~\ref{cor:deux_eq_deterministes_proches} with the bound:
    % valid for any $z \in \mathbb C \subset S^\varepsilon$:
   \begin{align*}
     \left\Vert \mathbb E_{\mathcal A_Q}[R] - \tilde R\right\Vert_{F, S^\varepsilon} 
     &\leq \sup_{z \in \mathbb C \setminus S^\varepsilon} \frac{1}{|z|} \left\Vert \mathbb{E}_{\mathcal A_Q} \left[Q^z\right] - \tilde Q^{\tilde \Lambda^z} \right\Vert \\
     &\leq \sup_{z \in \mathbb C \setminus S^\varepsilon} O \left(\frac{\kappa_z}{\sqrt n|z|}\right) \leq O \left(\frac{1}{\sqrt n}\right)
   \end{align*}
\end{proof}


% This second theorem gives us good estimates for 
The projections on deterministic vectors provide us with good estimates on isolated eigenvectors, but a concentration in spectral norm would have been sufficient for this kind of result. A key consequence of Theorem~\ref{the:concentration_resolvente_main_res} lies in the accurate estimates of projections on high dimensional subspaces $F \subset \mathbb R^p$ it provides; this is shown\footnote{It must be noted that the setting of Figure~\ref{fig:spectre_XXT_influence_nombre_de_classe} does not exactly fall under our hypotheses (since here $\|\mathbb E[x_i] \| \geq O(\sqrt p)$), as the amplitude of the signals must be sufficiently large for the resulting eigenvalues to isolate from the bulk of the distribution when the number of classes is high ($\sqrt{p} \approx 14$ is not so large). However, even in this extreme setting the prediction are good.} in Figure~\ref{fig:spectre_XXT_influence_nombre_de_classe} that depicts some of these projections with increasing numbers of classes\footnote{The number of classes is the number of different distributions that can follow the column vectors of $X$}. Given $k \in \mathbb N$, we consider $B  \equiv \{ \theta_1, \ldots, \theta_k\} \subset \mathbb R$, a (random) subset of $k$ eigenvalues of $\frac{1}{n}XX^T$, $E_B$ the eigenspace associated to those eigenvalues and $\Pi_B$ and $\Pi_F$, respectively the orthogonal projection on $E_B$ and $F$. If one can construct\footnote{The possibility to construct such a path and the condition on $B$ for its existence, related to the notion of clusters, is a very interesting question that we do not address in this study.} a deterministic path $\gamma$ such that $\{\mathbb E [\theta_i], i \in [k]\}^\varepsilon \subset \gamma \subset \mathbb C \setminus S_{-0}^\varepsilon$ then we can bound (since $\|\Pi_F\|_F = \sqrt{\text{dim}(F)}\leq O(\sqrt p)$):
\begin{align*}
  \mathbb P \left( \left\vert \frac{1}{p}\tr(\Pi_F\Pi_A) - \frac{1}{2ip\pi} \oint_\gamma \tr(\Pi_F \tilde R(z)) dz\right\vert\geq t\right) \leq C e^{-cnpt^2} + C e^{-cn},
\end{align*}
% where the deterministic path $\gamma$ is chosen such that it contains the eigen $S_{-0}^\varepsilon \subset \gamma \subset \mathbb C \setminus S_{-0}^\varepsilon$.


\begin{figure}
\centering
\begin{tabular}{cc}
\begin{tikzpicture}   
  \begin{axis}[ylabel=spectral density $d\mu(\lambda)$, y label style={at={(-0.12,0.5)}}, width = 0.55\textwidth,xlabel=eigenvalues $\lambda$,  legend cell align = left, legend style={fill=white, fill opacity=0.7,draw=none}, ytick ={0,0.2,0.4, 0.6, 0.8}, ymax = 0.85, xtick={0,5,10}, xmax = 13] %,ytick ={0,0.2,0.4}, ymax = 0.6, xtick={0,5,10,15}, xmax = 15.5] 
    \addplot [blue,ybar,fill, fill opacity=0.3, bar width = 0.3,ybar legend] coordinates {(0.25, 0.6)(0.75, 0.49)(1.25, 0.31)(1.75, 0.24)(2.25, 0.14)(2.75, 0.02)(3.25, 0.0)(3.75, 0.0)(4.25, 0.0)(4.75, 0.0)(5.25, 0.0)(5.75, 0.01)(6.25, 
0.0)(6.75, 0.0)(7.25, 0.01)(7.75, 0.0)(8.25, 0.02)(8.75, 0.02)(9.25, 0.01)(9.75, 0.0)(10.25, 0.02)(10.75, 0.01)(11.25, 0.01)(11.75, 0.01)(12.25, 0.0)(12.75, 0.01)(13.25, 0.01)(13.75, 0.0)(14.25, 0.01)(14.75, 0.01)(15.25, 0.0)(15.75, 0.01)(16.25, 0.01)(16.75, 0.0)(17.25, 0.0)(17.75, 0.01)(18.25, 0.0)(18.75, 0.01)} \closedcycle;
    \addplot[sharp plot,black!60, line width = 1,domain=1:40,samples=100,line legend, smooth] coordinates {(0,0)(0.25, 0.6621)(0.5, 0.5972)(0.75, 0.4741)(1.0, 0.3904)(1.25, 0.3363)(1.5, 0.278)(1.75, 0.2326)(2.0, 0.1835)(2.25, 0.1364)(2.5, 0.0818)(2.75, 0.0044)(3.0, 0.0002)(3.25, 0.0)(3.5, 0.0)(3.75, 0.0)(4.0, 0.0)(4.25, 0.0)(4.5, 0.0)(4.75, 0.0)(5.0, 0.0)(5.25, 0.0)(5.5, 0.0029)(5.75, 0.0056)(6.0, 0.0079)(6.25, 0.0092)(6.5, 0.0099)(6.75, 0.0103)(7.0, 0.0105)(7.25, 0.0106)(7.5, 0.0107)(7.75, 0.0107)(8.0, 0.0107)(8.25, 0.0106)(8.5, 0.0104)(8.75, 0.0102)(9.0, 0.01)(9.25, 0.0098)(9.5, 0.0095)(9.75, 0.0092)(10.0, 0.0088)(10.25, 0.0085)(10.5, 0.0081)(10.75, 0.0078)(11.0, 0.0075)(11.25, 0.0073)(11.5, 0.0072)(11.75, 0.007)(12.0, 0.0069)(12.25, 0.0068)(12.5, 0.0067)(12.75, 0.0066)(13.0, 0.0065)(13.25, 0.0063)(13.5, 0.0062)(13.75, 0.006)(14.0, 0.0058)(14.25, 0.0056)(14.5, 0.0055)(14.75, 0.0053)(15.0, 0.0051)(15.25, 0.0049)(15.5, 0.0047)(15.75, 0.0045)(16.0, 0.0043)(16.25, 0.0042)(16.5, 0.004)(16.75, 0.0039)(17.0, 0.0038)(17.25, 0.0037)(17.5, 0.0036)(17.75, 0.0035)(18.0, 0.0034)(18.25, 0.0033)(18.5, 0.0032)(18.75, 0.003)(19.0, 0.0029)(19.25, 0.0028)(19.5, 0.0027) (20, 0.00) (22, 0.00)
    };
   \node at (axis cs: 7, 0.4) {$k = 20$};

    \node[color = red!60!black!40] at (axis cs: 9, 0.15) {$E_A$};
    \addplot[sharp plot,color = black!40!red!60!, line width = 0.3,domain=1:40,samples=100,line legend] coordinates {(4, 0)(4, 0.1)(21, 0.1)(21,0)};
    \legend{empirical distribution, prediction from $\tilde \Lambda$, integration path (in $\mathbb C$)} ;
  \end{axis} 
\end{tikzpicture}
\begin{tikzpicture}   
  \begin{axis}[ y label style={at={(-0.08,0.5)}}, width = 0.55\textwidth,xlabel=eigenvalues $\lambda$, legend cell align = left, legend style={draw=none},ytick ={0,0.2,0.4, 0.6, 0.8}, ymax = 0.85, xtick={0,5,10}, xmax = 13] 
    \addplot [blue,ybar,fill, fill opacity=0.3, bar width = 0.3,ybar legend] coordinates {(0.25, 0.28)(0.75, 0.66)(1.25, 0.46)(1.75, 0.18)(2.25, 0.0)(2.75, 0.02)(3.25, 0.05)(3.75, 0.04)(4.25, 0.03)(4.75, 0.04)(5.25, 0.03)(5.75, 0.03)(6.25, 0.03)(6.75, 0.02)(7.25, 0.01)(7.75, 0.04)(8.25, 0.01)(8.75, 0.02)(9.25, 0.01)(9.75, 0.02)(10.25, 0.01)(10.75, 0.01)} \closedcycle;
    \addplot[sharp plot,black!60, line width = 1,domain=1:40,samples=100,line legend, smooth] coordinates {(0,0)(0.2,0)(0.21,0.01)(0.22,0.05)(0.3, 0.2184)(0.4, 0.6577)(0.5, 0.7332)(0.6, 0.755)(0.7, 0.6914)(0.8, 0.6396)(0.9, 0.6061)(1.0, 0.5695)(1.1, 0.5064)(1.2, 0.463)(1.3, 0.4325)(1.4, 0.3751)(1.5, 0.3431)(1.6, 0.2973)(1.7, 0.2402)(1.8, 0.1725)(1.9, 0.0916)(2.0, 0.0076)(2.1, 0.0005)(2.2, 0.0001)(2.3, 0.0001)(2.4, 0.0001)(2.5, 0.0132)(2.6, 0.0282)(2.7, 0.0348)(2.8, 0.0375)(2.9, 0.0377)(3.0, 0.0367)(3.1, 0.0363)(3.2, 0.037)(3.3, 0.0377)(3.4, 0.038)(3.5, 0.0379)(3.6, 0.0376)(3.7, 0.0372)(3.8, 0.0369)(3.9, 0.0367)(4.0, 0.0366)(4.1, 0.0364)(4.2, 0.0361)(4.3, 0.0357)(4.4, 0.0352)(4.5, 0.0347)(4.6, 0.0341)(4.7, 0.0335)(4.8, 0.0328)(4.9, 0.0321)(5.0, 0.0314)(5.1, 0.0306)(5.2, 0.0299)(5.3, 0.0292)(5.4, 0.0286)(5.5, 0.028)(5.6, 0.0274)(5.7, 0.0269)(5.8, 0.0265)(5.9, 
0.0261)(6.0, 0.0258)(6.1, 0.0255)(6.2, 0.0252)(6.3, 0.0249)(6.4, 0.0247)(6.5, 0.0244)(6.6, 0.0241)(6.7, 0.0238)(6.8, 0.0235)(6.9, 0.0232)(7.0, 0.0229)(7.1, 0.0226)(7.2, 0.0222)(7.3, 0.0218)(7.4, 0.0214)(7.5, 0.0209)(7.6, 0.0204)(7.7, 0.0199)(7.8, 0.0194)(7.9, 0.0188)(8.0, 0.0183)(8.1, 0.0177)(8.2, 0.0172)(8.3, 0.0167)(8.4, 0.0162)(8.5, 0.0158)(8.6, 0.0153)(8.7, 0.0148)(8.8, 0.0144)(8.9, 0.0139)(9.0, 0.0135)(9.1, 0.013)(9.2, 0.0126)(9.3, 0.0123)(9.4, 0.012)(9.5, 0.0117)(9.6, 0.0116)(9.7, 0.0114)(9.8, 0.0113)(9.9, 0.0112)(10.0, 0.0111)(10.1, 0.011)(10.2, 0.0109)(10.3, 0.0108)(10.4, 0.0106)(10.5, 0.0105)(10.6, 0.0103)(10.7, 0.0101)(10.8, 0.0098)(10.9, 0.0095)(11.0, 0.0092)(11.1, 0.0089)(11.2, 0.0086) (11.5, 0.0001) (12,0) (13,0)};
    \addplot[sharp plot,color = black!40!red!60!, line width = 0.3,domain=1:40,samples=100,line legend] coordinates {(2.2, 0)(2.2, 0.1)(12, 0.1)(12,0)
    };
    \node[color = red!60!black!40] at (axis cs: 7, 0.15) {$E_A$};
    \node at (axis cs: 7, 0.4) {$k = 42$};
  \end{axis} 
\end{tikzpicture} \\
\begin{tikzpicture}   
  \begin{axis}[ylabel=spectral density $d\mu(\lambda)$, y label style={at={(-0.12,0.5)}}, width = 0.55\textwidth,xlabel=eigenvalues $\lambda$, legend cell align = left, legend style={draw=none},ytick ={0,0.2,0.4, 0.6, 0.8}, ymax = 0.85, xtick={0,5,10}, xmax = 13] 
    \addplot [blue,ybar,fill, fill opacity=0.3, bar width = 0.1,ybar legend] coordinates {(0.5, 0.6)(0.7, 0.775)(0.9, 0.725)(1.1, 0.55)(1.3, 0.475)(1.5, 0.275)(1.7, 0.075)(1.9, 0.05)(2.1, 0.1)(2.3, 0.075)(2.5, 0.05)(2.7, 0.1)(2.9, 0.05)(3.1, 0.05)(3.3, 0.075)(3.5, 0.075)(3.7, 0.05)(3.9, 0.075)(4.1, 0.05)(4.3, 0.05)(4.5, 0.05)(4.7, 0.05)(4.9, 0.025)(5.1, 0.05)(5.3, 0.05)(5.5, 0.025)(5.7, 0.05)(5.9, 0.025)(6.1, 0.05)(6.3, 0.05)(6.5, 0.025)(6.7, 0.025)(6.9, 0.0)(7.1, 0.05)(7.3, 0.0)(7.5, 0.025)(7.7, 0.025)(7.9, 0.05)(8.1, 0.0)(8.3, 0.0)(8.5, 0.025)(8.7, 0.0)(8.9, 0.025)} \closedcycle;
    \addplot[sharp plot,black!60, line width = 1,domain=1:40,samples=100,line legend, smooth] coordinates {(0,0) (0.4,0)(0.41,0.02)(0.42,0.05)(0.45, 0.4724)(0.5, 0.6529)(0.55, 0.7535)(0.6, 0.7548)(0.65, 0.7675)(0.7, 0.7576)(0.75, 0.7561)(0.8, 0.7628)(0.85, 0.7333)(0.9, 0.6889)(0.95, 0.6702)(1.0, 0.6342)(1.05, 0.6162)(1.1, 0.5772)(1.15, 0.5628)(1.2, 0.5222)(1.25, 0.4798)(1.3, 0.4523)(1.35, 0.4212)(1.4, 0.3884)(1.45, 0.3478)(1.5, 0.2864)(1.55, 0.2332)(1.6, 0.1912)(1.65, 0.0489)(1.7, 0.0065)(1.75, 0.0579)(1.8, 0.0682)(1.85, 0.0749)(1.9, 0.077)(1.95, 0.0772)(2.0, 0.0772)(2.05, 0.078)(2.1, 0.0792)(2.15, 0.0803)(2.2, 0.0814)(2.25, 0.0822)(2.3, 0.0824)(2.35, 0.0821)(2.4, 0.0811)(2.45, 0.0797)(2.5, 0.0779)(2.55, 0.0758)(2.6, 0.0737)(2.65, 0.072)(2.7, 0.0709)(2.75, 0.0705)(2.8, 0.0705)(2.85, 0.0706)(2.9, 0.0706)(2.95, 0.0704)(3.0, 0.0699)(3.05, 0.0693)(3.1, 0.0685)(3.15, 0.0675)(3.2, 0.0665)(3.25, 0.0653)(3.3, 0.0642)(3.35, 0.0631)(3.4, 0.0619)(3.45, 0.0608)(3.5, 0.0597)(3.55, 0.0586)(3.6, 0.0576)(3.65, 0.0568)(3.7, 0.056)(3.75, 0.0554)(3.8, 0.0547)(3.85, 0.0541)(3.9, 0.0535)(3.95, 0.0529)(4.0, 0.0522)(4.05, 0.0515)(4.1, 0.0508)(4.15, 0.0501)(4.2, 0.0493)(4.25, 0.0486)(4.3, 0.0479)(4.35, 0.0473)(4.4, 0.0467)(4.45, 0.0462)(4.5, 0.0458)(4.55, 0.0454)(4.6, 0.0451)(4.65, 0.0448)(4.7, 0.0445)(4.75, 0.0441)(4.8, 0.0438)(4.85, 0.0435)(4.9, 0.0431)(4.95, 0.0426)(5.0, 0.0422)(5.05, 0.0417)(5.1, 0.0412)(5.15, 0.0407)(5.2, 0.0402)(5.25, 0.0397)(5.3, 0.0392)(5.35, 0.0387)(5.4, 0.0382)(5.45, 0.0377)(5.5, 0.0372)(5.55, 0.0367)(5.6, 0.0362)(5.65, 0.0357)(5.7, 0.0352)(5.75, 0.0347)(5.8, 0.0342)(5.85, 0.0337)(5.9, 0.0332)(5.95, 0.0327)(6.0, 0.0322)(6.05, 0.0317)(6.1, 0.0312)(6.15, 0.0308)(6.2, 0.0303)(6.25, 0.0299)(6.3, 0.0294)(6.35, 0.029)(6.4, 0.0285)(6.45, 0.0281)(6.5, 0.0276)(6.55, 0.0271)(6.6, 0.0267)(6.65, 0.0262)(6.7, 0.0257)(6.75, 0.0252)(6.8, 0.0247)(6.85, 0.0242)(6.9, 0.0237)(6.95, 0.0232)(7.0, 0.0227)(7.05, 0.0222)(7.1, 0.0217)(7.15, 0.0213)(7.2, 0.0209)(7.25, 0.0205)(7.3, 0.0202)(7.35, 0.02)(7.4, 0.0198)(7.45, 0.0197)(7.5, 0.0196)(7.55, 0.0195)(7.6, 0.0194)(7.65, 0.0193)(7.7, 0.0192)(7.75, 0.0191)(7.8, 0.019)(7.85, 0.0189)(7.9, 0.0187)(7.95, 0.0185)(8.0, 0.0184)(8.05, 0.0182)(8.1, 0.018)(8.15, 0.0178)(8.2, 0.0175)(8.25, 0.0173)(8.3, 0.017)(8.35, 0.0167)(8.4, 0.0165)(8.45, 0.0162)(8.5, 0.0158)(8.55, 0.0155)(8.6, 0.0152)(8.65, 0.0148)(8.7, 0.0144)(8.75, 0.014)(8.8, 0.0136)(8.85, 0.0132)(8.9, 0.0127)(8.95, 0.0122)(9.0, 0.0118) (10,0.001) (13,0)
    };
    \addplot[sharp plot,color = black!40!red!60!, line width = 0.3,domain=1:40,samples=100,line legend] coordinates {(1.7, 0)(1.7, 0.1)(12, 0.1)(12,0)
    };
    \node at (axis cs: 7, 0.4) {$k = 75$};
    \node[color = red!60!black!40] at (axis cs: 7, 0.15) {$E_A$};
    % \node[coordinate, right:$k = 20$}] at (5, 0.4) {};
     % \legend{empirical distribution, prediction from $\tilde \Lambda$} 
  \end{axis} 
\end{tikzpicture}
\begin{tikzpicture}   
  \begin{axis}[ xlabel=number of classes $k$, width = 0.55\textwidth, legend cell align = left, legend style={,draw=none,fill=white, fill opacity=0.7}, ymax = 110,  xmax = 85] 
    \addplot [sharp plot,black!80, line width = 1,domain=1:40,samples=100,line legend, smooth] coordinates {(100, 100)};
    \addplot[only marks, mark = o, color = black!80] coordinates {(100, 100)};
    \addplot [dotted,black!60, line width = 1,domain=1:40,samples=100,line legend, smooth] coordinates {(5, 5)(80, 80)};
    \addplot [sharp plot,black!60!green!40!, line width = 1,domain=1:40,samples=100,line legend, smooth] coordinates {(10, 9.4009)(15, 13.9787)(20, 18.8687)(30, 26.4153)(35, 32.8043)(42, 38.7212)(50, 45.8802)(62, 55.5517)(75, 67.8602)};
    \addplot[only marks, mark = o, color = black!60!green!40!] coordinates {(10, 9.4397)(15, 14.2183)(20, 19.049)(30, 28.3995)(35, 32.8623)(42, 39.2463)(50, 46.5711)(62, 57.4712)(75, 67.5774)};
    % \addplot [sharp plot,black!60!red!40!, line width = 1,domain=1:40,samples=100,line legend, smooth] coordinates {(10, 9.9583)(15, 14.7775)(20, 19.9495)(30, 28.1035)(35, 34.9243)(42, 41.4846)(50, 49.4549)(62, 63.7302)(75, 78.913)};
    % \addplot[only marks, mark = o, color = black!60!red!40!] coordinates {(10, 10.0)(15, 15.0)(20, 20.0)(30, 30.0)(35, 35.0)(42, 42.0)(50, 50.0)(62, 62.0)(75, 75.0)};
      \addplot [sharp plot,black!40!blue!60!, line width = 1,domain=1:40,samples=100,line legend, smooth] coordinates {(10, 7.1985)(15, 21.3319)(20, 32.8815)(30, 27.8903)(35, 37.0225)(42, 44.6108)(50, 66.4528)(62, 61.1307)(75, 82.6033)};
    \addplot[only marks, mark = o, color = black!40!blue!60!] coordinates {(10, 5.877)(15, 21.5915)(20, 32.4591)(30, 24.3162)(35, 33.1281)(42, 44.1507)(50, 67.3547)(62, 57.3075)(75, 77.7281)};
    \node[color = black!40!green!60!] at (axis cs: 60,28) {$tr(\Pi_{E_A}UU')$};
    \node[color = black!40!blue!60!] at (axis cs: 25,50) {$\un^T\Pi_{E_A}\un$};
    \legend{prediction with $\tilde \Lambda^z$, value from drawing of $X$, $y = k$}
  \end{axis} 
\end{tikzpicture}
\end{tabular}
\caption{Prediction of the alignement of the signals in the data towards the eigen space of the biggest eigen values of $\frac1n XX^T$ for $p = 200$, $n = k n_k$ where $n_k = 20$ and $k$ is the number of classes taking the values $k = 10, 15, 20, 30, 35, 42, 50, 62, 75$. The signals $u_1,\ldots, u_k$ are drawn randomly and independently following a law $\mathcal N ( 0,I_p)$, and we let $U = (u_1,\ldots, u_k) \in \mathcal M_{p,k}$. Then, for all $j \in [k]$ and $l \in [20]$, $x_{j + ln_k} \sim \mathcal N(u_{j}, I_p)$. \textbf{(top and bottom left)} representation of the spectral distribution of $\frac1n XX^T$ and its prediction with $\tilde \Lambda^z$.%, our quantities related to the highest values generating the eigen space $E_A$ are then computed with an integration of $\tilde Q^{\tilde \Lambda^z}/z$ in the complex plane of the red half rectangle. 
\textbf{(bottom right)} representation (with marks) of the quantities $\tr(\Pi_{E_A} UU^T)$ and $\un^T \Pi_{E_A} \un$ and their prediction (smooth line) with the integration of, respectively, $\Im(\frac1{z\pi}\tr(\tilde Q^{\tilde \Lambda^z}))$ and $\Im(\frac1{z\pi}\un^T\tilde Q^{\tilde \Lambda^z}\un)$ on the path drawn in red on the other graphs. The line $y=k$ represents instances of $\tr(\Pi_A) = k$ that can be approximated integrating $\frac1{z\pi}\tr( \tilde Q^{\tilde \Lambda^z})$. The projection $\tr(\Pi_{E_A} UU^T)$ is a little lower than $k$ because the eigen vectors associated to the highest eigen values of $\frac1n XX^T$ are not perfectly aligned with the signal due to the randomness of $X$.}% Better predictions could have been obtained lowering the integration step.}
\label{fig:spectre_XXT_influence_nombre_de_classe}
\end{figure}


Although it is not particularly needed for practical use, we are now going to show that the mapping $\tilde g : z \to \frac{1}{p} \tr(\tilde R(z))$ is a Stieltjes transform that converges towards $\tilde g$ on $\mathbb C \setminus S^\varepsilon$.
 % (which is a bigger set than $\mathbb C \setminus S^\varepsilon$ on which we approximated $R(z)$).


\subsection{Approach with the Stieltjes formalism}\label{sse:stieltjes_approach}

We present here some arguably well known results (see \cite{kammoun2016no} for instance) about the Stieltjes transform of the eigen value distribution that allows to get some interesting inferences about its support. We start with an interesting identity that gives a direct link between the Stieltjes transforms $g$ and $\tilde g$ with the diagonal matrix $\Lambda^z$ and $\tilde \Lambda^z$. From the equality $Q^z - \frac{1}{nz} XX^TQ^z = I_p$, and the Schur identities~\eqref{eq:lien_q_qj_schur} we can deduce that:
\begin{align*}
  g(z) 
  &=-\frac{1}{pz} \tr(Q^z)
  = -\frac{1}{z} - \frac{1}{npz^2} \sum_{i=1}^n x_i^TQ^zx_i\\
  &=-\frac{1}{z} - \frac{1}{npz}\sum_{i=1}^n \frac{x_i^T Q_{-i}x_i}{\Lambda^z_i}
  =\frac{1}{z} \left(\frac{n}{p} - 1\right) - \frac{1}{p} \sum_{i=1}^n \frac{1}{\Lambda_i^z}
  = g^{\Lambda^z}(z),
\end{align*}
% \end{enumerate}
with the notation $g^{D^z}$, defined for any mapping $D: \mathbb H\ni z \mapsto D^z \in\mathcal D_n(\mathbb H)$ as\footnote{The Steiltjes transform of the spectral distribution of $\frac{1}{n}X^TX$ is $\check g = \check g^{\Lambda^z}$, where for all $D: \mathbb H\ni z \mapsto D^z \in\mathcal D_n(\mathbb H)$, $\check g^{D^z} : z \longmapsto  - \frac{1}{p} \sum_{i=1}^n \frac{1}{D^z}$}:
\begin{align*}
  g^{D^z} : z \longmapsto \frac{1}{z} \left(\frac{n}{p} - 1\right) - \frac{1}{p} \sum_{i=1}^n \frac{1}{D^z}.
\end{align*}
Interestingly enough, if we denote $\tilde g \equiv  g^{\tilde \Lambda}$, then one can rapidly check that we have the equality $\tilde g = -\frac{1}{pz} \tr(\tilde Q^{\tilde \Lambda^z})$.
To show that $\tilde g$ is a Stieltjes transform, we will employ the following well known theorem that can be found for instance in \cite{BOL97}:
\begin{theorem}\label{the:condition_stieltjes transform}
  Given an analytic mapping $f: \mathbb H \to \mathbb H$, if $\lim_{y \to +\infty} -iyf(iy) = 1$ then $f$ is the Stieltjes transform of a probability measure $\mu$ that satisfies the two reciprocal formulas:
  \begin{itemize}
    \item $f(z) = \int \frac{\mu(d \lambda)}{\lambda - z}$,
    % \item for any $x \in \mathbb R$, $\mu(\{x\}) = \lim_{y \to 0^+} y \Im (f(x+iy))$,
    \item for any continuous point\footnote{We can add the property $\forall x \in \mathbb R$, $\mu(\{x\}) = \lim_{y \to 0^+} y \Im (f(x+iy))$, here for $\mu$ to be continuous in $a,b$, we need $\mu(\{a\}) = \mu(\{b\}) = 0$} $a<b$: $\mu([a,b]) = \lim_{y\to 0+}\frac{1}{\pi} \int_a^b \Im(f(x+iy))dx$.
  \end{itemize}
  % for any continuity points $a,b \in \mathbb R$ of $\mu$. 
  If, in particular, $\forall z \in \mathbb H$, $zf(z) \in \mathbb H$, then $\mu(\mathbb R^-) = 0$ and $f$ admits an analytic continuation on $\mathbb C \setminus (\mathbb R_+ \cup \{0\})$.
\end{theorem}

The first hypothesis to verify in order to employ Theorem~\ref{the:condition_stieltjes transform} is the analycity of $\tilde g$, that originates from the analycity of $z \to \tilde \Lambda^z$. We can show with limiting arguments that $\tilde \Lambda^z$ is analytical as a limit of a sequence of analytical mappings. However, although it is slightly more laborious, we prefer here to prove the analicity from the original definition. First let us show the continuity with Proposition~\ref{pro:equation_proche_implique_solution_proche_version2}.
\begin{proposition}\label{pro:D_h_continuous}
  The mapping $z\mapsto \tilde \Lambda^z$ is continuous on $\mathbb H$.% \cap \{\Im(z) \leq -\nu\}$ for a given $\nu >0$.
\end{proposition}
\begin{proof}
    Given $z \in \mathbb H$, we consider a sequence $(t_s)_{s \in \mathbb N} \in \{w \in \mathbb C \ | \ w +z \in \mathbb H\}$ such that $\lim_{s \to \infty} t_s = 0$. Let us verify the assumption of Proposition~\ref{pro:equation_proche_implique_solution_proche_version2} where for all $s\in \mathbb N$, $f^s =  I^{z+t_s}$, $\tilde \Gamma^s = \tilde \Lambda^{z+t_s}$ and $\Gamma^s = \tilde \Lambda^z$ (it does not depend on $s$). We already know from Proposition~\ref{pro:I_z_contractante} that $f^s$ are all contracting for the stable semi-metric with a Lipschitz parameter $\lambda<1$ that can be chosen independent from $s$ for $s$ big enough. 
    Let us express for any $s \in \mathbb N$ and any $i\in [n]$:
  \begin{align}\label{eq:identite_f^s_m_f_0}
    f^s(\Gamma^s)_i - \Gamma^s_i
    &= I^{z+t_s}(\tilde \Lambda^z)_i - \tilde \Lambda^z_i 
    = t_s %\underset{s\to 
  \end{align}
   \sloppypar{Noting that for $s$ sufficiently big, $\Im(I^{z+t_s}(\tilde \Lambda^{z})) = \Im(t_s) + \Im(\tilde \Lambda^z) \geq \frac{\Im(\tilde \Lambda^z)}{4} \geq \frac{\Im(z)}{4}$, we see that $d_s(\Im(f^s(\Gamma^s)_i),\Im(\Gamma^s_i)) \leq \frac{4|\Im(t^s)|}{\Im(z)} \underset{s\to \infty}{\longrightarrow} 0$. Therefore, the assumptions of Proposition~\ref{pro:equation_proche_implique_solution_proche_version2} are satisfied and we can conclude that there exists $K>0$ such that for all $s\in \mathbb N$:}
  \begin{align*}
     \left\Vert \frac{\tilde \Lambda^{z+t_s}-\tilde \Lambda^z}{\sqrt{\Im(\tilde \Lambda^{z+t_s})\Im(\tilde \Lambda^z)}}\right\Vert \leq  \frac{K|t_s|}{\inf_{i\in [n]} \sqrt{\Im(\tilde \Lambda^{z+t_s})\Im(\tilde \Lambda^z)}} \leq \frac{2K |t_s|}{\Im(z)}.
  \end{align*}
  % since $\Im(I^{z+t_s}(\tilde \Lambda^{z})) = \Im(t_s) + \Im(\tilde \Lambda^z) \geq \frac{\Im(\tilde \Lambda^z)}{4} \geq \frac{\Im(z)}{4}$, for $s$ sufficiently big.
  Besides, we can also bound:
  \begin{align*}
    \sqrt{\Im(\tilde \Lambda^{z+t_s})} \leq \frac{2\sqrt{\Im(\tilde \Lambda^z)}}{\Im(z)}(\Im(\tilde \Lambda^z) + Kt_s)\leq O(1),
  \end{align*}
  That directly implies that $\|\tilde \Lambda^{z+t_s}-\tilde \Lambda^z\| \leq O(t_s) \underset{s \to \infty}{\longrightarrow} 0$, and consequently, $z \mapsto \tilde \Lambda^z$ is continuous on $\mathbb H$.
  \end{proof}
  % To show the analycity of $z \mapsto\tilde \Lambda^z$, we are going to 
  Let us now show that $z \mapsto\tilde \Lambda^z$ is differentiable. Employing again the notation $f^t =  \mathcal I^{z+t}$, we can decompose (noting for $D\in \mathcal{D}_{n}, R(D) \equiv (zI_p - \frac{1}{n} \sum_{i=1}^n )$:
  \begin{align*}
    \left(\tilde \Lambda^{z+t}-\tilde \Lambda^z\right)
    &=  \left(f^{t}(\tilde \Lambda^{z+t})-f^{t}(\tilde \Lambda^z) + f^{t}(\tilde \Lambda^{z})-f^{0}(\tilde \Lambda^z)\right)\\
    & =  \diag_{i \in[n]}\left(\frac{1}{n}\tr \left(\Sigma_i \tilde Q^{\tilde \Lambda^{z+t}}\frac{1}{n} \sum_{j=1}^n \frac{\tilde \Lambda^{z+t}_j - \tilde \Lambda^z_j}{\tilde \Lambda^{z+t}_j\tilde \Lambda^z_j}\Sigma_j \tilde Q^{\tilde \Lambda^{z}} \right)\right) + t I_n
  \end{align*}
  Now, if we introduce the vector $a(t) = \left(\tilde \Lambda_i^z - \tilde \Lambda_i^{z+t}\right)_{1\leq i\leq n} \in \mathbb R^n$,
  % \begin{align*}
    % a(t) &= \left(\frac{1}{n}\tr \left(\Sigma_i R(\tilde \Lambda^{z+t})AR(\tilde \Lambda^{z})\right)\right)_{1\leq i\leq n} \in \mathbb R^n,\\
     % b(t) &= \left(\frac{1}{n}\tr \left(\Sigma_j R(\tilde \Lambda^{z})R(\tilde \Lambda^{z})\right)\right)_{1\leq i\leq n} \in \mathbb R^n
  % \end{align*}
  and for any $D,D' \in \mathcal D_n(\mathbb H)$, the matrix:
  \begin{align*}
    \Psi(D,D') = \left(\frac{1}{n}\frac{\tr \left(\Sigma_i R(D)\Sigma_jR(D')\right)}{D_jD'_j}\right)_{1\leq  i, j \leq n} \in \mathcal M_{n}&
    % \Psi(t) = \left(\frac{1}{n}\frac{\tr \left(\Sigma_i R(\tilde \Lambda^{z+t})\Sigma_jR(\tilde \Lambda^{z})\right)}{\tilde \Lambda^{z+t}_jD'_j}\right)_{1\leq  i, j \leq n} \in \mathcal M_{n}&
    % &\text{and}&
    % &\tilde \Psi(t) = \Psi(t) - \diag(\Psi(t)),
  \end{align*}
  % and $\tilde \Psi(t) = \Psi(t) - \diag(\Psi(t))$, w
  We have the equation:
  \begin{align}\label{eq:point_fixe_a}
    a(t)= \Psi(\tilde \Lambda^z, \tilde \Lambda^{z+t}) a(t) + t\un.
  \end{align}
To be able to solve this equation we need:
\begin{lemma}\label{lem:I_n_m_PsiDD_inversible}
  Given any $z,z' \in \mathbb H$, $I_n - \Psi(\tilde \Lambda^z,\tilde \Lambda^{z'})$ is invertible.
  % Given any $D,D' \in \mathcal D_n(\mathbb H)$, $I_n - \Psi(D,D')$ is invertible.
\end{lemma}

\begin{proof}
  We are going to show the injectivity of $I_n - \Psi(\tilde \Lambda^{z},\tilde \Lambda^{z'})$. Let us introduce a vector $x \in \mathbb R^n$ such that $x = \Psi(\tilde \Lambda^{z},\tilde \Lambda^{z'}) x$. We can bound thanks to Cauchy-Schwatz inequality, with similar calculus as in the proof of Proposition~\ref{pro:I_z_contractante}:
  \begin{align*}
    |x_i| 
    &=  \left\vert \frac{1}{n} \tr \left(\Sigma_i R(\tilde \Lambda^{z}) \sum_{j=1}^n \frac{x_j \Sigma_j}{\sqrt{\Im(\tilde \Lambda^{z}) \Im(\tilde \Lambda^{z'}) }}\frac{\sqrt{\Im(\tilde \Lambda^{z}) \Im(\tilde \Lambda^{z'}) }}{\tilde \Lambda^{z}_j\tilde \Lambda^{z'}_j}R(\tilde \Lambda^{z'})\right)\right\vert\\
    &\leq \sup_{j\in [n]} \left\vert \frac{x_j}{\sqrt{\Im(\tilde \Lambda^{z}) \Im(\tilde \Lambda^{z'}) }}\right\vert \sqrt{ \Im(\tilde \Lambda^{z}_i) - \Im(z)} \sqrt{ \Im(\tilde \Lambda^{z'}_i) - \Im(z')}
    % &\leq \sup_{j\in [n]} \left\vert \frac{x_j}{\sqrt{\Im(\tilde \Lambda^{z}) \Im(\tilde \Lambda^{z'}) }}\right\vert \sqrt{\frac{1}{n} \tr \left(\Sigma_i R(\tilde \Lambda^{z}) \sum_{j=1}^n \frac{\Im(\tilde \Lambda^{z})\Sigma_j}{|\tilde \Lambda^{z}_j|^2}\bar R(\tilde \Lambda^{z})\right)}\\
    % &\hspace{1cm} \cdot \ \sqrt{\frac{1}{n} \tr \left(\Sigma_i R(\tilde \Lambda^{z'}) \sum_{j=1}^n \frac{\Im(\tilde \Lambda^{z'})\Sigma_j}{|\tilde \Lambda^{z'}_j|^2}\bar R(\tilde \Lambda^{z'})\right)}
    % &\leq 
  \end{align*}
  therefore, if we denote $\|x\|_{\tilde \Lambda} \equiv \sup_{i\in [n]} \left\vert \frac{x_j}{\sqrt{\Im(\tilde \Lambda^{z'}) \Im(\tilde \Lambda^{z'}) }}\right\vert$, we have then the bound:
  \begin{align*}
    \|x\|_{\tilde \Lambda^{z'},\tilde \Lambda^{z'}} \leq \|x\|_{\tilde \Lambda^{z'},\tilde \Lambda^{z'}} \sqrt{(1-\phi(z,\tilde \Lambda^{z'}))(1-\phi(z,\tilde \Lambda^{z'}))}
  \end{align*}
  which directly implies that $x=0$ since we know that $\phi(z,\tilde \Lambda^{z^({}'{}^)}) = \frac{\Im(w)}{\sup_{1\leq i \leq n}\Im(I^w(\tilde \Lambda^{z^({}'{}^)}))_i} \in (0,1)$.
\end{proof}
% Lemma~\ref{lem:I_n_m_PsiDD_inversible} allows us in particular to show that since 
From the continuity of $(z,z') \mapsto \Psi(\tilde \Lambda^z, \tilde \Lambda^{z'})$, and the limit $\lim_{x \to \infty} \|\Psi(\tilde \Lambda^x, \tilde \Lambda^{x})\| = 0$ (see the proof of Proposition~\ref{pro:mu_support_compact}), we can deduce as a side result from Lemma~\ref{lem:I_n_m_PsiDD_inversible}:
\begin{lemma}\label{lem:Psi_inf_1}
  Given any $z,z' \in \mathbb H$, $\|\Psi(\tilde \Lambda^z,\tilde \Lambda^{z'})\| <1$
\end{lemma}
The continuity of $z \mapsto \tilde \Lambda^z$ given by Proposition~\ref{pro:D_h_continuous} and the continuity of the inverse operation on matrices (around $I_n - \Psi(\tilde \Lambda^z, \tilde \Lambda^{z})$ which is invertible), allows us to let $t$ tend to zero in the equation
\begin{align*}
  \frac{1}{t}a(t)= (I_n-\Psi(\tilde \Lambda^z, \tilde \Lambda^{z+t}))^{-1} \un,
\end{align*}
to obtain:
\begin{proposition}\label{pro:Lambda_z_analytic}
  The mapping $z\mapsto \tilde \Lambda^z$ is analytic on $\mathbb H$, and satisfies:%\footnote{Although we will not need it, we can note here that $z \to \Lambda^z$ is therefore also differentiable and satisfies:
  % \begin{align*}
  %   \frac{\partial \Lambda^z}{\partial z} = \diag \left(\frac{1}{z}(I_n-\Psi(z\Lambda^z, z\Lambda^z))^{-1} \un- \frac{\Lambda^z}{z}\right)
  % \end{align*}}:
  \begin{align*}
    \frac{\partial \tilde \Lambda^z}{\partial z} = \diag \left((I_n-\Psi(\tilde \Lambda^z, \tilde \Lambda^z))^{-1} \un\right)
  \end{align*}
\end{proposition}

We can then conclude first that for all $i \in [n]$, the mappings $z \to \frac{1}{\Lambda^z_i}$ are Stieltjes transforms.
\begin{proposition}\label{pro:Lambda_tilde_stieltjes_transform}
  For all $i \in [n]$, there exists a distribution $\tilde \mu_i$ with support on $\mathbb R_+$ whose Stieltjes transform is $z \mapsto -\frac{1}{\tilde \Lambda_i^z}$
\end{proposition}
\begin{proof}
  We just check the hypotheses of Theorem~\ref{the:condition_stieltjes transform}. We already know that $z \mapsto -\frac{1}{\tilde \Lambda^z_i}$ is analytical thanks to Proposition~\ref{pro:Lambda_z_analytic} and the lower bound $\tilde \Lambda^z_i \geq \Im(z)>0$. Besides, $\forall z \in \mathbb H$:
  \begin{align*}
    \Im \left(-\frac{1}{\tilde \Lambda^z_i}\right) = \frac{\Im(\tilde \Lambda^z_i)}{|\tilde \Lambda^z_i|} >0&
    &\text{and}&
    &\Im \left(-\frac{z}{\tilde \Lambda^z_i}\right) = \frac{\Im(\tilde \Lambda^z_i/z)}{|\tilde \Lambda^z_i/z|} >0,
  \end{align*}
  since $\tilde \Lambda^z \in \mathcal D_{I_z}$.
  Finally recalling from Lemma~\ref{lem:borne_L_I^z} that for all $y \in \mathbb R_+$, $\|\tilde Q^{\tilde \Lambda^{iy}}\| \leq \frac{|iy|}{\Im(iy)} = 1$, we directly see that for all $j \in [n]$:
  \begin{align*}
    \frac{\tilde \Lambda^{iy}_j}{iy} = 1 + \frac{1}{iyn} \tr(\Sigma_j \tilde Q^{\tilde \Lambda^{iy}}) \underset{y \to +\infty}{\longrightarrow} 1.
  \end{align*}
  we can then conclude with Theorem~\ref{the:condition_stieltjes transform}.
\end{proof}
We can then deduce easily that $\tilde g$ is also a Stieltjes transform with an interesting characterization of its measure with the $\tilde \mu_i$ (defined in Proposition~\ref{pro:Lambda_tilde_stieltjes_transform}).
% \begin{theorem}\label{the:Stieltjes_transform_de_tilde_Lambda}
%   The mapping $\tilde g : z \to  \frac{1}{p}\tr(\tilde R)$ is the Stieltjes transform of a measure $\tilde \mu$ of compact support $\tilde S \subset \mathbb R_+$.
% \end{theorem}
\begin{proposition}\label{pro:g_stieltjes}
  % There exists a distribution $\tilde \mu$ with support on $\mathbb R_+$ whose Stieltjes transform is 
  The mapping $\tilde g$ is the Stieltjes transform of the measure:
  \begin{align*}
    \tilde \mu = \left(\frac{n}{p} - 1\right) \delta_{0} + \frac{1}{p} \sum_{i=1}^n \tilde \mu_i,
  \end{align*}
  where $\delta_0$ is the Dirac measure on $0$ (if $p>n$, then the measures $\tilde \mu_1, \ldots, \tilde \mu_n$ contains Dirac weights on zero that cancel the term $-\frac{p-n}{p} \delta_{0}$).
\end{proposition}
Recall that $\tilde \mu$, satisfies $\tilde g(z) = \int_0^{+\infty} \frac{1}{\lambda - z} d\tilde \mu(\lambda)$, and let us denote $\tilde S$, its support. This formula implies that $\tilde g$ is analytic on $\mathbb C \setminus \tilde S$ and that for all $z \in \mathbb C \setminus \tilde S$, $\tilde g(\bar z) = \overline{\tilde g(z)}$. 
To precise the picture let us provide a result of compactness of $\tilde S$.

\begin{proposition}\label{pro:mu_support_compact}
  The measure $\tilde \mu$ has a compact support $\tilde S \subset \mathbb R_ +$ and $\sup \tilde S \leq O(1)$.
\end{proposition}
  \begin{proof}
  % \textcolor{red}{Ã  mettre dans l'annexe}
  We are going to show that for $x$ sufficiently big, $\lim_{y \to 0^+}\Im(g(x+iy)) = 0$, which will allow us to conclude thanks to the relation between $\tilde \mu$ and $\tilde g$ given in Theorem~\ref{the:condition_stieltjes transform}.
  Considering $z = x + iy \in \mathbb H$, for $x,y \in \mathbb R$ and such that
  \begin{align*}
     % x\geq x_0 \equiv \max \left(\frac{\nu}{2}\right)
     x\geq x_0 \equiv \max \left(\frac{8}{n}\sup_{i\in [n]} \tr(\Sigma_i),4\nu\right)
   \end{align*} 
   let us show first that $\forall i \in [n]$, $\Re(\tilde \Lambda_i^z)\geq \frac{x_0}2$. This is a consequence of the fact that $\mathcal I^z$ is stable on $\mathcal A \equiv \mathcal D_n(\{t \geq \frac{x}{2}\} + i \mathbb R_+^*) \cap \mathcal D_{I^z}$. 
   Indeed, given $L \in \mathcal A$
    % we know from the proof of Proposition~\ref{pro:Lambdaz_well_defined_onC--} that $\|R(D)\| \leq 2$ and therefore:
    \begin{align*}
      \Re \left( (\tilde Q^L)^{-1}\right) 
      = I_p - \frac{1}{n } \sum_{i=1}^n \frac{\Re(\Lambda_i)\Sigma_i}{|L_i|^2} 
      \geq I_p - \frac{1}{n } \sum_{i=1}^n \frac{\Sigma_i}{\Re(L_i)} \geq \frac{1}{2}
      % \Re \left( (\tilde Q^L/z)^{-1}\right) = \Im\left(zI_p - \frac{1}{n } \sum_{i=1}^n \frac{\Sigma_i}{L_i/z}\right) = \Im(z)I_p + \frac{1}{n } \sum_{i=1}^n \frac{\Im(L_i/z)\Sigma_i}{|L_i/z|^2} \geq \Im(z)I_p,
    \end{align*}
    and as we already know, since $\mathcal D_{I^z}$, $\Im \left( (\tilde Q^L)^{-1}\right) \geq 0$, therefore, $\|\tilde Q^L\| \leq 2$. We can then bound: 
  \begin{align*}
    \Re(\mathcal I^z(L)_i) 
    &= x - \frac{1}{n} \tr \left(\Sigma_i{\tilde Q}^L \left(1 - \frac{1}{n} \sum_{j=1}^n \frac{\Re(L_j)\Sigma_j}{|L_j|^2}\right)\bar {\tilde Q}^L\right)\\
    &\geq x - \frac{4}{n} \tr \left(\Sigma_i\right) \geq \frac{x}{2}.
  \end{align*}
  Thus as a limit of elements of $\mathcal A$, $\tilde \Lambda^z \in \mathcal A$, and $\forall i \in [n]$, $\Re(\tilde \Lambda^z_i) \geq \frac{x}2$. 

  Besides, let us bound:
  \begin{align*}
    \Im(\tilde \Lambda^z_i) 
    &= y + \frac{1}{n} \tr \left(\Sigma_iR(\tilde \Lambda^z) \frac{1}{n} \sum_{j=1}^n \frac{\Im(\tilde \Lambda^z_j)\Sigma_j}{|\tilde \Lambda^z_j|^2}\bar R(\tilde \Lambda^z)\right)\\
    &\leq y + \frac{4}{n} \tr \left(\Sigma_i\right) \left\Vert \frac{1}{n} \sum_{j=1}^n \Sigma_j\right\Vert \sup_{j\in [n]}\frac{\Im(\tilde \Lambda^z_j)}{\Re(\tilde \Lambda^z_j)^2}.
     % \ \ \leq y + \frac{2\nu }{x}\sup_{j\in [n]}\Im(\tilde \Lambda^z_j)
  \end{align*}
  We can further bound $\left\Vert \frac{1}{n} \sum_{j=1}^n \Sigma_j\right\Vert \leq \nu$, since $\frac{1}{n}\|XX^T\| = (\|X\|/\sqrt n)^2 \in \nu \pm \mathcal E_1(1/\sqrt n)$ and therefore $\left\Vert \frac{1}{n} \sum_{j=1}^n \Sigma_j\right\Vert \leq \mathbb E [\frac{1}{n}\|XX^T\|] \leq \nu + O(1/\sqrt n) \leq 2 \nu$. Besides $\Re(\tilde \Lambda^z_j)^2 \geq \frac{x x_0}{4}$, we can eventually bound $\sup_{j\in [n]}\Im(\tilde \Lambda^z_j) \leq y + \frac{2\nu }{x}\sup_{j\in [n]}\Im(\tilde \Lambda^z_j)$, which implies, for $x$ sufficiently big:
  \begin{align*}
   \sup_{j\in [n]}\Im(\tilde \Lambda^z_j) \leq \frac{y}{1 - \frac{2\nu }{x}} \ \ \underset{y \to 0^+}{\longrightarrow} \ 0.
  \end{align*}
  We can then conclude letting $y$ tend to $0$ in the formulation $\tilde g = g^{\tilde \tilde \Lambda}$:
  \begin{align*}
    \Im(\tilde g(x+iy)) = \frac{y}{x^2 + y^2} \left(\frac{n}{p} - 1\right) + \frac{1}{p} \sum_{i=1}^n\frac{\Im(\tilde \Lambda_i^z)}{\Re(\tilde \Lambda_i^z)^2 + \Im(\tilde \Lambda_i^z)^2}\underset{y \to 0^+}{\longrightarrow} \ 0
  \end{align*}
\end{proof}

We end this section with the proof of the convergence of the Stieltjes transform of the spectral distribution $g$ towards $\tilde g$.

% We introduce the semi-norm $\| \cdot \|_{S_{-0}^\varepsilon}$, defined for any $f \in \mathcal F(\mathbb C)$ as:
%   \begin{align*}
%     \| f \|_{S_{-0}^\varepsilon} = \sup_{z \in \mathbb C \setminus S^\varepsilon_{-0}} |f(z)|.
%   \end{align*}
We introduce the semi-norm $\| \cdot \|_{S^\varepsilon}$, defined for any $f \in \mathcal F(\mathbb C)$ as:
  \begin{align*}
    \| f \|_{S^\varepsilon} = \sup_{z \in \mathbb C \setminus S^\varepsilon} |f(z)|.
  \end{align*}

\begin{theorem}\label{the:concentration_transformee_de_stieltjes_main_res}
$g \ | \ \mathcal A_Q \in \tilde g \pm \mathcal E_2 (1/\sqrt{pn})$ in $(\mathbb C^{\mathbb C \setminus S^\varepsilon}, \| \cdot \|_{S^\varepsilon})$.
\end{theorem}

\begin{proof}
  % Be careful that we want here a concentration for the infinite norm on $\mathbb C \setminus S^\varepsilon$. 
  % We first need to show the concentration of $g$. 
  % Two cases are under study:
  % \begin{itemize}
  %   \item When $p \leq n$, $\kappa_z = \frac{|z|}{1+|z|}$, and therefore we can show as in the proof of Proposition~\ref{pro:concentration_resolvente_1} that the mapping $g$ defined for any $z \in \mathbb C \setminus (S_{-0}^\varepsilon \cup \{0\})$ with the identity $g(z) = -\frac{1}{pz}\tr(Q^z)$ is, under $\mathcal A_Q$ a $O(1/\sqrt{pn})$-Lipschitz transformation of $X$, thus $(g \ | \ \mathcal A_Q) \propto \mathcal E_2(1/\sqrt{pn})$ in $(\mathcal F(\mathbb C), \|\cdot \|_{S_{-0}^\varepsilon})$. 
  %   We can then conclude thanks to the bound:
  % \begin{align*}
  %   \sup_{z \in \mathbb C \setminus S_{-0}^\varepsilon} \left\vert \mathbb E_{\mathcal A_Q}[g(z)] - \tilde g(z)\right\vert 
  %   &\leq \sup_{z \in \mathbb C \setminus S_{-0}^\varepsilon} \frac{1}{zp} \left\vert \tr \left( \mathbb{E}_{\mathcal A_Q} \left[Q^z\right] - \tilde Q^{\tilde \Lambda^z}\right) \right\vert \\
  %   &\leq \sup_{z \in \mathbb C \setminus S_{-0}^\varepsilon} O \left(\frac{\kappa_z}{|z|\sqrt {np}}\right) \leq O \left(\frac{1}{\sqrt{np}}\right).
  % \end{align*}
  %   \item When $p \geq n$ $\check \kappa_z = \frac{|z|}{1+|z|}$, and we are going to employ the fact (see Lemma~\ref{lem:Borne_Lambda}) that then $|\Lambda^z| \geq O(1)$. Indeed, thanks to this lower bound and the identity:
  %   \begin{align*}
  %     g(z) = \frac{1}{z} \left(\frac{n}{p} - 1\right) - \frac{1}{p} \sum_{i=1}^n \frac{1}{\Lambda_i^z},
  %   \end{align*}
  %   we can show as in the proof of Lemma~\ref{lem:Concentration_lambda} that $g$ is, under $\mathcal A_Q$, a $O(1/\sqrt{pn})$-Lipschitz transformation of $X$, and as such $(g \ | \ \mathcal A_Q) \propto \mathcal E_2(1/\sqrt{pn})$ in $(\mathcal F(\mathbb C), \|\cdot \|_{S_{-0}^\varepsilon})$. And this time we conclude with the bound:
  % \begin{align*}
  %   \sup_{z \in \mathbb C \setminus S_{-0}^\varepsilon} \left\vert \mathbb E_{\mathcal A_Q}[g(z)] - \tilde g(z)\right\vert 
  %   &\leq \sup_{z \in \mathbb C \setminus S_{-0}^\varepsilon} \frac{1}{p}\sum_{i=1}^n \mathbb E \left[\frac{\left\vert\Lambda_i^z - \tilde \Lambda_i^z\right\vert}{\left\vert\Lambda_i^z  \tilde \Lambda_i^z\right\vert}\right] \\
  %   &\leq \sup_{z \in \mathbb C \setminus S_{-0}^\varepsilon} O \left(\frac{1}{p}\sum_{i=1}^n \mathbb E_{\mathcal A_Q} \left[\left\vert\Lambda_i^z - \hat \Lambda_i^z\right\vert\right] + \left\vert\hat \Lambda_i^z - \tilde \Lambda_i^z\right\vert\right)\\
  %   & \leq O \left(\frac{1}{p}\right) \leq O \left(\frac{1}{\sqrt{pn}}\right)
  % \end{align*}
  % \end{itemize}
  We know from remark~\ref{rem:borne_kappa_z_z_sur_S} that $O(\frac{\kappa_z}{z}) \leq O(1)$ and therefore we can show as in the proof of Proposition~\ref{pro:concentration_resolvente_1} that the mapping $g$ defined for any $z \in \mathbb C \setminus (S^\varepsilon \cup \{0\})$ with the identity $g(z) = -\frac{1}{pz}\tr(Q^z)$ is, under $\mathcal A_Q$ a $O(1/\sqrt{pn})$-Lipschitz transformation of $X$, thus $(g \ | \ \mathcal A_Q) \propto \mathcal E_2(1/\sqrt{pn})$ in $(\mathcal F(\mathbb C), \|\cdot \|_{S^\varepsilon})$. 
    We can then conclude thanks to the bound:
  \begin{align*}
    \sup_{z \in \mathbb C \setminus S^\varepsilon} \left\vert \mathbb E_{\mathcal A_Q}[g(z)] - \tilde g(z)\right\vert 
    &\leq \sup_{z \in \mathbb C \setminus S^\varepsilon} \frac{1}{zp} \left\vert \tr \left( \mathbb{E}_{\mathcal A_Q} \left[Q^z\right] - \tilde Q^{\tilde \Lambda^z}\right) \right\vert \\
    &\leq \sup_{z \in \mathbb C \setminus S^\varepsilon} O \left(\frac{\kappa_z}{|z|\sqrt {np}}\right) \leq O \left(\frac{1}{\sqrt{np}}\right).
  \end{align*}
  % We retrieve then the concentration inequality of the theorem thanks to the bound on $\mathbb P(\mathcal A_Q)$ given in Lemma~\ref{lem:A_Q_overwhelming}.
\end{proof}

\begin{figure}
\centering
\begin{tabular}{cc}
\begin{tikzpicture}   
  \begin{axis}[ y label style={at={(-0.12,0.5)}}, width = 0.55\textwidth,xlabel=eigenvalues $\lambda$, ylabel=spectral density $d\mu(\lambda)$, legend cell align = left, legend style={draw=none},ytick ={0,0.2,0.4}, ymax = 0.6, xtick={0,5,10,15}, xmax = 15.5] 
    \addplot [blue,ybar,fill, fill opacity=0.3, bar width = 0.7,ybar legend] coordinates {(0.5, 0.4861)(1.5, 0.25)(2.5, 0.0139)(3.5, 0.0)(4.5, 0.0278)(5.5, 0.0278)(6.5, 0.0417)(7.5, 0.0278)(8.5, 0.0278)(9.5, 0.0139)(10.5, 0.0278)(11.5, 0.0278)(12.5, 0.0139)(13.5, 0.0139)} \closedcycle;
    \addplot[sharp plot,black!60, line width = 1,domain=1:40,samples=100,line legend, smooth] coordinates {(0,0) (0.5, 0.4752)(1.0, 0.3449)(1.5, 0.2317)(2.0, 0.1162)(2.5, 0.0137) (2.6, 0.005) (3.1, 0.00) (3.15, 0.00) (3.3, 0.00) (3.5, 0.0) (3.7, 0.00) (3.85, 0.00) (3.9, 0.002)(4.5, 0.0269)(5.0, 0.0305)(5.5, 0.0339)(6.0, 0.0342)(6.5, 0.0328)(7.0, 0.0324)(7.5, 0.0316)(8.0, 0.0301)(8.5, 0.0291)(9.0, 0.0274)(9.5, 0.0262)(10.0, 0.0244)(10.5, 0.023)(11.0, 0.0214)(11.5, 0.0192)(12.0, 0.0173)(12.5, 0.0153)(13.0, 0.0138)(13.5, 0.0115)(14.0, 0.0078) (14.15, 0.00) (14.2, 0.00) (15, 0.00)
    };
  \end{axis} 
\end{tikzpicture}
\begin{tikzpicture}   
  \begin{axis}[ y label style={at={(-0.08,0.5)}}, width = 0.55\textwidth,xlabel=eigenvalues $\lambda$, legend cell align = left, legend style={draw=none},ytick ={0,0.2,0.4}, ymax = 0.6, xtick={0,5,10,15}, xmax = 15.5] 
    \addplot [blue,ybar,fill, fill opacity=0.3, bar width = 0.3,ybar legend] coordinates {(0.25, 0.0833)(0.75, 0.3056)(1.25, 0.2778)(1.75, 0.1944)(2.25, 0.1944)(2.75, 0.1944)(3.25, 0.1389)(3.75, 0.0833)(4.25, 0.1111)(4.75, 0.0833)(5.25, 0.0833)(5.75, 0.0556)(6.25, 0.0833)(6.75, 0.0278)(7.25, 0.0556)(7.75, 0.0278)} \closedcycle;
    \addplot[sharp plot,black!60, line width = 1,domain=1:40,samples=100,line legend, smooth] coordinates {(0,0) (0.5, 0.305)(1.0, 0.2799)(1.5, 0.2203)(2.0, 0.1996)(2.5, 0.1645)(3.0, 0.1486)(3.5, 0.1298)(4.0, 0.1153)(4.5, 0.1019)(5.0, 0.0873)(5.5, 0.0775)(6.0, 0.0661)(6.5, 0.0513)(7.0, 0.0411)(7.5, 0.0256)(8.0, 0.0028) (8.0, 0.0028) (8.05, 0.00) (8.15, 0.00) (8.5, 0.00) (15, 0.00)
    };
     \legend{empirical distribution, prediction from $\tilde \Lambda$} 
  \end{axis} 
\end{tikzpicture}
\end{tabular}
\caption{Spectral distribution of $\frac{1}{n}XX^T$ and its deterministic estimate obtained from $\tilde \Lambda$ for $n=160$ and $p=80$. Introducing $P$ an orthogonal matrix chosen randomly and $\Sigma\in \mathcal D_p$ such that for $j\in\{1,\dots, 20\}$, $\Sigma_j = 1$ and for $j\in\{21,\dots, 80\}$, $\Sigma_j = 8$, we chose \textbf{(left)} $\forall i \in [n]$, $x_i \sim \mathcal N(0, \Sigma)$ and \textbf{(right)} $\forall i \in [n]$, $x_i \sim \mathcal N(0, \Sigma_i)$, where $\Sigma_1 = \Sigma$ and $\Sigma_{i+1} = P^T \Sigma_i P$ for all $i \in[n]$. The histograms would have been similar for any other concentrated vectors $x_1,\ldots, x_n$ having the same covariances and comparable observation diameter (see Definition~\ref{def:concentrated_sequence})}
\label{fig:spectre_XXT_rotation_covariance}
\end{figure}


In particular, thanks to the Cauchy identity, for any analytical mapping $f: \mathbb C \to \mathbb C$, since the integration on bounded paths of $\mathbb C \setminus S^\varepsilon$ is Lipschitz for the norm $\| \cdot \|_{S^\varepsilon}$, we can approximate:
\begin{align*}
  \mathbb P \left( \left\vert \int f(\lambda) d\mu(\lambda) - \frac{1}{2i\pi} \oint_\gamma f(z)g(z) dz\right\vert\geq t\right) \leq C e^{-cnpt^2} + C e^{-cn},
\end{align*}
for any closed path $S^\varepsilon \subset \gamma \subset \mathbb C \setminus S^\varepsilon$ with length $l_\gamma$ satisfying $l_\gamma\leq O(1)$. There exists a correspondence between a distribution and its Stieltjes transform: denoting $\mu$ the spectral distribution of $\frac{1}{n}XX^T$, we have indeed for any real $a<b$:
\begin{align*}
    \mu([a,b]) = \lim_{y \to 0} \frac{1}{\pi } \int_{a}^b \Im(g(x+iy)) dx.
\end{align*}
As seen on Figure~\ref{fig:spectre_XXT_rotation_covariance}, this measure is naturally close to $\tilde \mu$ defined for any real $a<b$ as $\tilde \mu([a,b]) = \lim_{y \to 0} \frac{1}{\pi } \int_{a}^b \Im(\tilde g(x+iy)) dx$, it can indeed be shown that the Kolmogorov distance between those two measures tends to zero as stated in \cite{chouard2022quantitative}.
% For computation issues, the quantities $p$ and $n$ are chosen relatively small; the convergence of the iteration of the fixed point equation \eqref{eq:fixed_point_equation_tilde_lambda_theorem} defining $\tilde \Lambda$ is in particular very slow when the covariances $\Sigma_1, \ldots, \Sigma_n$ are all different from one another. Although the contractivity of \eqref{eq:fixed_point_equation_tilde_lambda_theorem} for the semi metric $d_s$ ensures the convergence of the iterations, the Lipschitz parameter is very close to $1$ when $z=x +iy $ is close to the spectrum (that happens naturally when $y$ is chosen close to $0$ to estimate $d\tilde \mu$). 
%The histograms are drawn for Gaussian data but they 


\section{Statistical study of the resolvent with convex concentration hypotheses}\label{sec:resolvent_convex}

We want in this section to extend the result of Section~\ref{sec:main_res_lipschitz} to the case of convexly concentrated matrices.
% The convexity required for the observations to concentrate makes the discussion on convexly concentrated random vector far more delicate. 
Recall that convexly concentrated random vectors class is not stable through Lipschitz maps, we just set it was stable through affine transformations. 
% This issue raises naturally for one of the major objects of random matrix theory, namely the resolvent $Q^z = (zI_n - X)^{-1}$ that can provide important eigen properties on $X$. %whose concentration raises several issues in the case of convex concentration. 
As a consequence, in this setting, the concentration of the resolvent $Q^z = (I_n - X/z)^{-1}$ is no more a mere consequence of a bound on its differential on $X\in \mathcal{M}_{p}$. Still, as first shown by \cite{guionnet2000concentration}, it is possible to obtain concentration properties on the sum of Lipschitz functionals of the eigen values. Here we pursue the study, looking at \textit{linear} concentration properties of $Q$ for which concentration inequalities are only satisfied by $1$-Lipschitz \emph{and linear} functionals $f$. 
% This is an extension of the result of \cite{guionnet2000concentration} since t
The well known identity
\begin{align}\label{eq:importance_stieltjes_transform}
  \frac{1}{p}\sum_{\lambda \in \text{Sp}(X)} f(\lambda) = - \frac{1}{2i\pi} \oint_\gamma \frac{f(z)}{z} \tr(Q^z)dz,
\end{align}
is true for any analytical mapping $f$ defined on the interior of a path $\gamma \in \mathbb C$ containing the spectrum of $X$ (or any limit of such mappings), therefore, our results on the concentration of $Q^z$ concern in particular the quantities studied in \cite{guionnet2000concentration}.

% Note that $\tr(Q^z)$ is only a particular linear functional of $Q^z$, we prove in the paper the concentration of any $\tr(AQ^z)$, for $A$ deterministic and provide a deterministic equivalent.

% Although it is weaker, the class of linearly concentrated vectors behaves very well towards the dependence and the sum and allows us to obtain t
The linear concentration of the resolvent is proven thanks to Theorem~\ref{the:Concentration_linearire_solution_implicite_hypo_concentration_phi^k_pour tout_k}, expressing it as a sum $Q^z = \frac{1}{z}\sum_{i=1}^\infty (X/z)^i$. The linear concentration of the powers of $X$ was justified in Theorem~\ref{the:concentration_lineaire_produit_matrice_convexement_concentres}. We call this weakening of the concentration property ``the degeneracy of the convex concentration through multiplication''. The linear concentration of the resolvent is though sufficient for most practical applications that rely on an estimation of the Stieltjes transform $m(z) = \frac{1}{zp} \tr(Q^z)$ or on projections on $Q^z$.% 

% \subsection{Assumptions}\label{sec:assumptions_convex}

We still work under Assumptions~\ref{ass:n_p_commensurable}-\ref{ass:Sigma_borne_inferieurement}, we just adapt Assumption~\ref{ass:concentration_X} to the convex concentration setting and assume instead:
\addtocounter{assumption}{-4}
\begin{assconv0}[Convex concentration]\label{ass:concentration_covexe_X}
  $X \propto_c \mathcal E_2$.
\end{assconv0}
\addtocounter{assumption}{3}

% When $n$ gets big, $\mu$ distributes along a finite number of bulks. To describe them, let us consider a positive parameter, $\varepsilon>0$, that could be chosen arbitrarily small (it will though be chosen independent with $n$ in most practical cases) and introduce as in Chapter~\ref{cha:resolvente_lipschtiz} the sets:
% \begin{align*}
%   \mathcal S = \left\{\lambda_i\right\}_{i \in [p]} &
%   &\bar{\mathcal S} = \left\{ \mathbb E[\lambda_i]\right\}_{i \in [p]} &
%   &\mathcal S^\varepsilon = \left\{ x \in \mathbb R, \exists i \in [n], |x - \lambda_i | \leq \varepsilon \right\}
% \end{align*}
% % Let us note $\nu = \mathbb E[\|X\|]/ \sqrt n \leq O(\sqrt n)$ (see \cite{}) and 
% One can show that $\nu \equiv \sup \bar{\mathcal S} = \mathbb E[\lambda_1] \leq O(1)$ and introducing the event:
We also keep the same notations $S = \{\mathbb E_{\mathcal A_\nu}[\lambda_1], \ldots, \mathbb E_{\mathcal A_\nu}[\lambda_p]\}$ and 
\begin{align*}
  \mathcal A_Q \equiv \left\{ \forall i \in[p], \sigma_i \left( \frac{1}{n}XX^T \right) \in S^{\varepsilon/2} \right\},
\end{align*}
for some $\varepsilon \geq O(1)$.
the concentration of $\sigma(X) / \sqrt n \in \mathbb E[\sigma(X)] \pm \mathcal E_2(1/\sqrt n)$, allows us to set\footnote{In Lemma~\ref{lem:A_Q_overwhelming}, the proof is conducted for Lipschitz concentration hypotheses on $X$. However, since only the linear concentration of $\sigma(X)$ is needed, the justification is the same in a context of convex concentration thanks to Theorem~\ref{the:conc_val_sing}.} as in Lemma~\ref{lem:A_Q_overwhelming} 
% \begin{lemma}[\cite{LOU21RHL}, Lemma 3.]\label{lem:A_Q_overwhelming}
that there exist two constants $C,c>0$ such that $\mathbb P \left(\mathcal A_Q^c\right) \leq C e^{-cn\varepsilon^2}$.
% \end{lemma}
% The following lemma allows us to conduct the concentration study on the highly probable event $\mathcal A_Q$ (when $\varepsilon \geq O(1)$).
 % $\mathcal A \equiv \{\|X\| \geq \bar \nu  \sqrt n\}$, where $\bar \nu = \nu \varepsilon$.


We can beside deduce from Lemma~\ref{lem:concentration_conditionnee_convexe} that $(X \ |\ \mathcal A_Q) \propto_c \mathcal E_2$.
 % and the random matrix $(X \ |\ \mathcal A_Q)$ is far easier to control because $\|(X \ |\ \mathcal A_Q)\| \leq \nu + \frac{\varepsilon}{2}$ (we recall that $\nu \equiv \mathbb E[\lambda_1]$).

% \subsection{Concentration of the resolvent}
Placing ourselves under the event $\mathcal A_Q$, let us first show that the resolvent $Q^z \equiv (I_p - \frac{1}{nz}XX^T)^{-1}$ is concentrated if $z$ has a big enough modulus. Be careful that the following concentration is expressed for the nuclear norm (for any deterministic matrix $A \in \mathcal{M}_{p}$ such that $\|A\|\leq O(1)$, $\tr(AQ^z) \in \mathcal E_2$).
 % All the following results are provided under Assumptions~\ref{ass:p_plus_petit_que_n}-
The next proposition is just provided as a first direct application of Theorem~\ref{the:Concentration_linearire_solution_implicite_hypo_concentration_phi^k_pour tout_k}, a stronger result is provided in Proposition~\ref{pro:Concentration_lineaire_Q_proche_spectre}.
%\footnote{We showed in \cite{louart2018concentration} that we have a linear concentration of $Q^z$ for $z \in \mathbb R^-$ with slightly different techniques.}. % we need to show the concentration of $D z$.
\begin{proposition}\label{pro:concentration_resolvent_concentration_convexe_z_hors_de_boule}
  % Assuming here that $\varepsilon$ is an asymptotic quantity that could tend to $0$ and g
  Given $z \in \mathbb C$ such that $|z| \geq \nu + \varepsilon$:
  % $|z| \geq 4e^2 (\nu + \varepsilon)$:
  \begin{align*}
    (Q^z \ | \ \mathcal A_Q) \in \mathcal E_2&
    % (Q^z \ | \ \mathcal A_Q) \in \mathcal E_2 \left( \frac{4}{\varepsilon} (\nu + \varepsilon )\right)&
    &\text{in} \ \ (\mathcal M_{p}, \| \cdot \|_*).
    % &\text{and}&
    % &\mathbb P(\mathcal A^c) \leq C e^{-cn},
  \end{align*}
  % for two constants $C,c>0$.
\end{proposition}
\begin{proof}
  % We already know from Corollary~\ref{cor:concentration_resolvante_concentration_convexe} that 
  We know from Lemma~\ref{lem:concentration_conditionnee_convexe} that $(X \ | \ \mathcal A_Q) \propto_c \mathcal E_2$ and from Theorem~\ref{the:concentration_lineaire_produit_matrice_convexement_concentres} that (here $\kappa = \nu + \frac{\varepsilon}{2} \leq O(1)$, $\sigma = 1/\sqrt n$ and $p= O(n)$):
  \begin{align*}
     \text{Under $\mathcal A_Q$:}&
     &\left(\frac{1}{n}XX^T\right)^m \in \mathcal E_2 \left( \left( \nu + \frac{\varepsilon}{2} \right)^{m} \sqrt m \right)&
    &\text{ in } \left(\mathcal M_{p}, \| \cdot \|_*\right).
   \end{align*}
   Let us then note that $\left(\nu + \frac{\varepsilon}{2} \right)^{m} \sqrt m  = O\left(\left(\nu + \frac{3\varepsilon}{4} \right)^{m}\right)$ and for $z \in \mathbb C$ satisfying our hypotheses: $(\nu + \frac{3\varepsilon}{4})/|z| \leq 1 - \frac{\varepsilon}{4(\nu + \varepsilon)}$.
   % Taking , $\frac{\nu}{|z|} \leq 1 -\epsilon$ for a constant $\epsilon \geq O(1)$, w
   We can then deduce from Corollary~\ref{cor:concentration_serie_vecteur_lineairement_concentres} that under $\mathcal A_Q$:
   \begin{align*}
     Q^z = \frac{1}{z} \left(I_p - \frac{1}{zn}XX^T\right)^{-1} = \frac{1}{z}\sum_{i=1}^\infty \left(\frac{1}{zn}XX^T\right)^i \in \mathcal E_2 \left( \frac{4}{\varepsilon} (\nu + \varepsilon )\right).
     % &\text{ in } \left(\mathcal M_{p}, \| \cdot \|_*\right)
   \end{align*}
\end{proof}
Let us now try to study the concentration of $Q^z$ when $z$ gets close to the spectrum.
 % for that we require $\varepsilon>0$ to be a constant (recall that $\varepsilon \geq O(1)$).
\begin{proposition}\label{pro:Concentration_lineaire_Q_proche_spectre}
  % Given $\varepsilon \geq O(1)$, f
  For all $z \in \mathbb C \setminus S^ \varepsilon$:
  \begin{align*}
    (Q^z \ | \ \mathcal A_Q) \in \mathcal E_2(\kappa_z)&
    &\text{in } \ \ (\mathcal{M}_{p}, \|\cdot \|_*),
  \end{align*}
  % and we recall that there exist two constants $C,c>0$ such that $ \mathbb P \left( \mathcal A_Q^c \right)  \leq C e^{-cn}$.
\end{proposition}

\begin{proof}
  Proposition~\ref{pro:concentration_resolvent_concentration_convexe_z_hors_de_boule} already set the result for $|z| \geq \nu + \varepsilon\equiv \rho $, therefore, let us now suppose that $|z| \leq \rho$. 

  % We can distinguish three cases:% (that altogether contain $\{|z| \geq 8e^2 \bar \nu\}$):
  %   \begin{enumerate}
  %      \item $z \in \mathbb R$ and $z \leq - \epsilon$ with $\epsilon\geq O(1)$
  %      % \item $z \in \mathbb R$ and $z \geq \bar \nu + \epsilon$ with $\epsilon\geq O(1)$
  %      \item $z \in \mathbb C$ and $|\Im z | \geq \epsilon$ with $\epsilon\geq O(1)$
  %    \end{enumerate}
  % If $z \leq -\epsilon$, we can rewrite
  % \begin{align*}
  %   Q^z = \frac{1}{\rho} \left( I_p - \left( I_p - \frac{|z|}{\rho} - \frac{1}{n\rho}XX^T\right) \right)^{-1} = \frac{1}{\rho} \sum_{m=0}^\infty \left( I_p - \frac{|z|}{\rho} - \frac{1}{n\rho}XX^T\right)^m
  % \end{align*}
  % \begin{align*}
  %     \tr(Q^z) 
  %     &= \sum_{i=1}^p \frac{1}{z - \frac{1}{n}\sigma(X)^2_i}
  %     = -\frac{1}{\rho}\sum_{i=1}^p \frac{1}{\frac{|z|}{\rho} + \frac{\sigma(X)^2_i}{\rho n}} \\
  %     &= -\frac{1}{\rho}\sum_{i=1}^p \frac{1}{1 - \left(1 - \frac{|z|}{\rho} - \frac{\sigma(X)^2_i}{\rho n}\right)} 
  %     = -\frac{1}{\rho}\sum_{k=1}^\infty \sum_{i=1}^p  \left(1 - \frac{|z|}{\rho} - \frac{\sigma(X)^2_i}{\rho n}\right)^k
  %     % = \sum_{i=1}^p \frac{\Re(z) - \sigma(X)_i^2}{\Im(z)^2 + (\Re(z) - \sigma(X)_i^2)^2} - \frac{\Im(z)}{\Im(z)^2 + (\Re(z) - \sigma(X)_i^2)^2}\\
  %     % & = \frac{1}{\Im(z)^2} \sum_{i=1}^p \sum_{k=1}^\infty \frac{2\cdots (k+2)}{(k+1)!} \left(\frac{\Re(z) - \sigma(X)_i^2}{\Im(z)}\right)^{k+1} \left(\Re(z) - \sigma(X)_i^2 -\Im(z)\right) 
  %   \end{align*}  
    % This Taylor expansion is allowed since, with the order relation on the set of symmetric matrices:
    % \begin{align*}
    %   -1<-\frac{\nu + \frac{\varepsilon}{2}}{\rho} \leq 1 - \frac{|z|}{\rho} - \frac{1}{\rho n} XX^T < \frac{\varepsilon}{2\rho}  <1
    % \end{align*}
    % Summing the observable diameters with Corollary~\ref{cor:concentration_serie_vecteur_lineairement_concentres}, we obtain $Q^z \in \mathcal E_2(1/\sqrt n)$.
    % Besides, as in the proof of Theorem~\ref{the:concentration_convexe_produit_odot_Rp}, $\forall k \in \mathbb N$, $y \mapsto \sum_{i=1}^p\left(1 - \frac{|z|}{\rho} + \frac{y^2_i}{\rho n}\right)^k$ can be written as the difference of two $C(1 -\epsilon')^{k-1}$-Lipschitz convex mappings on $\sigma(X)(\mathcal A_Q)$, for well chosen constants $C\leq O(1)$ and $\epsilon\geq O(1)$. We can then conclude from the concentration of $\sigma(X)$ given by Theorem~\ref{the:conc_val_sing} with Corollary~\ref{cor:concentration_serie_vecteur_lineairement_concentres}.

    % If $z \in [\bar \nu , \rho]$, $\forall i\in [n]$, $0\leq \frac{\sigma(X)^2_i}{ n} \leq z$ and we rather decompose:
    % \begin{align*}
    %   \tr(Q^z) 
    %   &= \sum_{i=1}^p \frac{1}{1 - \left(1 - z + \frac{\sigma(X)^2_i}{ n}\right)} 
    %   = \sum_{k=1}^\infty \sum_{i=1}^p  \left(1 - z + \frac{\sigma(X)^2_i}{ n}\right)^k
    % \end{align*}
    % we can then conclude as previously.

    % If $\Im(z) \geq \epsilon$ (and $|z|\leq \rho$) we 
    With the notation $M \equiv \left( \Im(z)^2 + \left( \Re(z) - \frac{1}{n}XX^T \right)^2 \right)^{-1} = |\frac{1}{z}Q^z|^2$, let us decompose:
    \begin{align}\label{eq:decomposition_Q_Im_Re}
      \frac{1}{z}Q^z = \left( \Re(z) - \frac{1}{n}XX^T \right) M - \Im(z)i M.
    \end{align}
    We can then deduce the linear concentration of $M$ with the same justifications as previously thanks to the Taylor decomposition:
    \begin{align*}
      M 
      % &= \left( \Im(z)^2 + \left( \Re(z) - \frac{1}{n}XX^T \right)^2 \right)^{-1} \\
      = \frac{|z|^2}{\rho^2} \sum_{m=0}^\infty \left( 1 - \frac{\Im(z)^2}{\rho^2} - \frac{\left( \Re(z) - \frac{1}{n}XX^T \right)^2}{\rho^2} \right)^m.
    \end{align*}
    % We conclude on 
    Indeed, $\|\Re(z)I_p - \frac{1}{n}XX^T\| \leq d(\Re(z), S)$ and $d(z, S)^2 = \Im(z)^2 + d(\Re(z), S)^2 \leq \rho$ thus:
    \begin{align*}
      \left\Vert 1 - \frac{\Im(z)^2}{\rho^2}  - \frac{1}{\rho^2}\left(\Re(z)I_p - \frac{1}{n}XX^T\right) ^2\right\Vert 
      & \leq 1 -  \frac{d(z, S)^2}{\rho^2} 
      \leq 1 - \frac{\varepsilon^2}{\rho^2} <1 .
    \end{align*}
    % when $p<n$, $d(z, S) = d(z, S) \geq \varepsilon$, when $p>n$, $0 \in S$, thus $d(z, S) \geq \min(|z|, \varespilon)$.
  We therefore deduce from \eqref{eq:decomposition_Q_Im_Re} that:
  \begin{align*}
    (Q^z \ | \ \mathcal A_Q) 
    \in \mathcal E_2 \left(\frac{ |z|}{\varepsilon^2} \left( |\Im(z)| + |\Re(z)| + \nu + \frac{\varepsilon}{2} \right)  \right) 
    = \mathcal E_2(\kappa_z).
  \end{align*}
    % We can then develop $\frac{1}{{\Im(z)^2 + (\Re(z) - \sigma(X)_i^2)^2}} = \frac{1}{{1 -\Im(z)^2 + (\Re(z) - \sigma(X)_i^2)^2}}$
\end{proof}
% For the sake of completeness, we left in the appendix an alternative laborious proof (but somehow more direct) already presented in \cite{louart2018concentration}. 

One can then follow the lines of study made for the Lipschitz concentration case to show that $Q^z$ is also concentrated around $\tilde Q^{\tilde \Lambda^z}$ under convex concentration hypotheses. 
Although Proposition~\ref{pro:Concentration_lineaire_Q_proche_spectre} gives us a concentration of $Q^z$ in nuclear norm, we will estimate $\mathbb E[Q^z]$ with the Frobenius norm as in the Lipschitz concentration case. 
% The next proposition gives us a first deterministic equivalent, as an approximation to $\mathbb E[Q^z]$. 
% For any $z \in \mathbb C \setminus S^\varepsilon$, let us introduce $\bar \Lambda^z = (z  - \frac{1}{n}\tr(\Sigma_i\mathbb E[Q^z]))_{i \in [n]}$ and recall that for any $\delta \in \mathbb C^n$, we note $\tilde Q^\delta = (I_p - \frac{1}{n} \sum_{i=1}^n \frac{\Sigma_i}{\delta_i})^{-1} $. We have the following first approximation to $\mathbb E[Q^z]$:
\begin{proposition}\label{pro:first_deterministic_equivalent}
  For any $z \in \mathbb C \setminus S^\varepsilon$ in convex concentration setting:
  \begin{align*}
    % \left\Vert \tilde Q^{\bar \Lambda^z} \right\Vert \leq O(1)&
    % &\text{and}&
    &\left\Vert \mathbb E[Q^z] - \tilde Q^{\bar \Lambda^z} \right\Vert_F \leq O \left( \frac{\kappa^z}{\sqrt n} \right).
  \end{align*}
\end{proposition}
% To prove this proposition, we will play on the dependence of $Q^z$ towards $x_i$ with the notation $X_{-i} \equiv (x_1, \ldots, x_{i-1}, 0, x_{i+1}, \ldots, x_n) \in \mathcal{M}_{p,n}$ and:
% \begin{align*}
%   Q_{-i}^z \equiv \left( I_p - \frac{1}{zn}X_{-i}X_{-i}^T \right)^{-1}.
% \end{align*}
% To link $Q^z$ to $Q^z_{-i}$ we will extensively use a direct application of the Schur identity:
% \begin{align}\label{eq:lien_q_qj_schur}
%    Q^zx_i = \frac{Q^z_{-i}x_i}{1 - \frac{1}{n}x_i^T Q^z_{-i}x_i}.
%  \end{align} 
% \begin{proof}
%   All the estimations hold under $\mathcal A_Q$, therefore the expectation should also be taken under $\mathcal A_Q$ to be fully rigorous. Note that if $Q_{-i}$ and $x_i$ are independent on the whole universe, they are no more independent under $\mathcal A_Q$. However, since the probability of $\mathcal A_Q$ is overwhelming, the correction terms are negligible, we thus allow ourselves to abusively expel from this proof the independence and approximation issues related to $\mathcal A_Q$, a rigorous justification is provided in Chapter~\ref{cha:resolvente_lipschtiz}.

%   Let us bound for any deterministic matrix $A \in \mathcal{M}_{p}$ such that $\|A\|_F\leq 1$:
%   % Let us bound for any deterministic vector $u \in \mathbb R^p$ such that $\|u\|\leq 1$:
%   \begin{align*}
%    \left\vert  \tr \left( A  \left( \mathbb E[Q^z] - \tilde Q^z_{\bar \Lambda^z} \right) \right) \right\vert
%     &\leq \frac{1}{n} \sum_{i=1}^n \left\vert \mathbb E \left[ \tr \left( A \left( Q^z \left( \frac{\Sigma_i}{1+\bar \Lambda^z_i} - x_ix_i^T \right)\tilde Q^z_{\bar \Lambda^z} \right) \right) \right] \right\vert.
%   \end{align*}
%   We can then develop with \eqref{eq:lien_q_qj_schur}:
%   \begin{align*}
%     &\left\vert  \tr \left( A \left( \mathbb E[Q^z] - \tilde Q^z_{\bar \Lambda^z} \right) \right) \right\vert\\
%     &\hspace{1cm}\leq \frac{1}{n} \sum_{i=1}^n \left\vert   \frac{ \tr \left( A \left( \mathbb E \left[ Q^z - Q_{-i}^z  \right]\Sigma_i\tilde Q^z_{\bar \Lambda^z} \right) \right)}{1 - \bar \Lambda^z_i}  \right\vert\\
%     &\hspace{1cm}\hspace{1cm} + \frac{1}{n} \sum_{i=1}^n \left\vert \mathbb E \left[ \tr \left( A \left( Q_{-i}^z \left( \frac{\Sigma_i}{1 - \bar \Lambda^z_i} - \frac{x_ix_i^T}{1 + \frac{1}{n} x_i^T Q_{-i}^z x_i} \right)\tilde Q^z_{\bar \Lambda^z} \right) \right) \right] \right\vert\\
%     &\hspace{1cm}\leq \frac{1}{n} \sum_{i=1}^n \left\vert \mathbb E \left[ \frac{ x_i^T\tilde Q^z_{\bar \Lambda^z}A Q^zx_i}{1 - \bar \Lambda^z_i } \left( \frac{1}{n }x_i^t Q_{-i}^z x_i - \bar \Lambda^z_i \right)\right] \right\vert + O \left(  \frac{\left\Vert \tilde Q^z_{\bar \Lambda^z} \right\Vert}{\sqrt n}\right),
%   \end{align*}
%   thanks to Lemma~\ref{lem:Q_m_Q_m_i} and the independence between $Q_{-i}^z$ and $x_i$.
%   We can then bound thanks to H\"older inequality and Lemma~\ref{lem:concentration xQx} below:
%   \begin{align*}
%     &\left\vert \mathbb E \left[ x_i^T\tilde Q^z_{\bar \Lambda^z}A Q^zx_i \left( \frac{1}{n }x_i^t Q_{-i}^z x_i - \bar \Lambda^z_i \right) \right] \right\vert\\
%     &\hspace{0.5cm}=\left\vert \mathbb E \left[ \left( x_i^T\tilde Q^z_{\bar \Lambda^z}A Q^zx_i - \mathbb E \left[ x_i^T\tilde Q^z_{\bar \Lambda^z}A Q^zx_i \right] \right) \left( \frac{1}{n }x_i^t Q_{-i}^z x_i - \mathbb E \left[ \frac{1}{n }x_i^t Q_{-i}^z x_i \right] \right) \right] \right\vert\\
%   &\hspace{0.5cm}\leq \sqrt{\mathbb E \left[ \left(\frac{x_i^T AQ^z_{-i}x_i}{1 - \frac{1}{n} x_i^TQ_{-i}x_i} - \mathbb E \left[ \frac{x_i^T AQ^z_{-i}x_i}{1 - \frac{1}{n} x_i^TQ_{-i}x_i} \right] \right)^2 \right]}O \left( \frac{1}{\sqrt n}  \right)\\
%   &\hspace{0.5cm}\leq O \left( \frac{1}{\sqrt n}  \right)\left(\mathbb E \left[ \left(\frac{x_i^T \tilde Q^z_{\bar \Lambda^z}AQ^z_{-i}x_i - \mathbb E[x_i^T \tilde Q^z_{\bar \Lambda^z}AQ^z_{-i}x_i]}{1 - \frac{1}{n} x_i^TQ_{-i}x_i} \right)^2 \right] \right.\\
%   &\hspace{1.5cm}\left.+ \mathbb E \left[ \left(\tr\left(\Sigma_i \tilde Q^z_{\bar \Lambda^z}AQ^z_{-i}\right) \left( \frac{1}{1 - \frac{1}{n} x_i^TQ_{-i}x_i} - \mathbb E \left[ \frac{1}{1 - \frac{1}{n} x_i^TQ_{-i}x_i} \right] \right) \right)^2 \right]\right)^{1/2}\\
%   &\hspace{0.5cm}\leq O \left( \frac{\left\Vert \tilde Q^z_{\bar \Lambda^z} \right\Vert}{\sqrt n}  \right).
%   \end{align*}
%   indeed since we know that $|\frac{1}{1 - \frac{1}{n} x_i^TQ_{-i}x_i} | \leq O(1)$ from Lemma~\ref{lem:Borne_resolvante}, $\frac{1}{1 - \frac{1}{n} x_i^TQ_{-i}x_i}$ is a $O(1)$-Lipschitz transformation of $\frac{1}{n} x_i^TQ_{-i}x_i$, therefore, it follows the same concentration inequality (with a variance of order $O(1/ n)$).
%   % \end{align*}
%   Since this inequality is true for any $A \in \mathcal M_p$, we can bound:
%   \begin{align*}
%     \left\Vert \tilde Q^z_{\bar \Lambda^z} \right\Vert \leq \left\Vert \tilde Q^z_{\bar \Lambda^z} - \mathbb E[Q^z] \right\Vert_F + \left\Vert \mathbb E[Q^z] \right\Vert \leq O \left( \frac{\left\Vert \tilde Q^z_{\bar \Lambda^z} \right\Vert}{\sqrt n} \right) + O(1),
%   \end{align*}
%   which directly implies that $\left\Vert \tilde Q^z_{\bar \Lambda^z} \right\Vert \leq O(1)$ and $\left\Vert \mathbb E[Q^z] -  \tilde Q^z_{\bar \Lambda^z} \right\Vert_F \leq O(1/\sqrt n)$.
% \end{proof}
% \begin{lemma}[\cite{LOU21RHL}, Lemmas 4., 8. ]\label{lem:Borne_resolvante}
%   $\forall z \in S^\varepsilon$, under $\mathcal A^\varepsilon$: 
%   \begin{align*}
%     \|Q^z \| \leq \frac{2}{\varepsilon}&
%     &\text{and}&
%     &\sup_{i\in [n]}|\frac{1}{1 - \frac{1}{n} x_i^TQ_{-i}x_i} | \leq O(1)
%     % $\|Q^z \| \leq \frac{2}{\varepsilon}$ and $\sup_{i\in [n]}|\frac{1}{1 - \frac{1}{n} x_i^TQ_{-i}x_i} | \leq O(1)$
%   \end{align*}
% \end{lemma}
The Proof of the Theorem is done the same way as in the Lipschitz case, it just relies on the Lemmas~\ref{lem:concentration xQx} and~\ref{lem:Q_m_Q_m_i} below.


\begin{lemma}\label{lem:Q_m_Q_m_i}
  Under $\mathcal A_Q$, for any $z \in \mathbb C \setminus S^\varepsilon$ and any $i \in [n]$:
  \begin{align*}
    \|\mathbb E[Q^z - Q^z_{-i}]\| \leq O \left( \frac{1}{n} \right).
  \end{align*}
\end{lemma}
The proof is the same as the one of Lemma~\ref{lem:Q_m_i_proche_Q} and relies on the bound on $\Lambda_i^z$ given by Lemma~\ref{lem:Borne_Lambda} and the concentration of $u^TQ_{-i}x_i$ provided in next lemma.
\begin{lemma}\label{lem:uQx}
  For any $z \in \mathbb C \setminus S^\varepsilon$, any $i \in [n]$ and any $u \in \mathbb R^p$ such that $\|u\|\leq 1$:
  \begin{align*}
    (u^T Q_{-i}^zx_i \ | \ \mathcal A_Q)
    % (u^T Q^zx_i \ | \ \mathcal A_Q)
     \in O(1) \pm \mathcal E_2.
  \end{align*}
\end{lemma}
\begin{proof}
    We do not care about the independence issues brought by $\mathcal A_Q$. Let us simply bound for any $t>0$ and under $\mathcal A_Q$:
    \begin{align*}
      &\mathbb P \left( \left\vert u^T Q_{-i}^zx_i - \mathbb E \left[  u^T Q_{-i}^zx_i\right] \right\vert \geq t \right)\\
      &\hspace{1cm}\leq \mathbb P \left( \left\vert u^T Q_{-i}^z(x_i -\mu_i) \right\vert \geq \frac{t}{2} \right)+
      \mathbb P \left( \left\vert u^T  \left( Q_{-i}^z-\mathbb E \left[ Q_{-i}^z\right] \right)\mu_i \right\vert \geq \frac{t}{2} \right)\\
      &\hspace{1cm}\leq \mathbb E \left[ C e^{-cnt^2/\|Q_{-i}\|^2} \right] + C e^{-cnt^2} \ \
      \leq \ 2C e^{-c'nt^2},
    \end{align*}
    for some constants $C,c,c'>0$. Besides, we can bound:
    \begin{align*}
      \left\vert \mathbb E \left[  u^T Q_{-i}^zx_i\right] \right\vert = \left\vert u^T \mathbb E[Q_{-i}^z]m_i \right\vert \leq O(1),
    \end{align*}
    thanks to Lemma~\ref{lem:Borne_resolvante}.

\end{proof}


The last Lemma is then important to employ similar results as Proposition~\ref{pro:estimation_XDY} as in the proof of Proposition~\ref{pro:borne_EQ_m_tQ}.
\begin{lemma}\label{lem:concentration xQx}
  For any $z \in  \mathbb C \setminus S^\varepsilon $:
\begin{align*}
  \forall i \in [n], \Lambda_i^z \ | \ \mathcal A_Q \in \tilde \Lambda_i^z \pm \mathcal E_2(\kappa_z/\sqrt n) + \mathcal E_1(\kappa_z/n).
\end{align*}
  Besides, for any deterministic matrix $A \in \mathcal{M}_{p}$:
  \begin{align*}
     (x_i^T AQ^zx_i \ | \ \mathcal A_Q) \in \tr(\Sigma_i A\mathbb E[Q^z]) \pm\mathcal E_2 \left( \kappa_z \|A\|_F\right) + \mathcal E_1 \left( \kappa_z \|A\|\right).
  \end{align*} 
  % and $(x_i^T AQ^zx_i \ | \ \mathcal A_Q) \in \mathcal E_2 \left( \|A\|_F \right) + \mathcal E_2(\|A\|)$
  % , where for any random vector $Z$, $\mathbb E_{\mathcal A_Q}[Z] = \mathbb E[Z \ | \ \mathcal A_Q]$
\end{lemma}

\begin{proof}
We will first show the concentration of $\frac{1}{n}x_i^T AQ^z_{-i}x_i$ for any deterministic matrix $A \in \mathcal{M}_{p}$ that will in particular imply the concentration of $\Lambda_i^z$.
Recall that under $\mathcal A_Q$, $\|X\|\leq O(1)$ and $\|Q^z\| \leq \kappa_z$. Given $i \in [n]$, 
% since we know from Lemma~\ref{lem:Q_m_Q_m_i} that $\|\mathbb E[Q^z - Q_{-i}^z\| \leq O(1/\sqrt n)$, 
we want to bound:
\begin{align*}
  &\left\vert x_i^T AQ^z_{-i}x_i - \tr \left( \Sigma_i A \mathbb E \left[ Q_{-i}\right] \right)\right\vert\\
  &\hspace{1cm}\leq \left\vert x_i^T AQ^z_{-i}x_i -  \tr (\Sigma_iA Q^z_{-i})\right\vert + \left\vert  \tr \left(  \Sigma_iA (Q^z_{-i} - \mathbb E[Q^z_{-i}]) \right)\right\vert.
\end{align*}
Now we know that, for $X_{-i}$ fixed, we can bound thanks to Proposition~\ref{pro:hanson_wright_convex}:
 % (and Lemma~\ref{lem:Borne_resolvante} $\|Q_{-i}^z\| \leq O(1)$):
% \begin{align*}
%   \left( \frac{1}{n}x_i^TQ_{-i}^zx_i, X_{-i} \right) 
%   % \left( \frac{1}{n}x_i^TQ_{-i}^zx_i \ | \ \mathcal A_Q, X_{-i} \right) 
%   \in \frac{1}{n}\tr \left( \Sigma_i Q_{-i}^z\right) \pm \mathcal E_2 \left( \frac{1}{\sqrt n} \right),
%   % \in \frac{1}{n}\tr \left( \mathbb E[x_ix_i^T\ | \ \mathcal A_Q] Q_{-i}^z\right) \pm \mathcal E_2 \left( \frac{1}{\sqrt n} \right),
% \end{align*}
% and since $\mathbb P(\mathcal A_Q^c) \leq C e^{-cn}$ for some constants $C,c>0$, we show easily that $\left\Vert \mathbb E[x_ix_i^T\ | \ \mathcal A_Q] - \mathbb E[x_ix_i^T] \right\Vert \leq O(1/\sqrt n) $. 
% We can then deduce from Lemma~\ref{lem:trou_noir_diametre_observable} that:
\begin{align*}
  \mathbb P \left( \left\vert x_i^T AQ^z_{-i}x_i -  \tr (\Sigma_i^T AQ^z_{-i})\right\vert \geq t  \right)
  &\leq \mathbb E \left[ Ce^{-c(t/\|Q_{-i}^z\| \|A\|_F)^2} + Ce^{-ct/\|Q_{-i}^z\| \|A\|} \right] \\
  &\leq  Ce^{-c'(t/\|A\|_F\kappa_z)^2} + Ce^{-c't/\|A\|\kappa_z},
\end{align*}
for some constants $C,c,c'>0$, thanks to Lemma~\ref{lem:Borne_resolvante}.

Besides, we know from Proposition~\ref{pro:Concentration_lineaire_Q_proche_spectre} and Lemma~\ref{lem:diametre_observable_pivot} that $Q_{-i}^z \in \mathbb E[Q^z] \pm \mathcal E_2(1/\sqrt n)$ in $(\mathcal{M}_{p}, \|\cdot\|_*)$, which allows us to bound:
\begin{align*}
  \mathbb P \left( \left\vert \tr (\Sigma_i A Q^z_{-i}) - \tr (\Sigma_i A \mathbb E[Q^z])\right\vert \geq t  \right)
  % &\leq \mathbb E \left[ Ce^{-cnt^2/\|Q_{-i}^z\|} \right] 
  \leq  Ce^{-ct^2/\|A\|_F^2}
  % \leq  Ce^{-ct^2/\|A\|_F^2},
\end{align*}
for some constants $C,c>0$, since $\|\Sigma_i\|\leq O(1)$. Putting the two concentration inequalities together, we obtain the concentration of $\frac{1}{n}x_i^T AQ_{-i}^zx_i$.

Now the identity $\frac{1}{n}x_i^T AQ^zx_i 
  = \frac{1}{n}\frac{x_i^T AQ^z_{-i}x_i}{\Lambda_i^z}$, and the bounds $\Lambda_i^z \geq O(|z|/\check \kappa_z)$ and $\frac{1}{n}x_i^T AQ_{-i}^zx_i \leq \kappa_z \rho$ allows us to deduce the concentration of $\frac{1}{n}x_i^T AQ^zx_i$ thanks to Lemma~\ref{lem:conc_produit} setting the concentration of the product of concentrated variables.
\end{proof}




\section{The deterministic equivalents of the powers of the resolvent}\label{sse:det_equ_puiss_Q}

Our aim here is to find  deterministic equivalent for all the powers $(Q^z)^m$, for $ m\in \mathbb N$ and for $z \in \mathbb C$ satisfying $d(z,S^\varepsilon)\geq O(1)$ for a given constant $\varepsilon>0$ ($\varepsilon \geq O(1)$). 
For simplicity, we will omit the exponent $z$ of the resolvent. We continue to work under Assumptions~\ref{ass:n_p_commensurable}-\ref{ass:Sigma_borne_inferieurement} we thus won't recall them in the coming lemmas and propositions. The main goal of this section is to display the formulas given in Proposition~\ref{pro:Definition_Phi}, because they might be seen in other contexts thereby allowing to interesting analogies. The coming proofs are quite laborious and do not present all the required justification mainly to avoid complex inferences of little interest.

In the concentration inequalities, it is interesting to keep track of the dependence on $m$ to use it later for a quasi-asymptotic formulations, we will thus assume sometimes that $m\in \mathbb N^\mathbb N$ is a sequence of integer (as $n$ and $p$).
% Thus, we know consider .
% A $O(1)$ is then a quantity that stays bounded whatever the value of $p$, $n$ and $m$ could be.
Since it is costless to devise directly a deterministic equivalent for $QA_1QA_2,\cdots A_{m-1}Q$ where $A_1,\ldots A_{m-1}$ are all matrices of unit spectral norm we will consider this general case.
% To simplify the notations, we will c
Considering from now on $m-1$ matrices $A_1, \ldots, A_{m-1}$, where $\forall i\in [m]$, $\left\Vert A_i\right\Vert\leq 1$ and we note for any matrix $M\in \mathcal M_p$, $k \in [m]$:           
\begin{align*}
M^{A_l^{k}}=
\left\{\begin{aligned}
  &\text{if } k<l \ : \ I_p\\
  &\text{if } k=l \ : \ M \\
  &\text{if } k > l  \ : \  MA_lMA_{l+1}\ldots A_{k-1}M&.
\end{aligned}\right.
  % &M^{{}^T\! \!\mathcal A_i^m}=MC_{m-1}^TMC_{m-2}^T\ldots C_{i}^TM
\end{align*}
We further note for formulation simplicity $A_m = I_p$.
% When $l=1$, we simply note $M^{\mathcal A^m}= M^{\mathcal A^m_1}$.% and $M^{{}^T\! \!\mathcal A^m}=M^{{}^T\! \!\mathcal A^m_1}$.  

\begin{proposition}\label{pro:concentration_Q^m}
Given a sequence of integer $m\in \mathbb N^\mathbb N$:
% Under Assumptions~\ref{ass:n_p_commensurable}-\ref{ass:Sigma_borne_inferieurement}:
 % there exist two constants $C,c>0$, such that for all linear form $u: \mathcal F(\mathbb C,\mathcal M_{p}) \to \mathbb R$, $1$-Lipschitz for the norm $\|\cdot \|_{F, S^\varepsilon }$:
\begin{align*}
  Q^{A_1^m} \ | \ \mathcal A_Q\in \mathbb E[Q^{A^m}] \pm \mathcal E_2\left(\frac{m\kappa_z^m}{\sqrt n}\right)&
  &\text{in}&
  &(\mathcal M_{p},\left\Vert \cdot\right\Vert_F)
\end{align*}
% for some constant $c>0$.
% Given $z \in S^{\varpesilon}$
  % \hspace{0.3cm}$Q^{A_1^m}\in \mathbb E[Q^{A_1^m}] \pm \mathcal E_2\left(\frac{c^m}{\sqrt n}\right)$ in $(\mathcal M_{p},\left\Vert \cdot\right\Vert_F)$, where $c>1$ is a constant (i.e. it verifies $c = O(1)$).
\end{proposition}
\begin{proof}
  % The concentration
  % \begin{align*}
  %    z \mapsto (Q^z)^{A_1^m} \ | \ \mathcal A_Q\propto \mathcal E_2\left(\frac{m\kappa_z^m}{\sqrt n}\right)
  %  \end{align*} 
  The result is proven the same way as Proposition~\ref{pro:concentration_resolvente_1}, employing the bound on $Q^z$ given by Lemma~\ref{lem:Borne_resolvante}. 
  % We deduce the concentration of $z \mapsto R(z) ^{A_1^m} = \frac{1}{z^m} (Q^z)^{A_1^m}$ distinguishing the cases $n>p$ and $n<p$ as in the proof of Theorem~\ref{the:concentration_resolvent_main}.
   % then the concentration around {cor:deux_eq_deterministes_proches}
\end{proof}
% We leave the proof for the reader who can easily verify that $X \mapsto Q^{A_1^m}$ is $\frac{2m}{z^{\frac{1}{2}+m}} \frac{1}{\sqrt n}$-Lipschitz (see \cite[Proposition 1.2.44]{LOU18}) and we find the result with $c=\frac{2}{z_0}$. 

% We are then looking for a computable deterministic equivalent of $Q^{A_1^m}$. % will be done in two steps, starting from the design of an intermediate deterministic equivalent $Q^{A_1^m}_{D_i}$.
% In \cite{LOU18}, we saw that the devise of a computable deterministic equivalent requires the full understanding of the contribution of each $x_i$ in the matrix $Q=(\frac{1}{n}\sum_{i=1}^n x_ix_i^T + z I_p)^{-1}$.  
% That can be done thanks to the well know Schur formulas:
% \begin{align}\label{eq:formule_Schur}
%   Q=Q_{-i} - \frac{1}{n}\frac{Q_{-i}x_ix_i^TQ_{-i}}{1+\frac{1}{n}x_i^T Q_{-i}x_i}&
%   &Qx_i=\frac{Q_{-i}x_i}{1+\frac{1}{n}x_i^T Q_{-i}x_i},
% \end{align}
% where $Q_{-i}=(\frac{1}{n}XX^T - \frac{1}{n}x_ix_i^T+zI_p)^{-1}$ is the resolvent $Q$ deprived of the contribution of $x_i$.

% $x_i$ as our typical data vector, a lot of lemmas will contain it, of course they are still true if one replaces $x_i$ by any $x_i$, $1\leq i \leq n$. It was tempting to note $x$ the typical column of the matrix $X$ but it might have been confounding since $x$ was defined in Section~\ref{sec:setting} has the testing data, independent of the matrix $X$ it will be indeed widely used in Section~\ref{sec:central_limit_theorem_for_the_score_of_the_ridge_regression}. We write then  that verifies 

% \begin{theorem}\label{the:premier_estimation_Q^m}
% There exists an $(m-1)$-linear function $F_m^\Sigma:A_p^m \rightarrow \mathcal M_p$, depending only on the population covariance $\Sigma$ and a constant $c>1$ such that: 
%   \begin{align}\label{eq:estimation_Q^A_formule_1}
%     \mathbb{E}\left[ Q^{A_1^m}\right]=F_m^\Sigma(A) + O_{\left\Vert \cdot\right\Vert}\left(c^{m}\sup_{1\leq k \leq m}\frac{(2k)^{\frac {2k}{q}}}{n^\frac k 2}\right).
%     % Q^{A_1^m}_{D_i} = \tilde Q^{A_1^m} + \sum_{l=1}^m \mathbb{E}\left[\tr \left(\Sigma Q^{A^q_1}\right)\right]  \mathbb{E} \left[\tilde Q\Sigma Q^{A_1^m_q}\right]. 
%   \end{align}
% Consequently:
% \begin{align*}
%     Q^{A_1^m}\in F_m^\Sigma(A) \pm  \mathcal E_q\left(\frac{c^m}{\sqrt n}\right) \ \ \text{ in } \ (\mathcal M_{p,n},\left\Vert \cdot\right\Vert)
% \end{align*}
% The mapping is defined iteratively thanks to the relation:
% \begin{align*}
%     &F^\Sigma(A_{i}^j) = F^\Sigma(A_i^{j-1}) A_j \tilde Q + \frac{1}{n}\sum_{k=1}^{j-1} \tr\left(\Sigma F^\Sigma(A^{j}_{k})\right)\left(z F^\Sigma A_1^k) - F^\Sigma(A_ 1^{k-1})A_{k-1}\tilde Q \right) 
%     % + O_{\left\Vert \cdot\right\Vert}(c^{m}\kappa_q(m,n))
%     % &\mathbb{E} Q^{A_1^m} - \mathbb{E}\left[Q^{A^{m-1}}A_{m-1}\tilde Q \right] \\
%     % &\hspace{1cm}= \sum_{j=1}^{m-1} \frac{1}{n}\tr\left(\Sigma\mathbb{E} Q^{A^{m}_{j}}\right)\left(z\mathbb{E} Q^{A^j} - \mathbb{E}\left[Q^{A^{j-1}}A_{j-1}\tilde Q \right] \right) + O_{\left\Vert \cdot\right\Vert}(c^{m}\kappa_q(m,n))
% \end{align*}
% \end{theorem}
% An easy way to show (\ref{eq:estimation_Q^A_formule_1}) is to consider two unit norm vectors $u,v \in \mathbb R^p$ and try to estimate $\mathbb{E}[u^TQ^{A_1^m}v]$. 
% When trying to compute $\mathbb{E}[u^TQ^{A_1^m}v]$ for two unit norm vectors $u,v \in \mathbb R^p$, we see appearing in the calculus random quantities like $\frac{1}{n}x_i^T Q^{A^l}x_i$, $\frac{1}{n}x_i^T Q_{-i}^{A^l}x_i$, $u^TQ^{A^l}x_i$ or $u^TQ_{-i}^{A^l}x_i$ for a given $l\in \mathbb N_*$. The following Lemmas directly provide the concentration of these quantities, we do not present their proof since they are closely similar to the proofs of \cite[Propositions~2.2.1 and~2.2.3]{LOU18} and are thus simple consequences of Proposition~\ref{pro:concentration_Q^m} (the dependence between $Q^{A_1^m}$ and $x_i$ is not an issue to set the concentration of the quantities $u^T Q^{A_1^m}x_i$ and $\frac{1}{n}x_i^TQ^{A_1^m}x_i$ since $Q^{A_1^m}$ has a bounded spectral norm).
 % The random variables depending on $Q_{-i}$ are easy to control thanks to Proposition~\ref{pro:concentration_Q^m} it is convenient to rely on the independence between $Q_{-i}$ and $x_i$ (see \cite[Propositions~2.2.3 and~2.2.1]{LOU18} for more detail). 
% The idea is then to deduce the concentration of $\frac{1}{n}x_i^T Q^{A^l}x_i$ and $u^TQ^{A_1^m}x_i$ from the concentrations $\frac{1}{n}x_i^T Q_{-i}^{A^l}x_i$  and $u^T Q_{-i}^{A^l}x_i$ thanks to the following lemma.

% With this lemma at hand we can prove the two following lemmas:
% \begin{lemma}\label{lem:concentration_uQ^A^mx}
% There exists a constant $c>1$ such that:
% \begin{align*}
%   \frac{1}{n}x_i^TQ_{-i}^{A^m}x_i, \ 
%   \frac{1}{n}x_i^TQ^{A_1^m}x_i \in O(c^m) \pm \mathcal E_q\left(\frac{c^m}{\sqrt n}\right) +  \mathcal E_{\frac q 2}\left(\frac{c^m}{ n}\right).
% \end{align*}
% \end{lemma}
% \begin{lemma}\label{lem:concentration_uQx_uQ_-xx}
% Given two unit norm vectors $u,v \in \mathbb R^p$ and $m\in \mathbb N_*$, there exists a constant $c>1$ such that:
% \begin{align*}
%   u^T\tilde Q^{A_1^m}x_i,\
%   u^TQ_{-i}^{A^m}x_i, \
%   u^TQ^{A_1^m}x_i
%   \in O \left(c^m\right) \pm \mathcal E_q\left(c^m\right)
% \end{align*}

% \end{lemma}
% Before proving Theorem~\ref{the:premier_estimation_Q^m} we eventually give 
We now look for a computable deterministic equivalent of $Q^{A_1^m}$. Let us first provide a useful formula to start to disentangle the dependence between $Q^{A_1^m}$ and $x_i$; it is a consequence of the Schur formulas~\eqref{eq:lien_q_qj_schur}
\begin{lemma}\label{lem:telescopage_Q^mi_m_x_Q^m}
  For any $ m \in \mathbb N_*$:
\begin{align*}
  Q^{A_1^{m}}
  &=Q_{-i}^{A_1^{m}}
  +\frac{1}{\Lambda_i^zn}\sum_{l=1}^{m} Q_{-i}^{A_1^{l}}x_ix_i^TQ_{-i}A_lQ^{A^{m}_{l+1}}\\%=Q_{-i}^{A^{m}} - \frac{1}{n}\sum_{l=1}^m Q^{A^{l}}x_ix_i^TQ_{-i}^{A^{m}_{l}}\\
  % &=Q^{A_1^m}_{-1} + \sum_{k=1}^m \left(\frac{-1}{n} \right)^k \sum_{l \in \mathcal L_k^m} Q_{-i}^{A^{l_1}}x_ix_i^TQ_{-i}^{A^{l_2}_{l_1}}x_i\ldots x_i^T Q_{-i}^{A^{m}_{l_k}}
  % &= \sum_{k=0}^m \frac{1}{(zn)^k} \sum_{l \in \mathcal L_k^m} Q_{-i}^{A_1^{l_1}}x_ix_i^TQ_{-i}^{A^{l_2}_{l_1}}x_i\ldots x_i^T Q_{-i}^{A^{m}_{l_k}} \\
  % &= Q_{-i}^{A_1^{m}}
  % +\sum_{k=1}^{m} \frac{1}{(\Lambda_i^zn)^{k}}  \sum_{l \in \mathcal L_k^{m}} Q_{-i}^{A_1^{l_1}}x_ix_i^TQ_{-i}^{A^{l_2}_{l_1}}x_i\ldots x_i^T Q_{-i}^{A^{m}_{l_k}}
\end{align*}
where $\mathcal L_k^m=\{(l_1,\ldots , l_k)\in \mathbb N^k \  \vert \ 1\leq l_1 <\ldots <l_k\leq m\}$ and $\mathcal L_0^m = \{()\}$ contains only the $0$-tuple (and recall that $A_m = I_p$). 
% When one multiply on the left by $x_i$ one gets the shorter identity:
% \begin{align*}
% Q^{A_1^{m}}x_i
%   &= Q_{-i}^{A_1^{m}}x_i
%   +\sum_{k=1}^{m-1} \frac{z}{(\Lambda_i^z)^{k+1}n}  \sum_{l \in \mathcal L_k^{m-1}} Q_{-i}^{A_1^{l_1}}x_ix_i^TQ_{-i}^{A^{l_2}_{l_1}}x_i\ldots x_i^T Q_{-i}^{A^{m}_{l_k}}
% \end{align*}
\end{lemma}
\begin{proof}
  The result is just a consequence of the following telescoping sum decomposition (where we set $A_0,A_m=I_p$):
  \begin{align*}
      Q^{A^{m}}-Q_{-i}^{A^{m}}
      &=\sum_{l=1}^m Q_{-i}^{A^{l-1}}A_{l-1}Q^{A^{m}_{l}}-Q_{-i}^{A^{l}}A_lQ^{A^{m}_{l+1}} \\
      &=\sum_{l=1}^m Q_{-i}^{A^{l-1}}A_{l-1}(Q-Q_{-i})A_{l}Q^{A^{m}_{l+1}}
      \ =  \ \frac{1}{\Lambda_i^zn}\sum_{l=1}^m Q_{-i}^{A^{l}}x_ix_i^TQ_{-i} A_lQ^{A^{m}_{l+1}}.
  \end{align*}
  % The second result is due to the equality:
  % \begin{align*}
  %   Q_{-i}x_i + \frac{1}{n \Lambda_i^z}Q_{-i}x_ix_i^T Q_{-i}x_i = \frac{z Q_{-i}x_i}{\Lambda_i^z}
  % \end{align*}
  % (recall that $\Lambda_i^z \equiv z - \frac{1}{n}x_i^T Q_{-i}x_i$).
\end{proof}
% To prove this corollary we just need a supplementary lemma that we provide without proof since it is strictly analogous to Lemma~\ref{lem:uQx}.
\begin{lemma}\label{lem:concentration_uQ^A^mx}
  Given a deterministic vector $u \in \mathbb R^p$, for any $k,l \in \mathbb N$ such that $1\leq k<l <m$:
  \begin{align*}
    u^T Q_{-i}^{A_k^l}x_i  \ | \ \mathcal A_Q \in O \left( \kappa_z^{l-k+1} \right) \pm \mathcal E_2 \left((c\kappa_z)^{l-k+1}  \right),
  \end{align*}
  for some constant $c>1$.
\end{lemma}
\begin{corollary}\label{cor:diff_Q^m_Q_-1^m}
  $\left\Vert \mathbb E_{\mathcal A_Q} [ Q_{-i}^{A^m} - Q^{A_1^m}]\right\Vert = O \left(\frac{(c\kappa_z)^m}{n}\right)$ for a constant $c>1$.
\end{corollary}
\begin{proof}
We do not use directly the second identity of Lemma~\ref{lem:telescopage_Q^mi_m_x_Q^m} because it would let a term $m^m$ appear in the bound.
Instead of the first result of Lemma~\ref{lem:telescopage_Q^mi_m_x_Q^m}, one could have stated the identity:
\begin{align*}
  Q^{A_1^{m}}
  &=Q_{-i}^{A_1^{m}}
  +\frac{1}{\Lambda_i^zn}\sum_{l=1}^{m} Q^{A_1^{l-1}}A_{l-1}Q_{-i}x_ix_i^TQ_{-i}^{A^{m}_{l}},
\end{align*}
(recall the notation $A_0 = I_p$).
Putting those two identities together one obtains:
\begin{align}\label{eq:simplification_Qm_Qmim}
  Q^{A_1^{m}}
  &=Q_{-i}^{A_1^{m}}
  +\frac{1}{\Lambda_i^zn}\sum_{l=1}^m  Q_{-i}^{A_1^{l}}x_ix_i^TQ_{-i}^{A_{l}^{m}} \nonumber\\
  &\hspace{1cm}+\frac{1}{(\Lambda_i^zn)^2}\sum_{l=1}^m \sum_{k=l+2}^m Q_{-i}^{A_1^{l}}x_ix_i^TQ_{-i}A_lQ^{A_{l+1}^{k-1}}A_{k-1}Q_{-i}x_ix_i^TQ_{-i}^{A^{m}_{k}} \nonumber\\
  &\hspace{1cm}  + \frac{1}{(\Lambda_i^zn)^2}\sum_{l=1}^m  Q_{-i}^{A_1^{l}}x_ix_i^TQ_{-i}A_lQ_{-i}x_ix_i^TQ_{-i}^{A^{m}_{l+1}}
\end{align}
Thus, knowing from Lemmas~\ref{lem:concentration_uQ^A^mx} and \ref{lem:Borne_resolvante} that given any deterministic vector $u \in \mathbb R^p$ such that $\|u\| \leq 1$, any $l \in [m]$ and any $k \in \{l+2,\ldots, m\}$ we have:
\begin{itemize}
  \item $u^TQ_{-i}^{A_1^{l}}x_i \ | \ \mathcal A_Q \in O(\kappa_z^l) \pm \mathcal E_2((c\kappa_z)^l)$
  \item $\frac{1}{|\Lambda^z_i n|} \left\vert x_i^TQ_{-i}A_lQ^{A_{l+1}^{k-1}}A_{k-1}Q_{-i}x_i \right\vert \leq \frac{\kappa_z^{k-l+1} \check \kappa_z^2}{|z|n} \leq O \left( \frac{\kappa_z^{k-l}}{n} \right)$,
\end{itemize}
one can deduce from the estimation of the product of concentrated random variables given in Lemma~\ref{lem:borne_moment_produit_m_variables} that for all $u,v \in \mathbb R^p$ such that $\|u\|,\|v\| \leq 1$:
\begin{align*}
  u^T \mathbb E_{\mathcal A_Q}  \left[  Q_{-i}^{A^m} - Q^{A_1^m} \right]v
  \leq O \left( \frac{(c\kappa_z)^{m}}{n} \right) + O \left( \frac{(c\kappa_z)^{k-l-1}}{n^2} \right) \leq O \left( \frac{(c\kappa_z)^{m}}{n} \right).
\end{align*}
% It is a simple consequence of Lemma~\ref{lem:telescopage_Q^mi_m_x_Q^m} and the bound given by Lemmas~\ref{lem:Borne_resolvante},~\ref{lem:Borne_Lambda}:
%   \begin{align*}
%     \left\Vert \mathbb E Q_{-i}^{A^m} - \mathbb E Q^{A_1^m}\right\Vert
%     &\leq \sup_{\left\Vert u\right\Vert,\left\Vert v\right\Vert\leq 1} \frac{1}{|\Lambda_i^z|n}\sum_{l=1}^m \mathbb{E}\left[\left\vert u^T Q_{-i}^{A^{l}}x_ix_i^TQ_{-i}A_lQ^{A^{m}_{l}} v  \right\vert\right]
%     % &\leq \sup_{\left\Vert u\right\Vert,\left\Vert v\right\Vert\leq 1} \frac{1}{n}\sum_{l=1}^m \mathbb{E}\left[u^T Q_{-i}^{A^{l}}x_ix_i^TQ^{A^{m}_{l}} v \right]
%     % &\leq \sum_{k=1}^m  \sum_{1\leq l_1<\ldots<l_k\leq m} O\left(\frac{c^m}{n} \right) 
%     \leq O \left(\frac{m\kappa_z^{m+1}\check\kappa_z}{n|z|}\right)
%      % \leq O \left(\frac{m\kappa_z^{m}}{n}\right)
%   \end{align*}
%   which allows us to conclude since $\kappa_z \check \kappa_z = \frac{|z|}{1+|z|} \leq |z|$.
\end{proof}
Before starting the estimation of $\mathbb E_{\mathcal A_Q}[Q^{A_1^m}]$, we still need a result analogous to Lemma~\ref{lem:concentration_QX_s_z}.
\begin{lemma}\label{lem:concentration_QmX^A}
  Given $k,l \in \mathbb N$ such that $1\leq k<l <m$:
  \begin{align*}
    Q^{A_k^l}X  \ | \ \mathcal A_Q \propto \mathcal E_2 \left((c\kappa_z)^{l-k+1}  \right),
  \end{align*}
  for some constant $c>1$.
\end{lemma}
\begin{proof}
  The concentration is really proven the same way as in the proof of Proposition~\ref{pro:concentration_resolvente_1} (and the fact that there exists a constant $c>0$ such that for all $i\in[m]$, $i \leq c^i$).

  To bound $\|\mathbb E_{\mathcal A_Q}[Q^{A_k^l}x_i]\|$, we use the identity \eqref{eq:simplification_Qm_Qmim} and bound for any deterministic vector $u\in \mathbb R^p$ such that $\|u\| \leq 1$:
  \begin{align*}
    &\left\vert \mathbb E_{\mathcal A_Q} \left[  u^TQ^{A_k^l}x_i \right] \right\vert
    = \left\vert \mathbb E_{\mathcal A_Q} \left[  u^TQ^{A_k^l}x_i \right] \right\vert
    + \frac{1}{\hat \Lambda_i^zn}\sum_{j=k}^l \left\vert \mathbb E_{\mathcal A_Q} \left[ u^TQ_{-i}^{A_k^{j}}x_ix_i^TQ_{-i}^{A_{j}^{l}}v \right] \right\vert \\
    &\hspace{0.2cm}  + \left\vert \frac{1}{(\hat \Lambda_i^zn)^2}\sum_{j=k}^l \mathbb E_{\mathcal A_Q} \left[u^T Q_{-i}^{A_k^{j}}x_i\right] \mathbb E_{\mathcal A_Q} \left[x_i^TQ_{-i}A_jQ_{-i}x_i\right] \mathbb E_{\mathcal A_Q} \left[x_i^TQ_{-i}^{A^{l}_{j+1}}v\right] \right\vert\\ 
    &\hspace{0.2cm} + \left\vert \frac{1}{(\hat\Lambda_i^zn)^2}\sum_{j=k}^l \sum_{o=j+2}^l \mathbb E_{\mathcal A_Q} \left[u^T Q_{-i}^{A_k^{j}}x_i\right] \mathbb E_{\mathcal A_Q} \left[x_i^TQ_{-i}A_jQ^{A_{j+1}^{o-1}}A_{o-1}Q_{-i}x_i \right] \mathbb E_{\mathcal A_Q} \left[x_i^TQ_{-i}^{A^{l}_{o}} v\right] \right\vert\\
    &\hspace{0.2cm}+ O \left( (c\kappa)^{l-k+1} +\frac{(l-k)(c\kappa)^{l-k+1} \check \kappa_z }{n|z|} \left( 1 + \frac{\kappa_z \check\kappa_z(l-k)}{|z|n} \right)\right)  \leq O \left((c\kappa_z)^{l-k+1} \right),
  \end{align*}
  for some constant $c>0$.
\end{proof}

\begin{proposition}\label{pro:estimation_QA}
With the notation:
  \begin{align*}
    T^{A^{m}_{l}}\equiv \diag_{i\in[m]} \left( \frac{1}{n\Lambda_i^z}x_i^TQ_{-i}^{A^{m}_{l}}x_i \right), 
    % \propto \mathcal E_2 \left( \frac{(c\kappa_z)^{m-l}}{\sqrt n} \right)&
    % &\text{in} \ \left( \mathcal D_n, \|\cdot \| \right),
  \end{align*}  
  one can estimate for any (sequence of) integer $m$ and any set of deterministic matrices $A_1,\ldots, A_{m-1} \in \mathcal{M}_{p}^{m-1}$:
  \begin{align*}
    &\left\Vert Q^{A_1^m} - Q^{A_1^{m-1}}A_{m-1} \tilde Q \right.\\
    &\hspace{1cm} \left. -  \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^{m-1}\frac{1}{\Lambda_i^z}\sum_{l\in L_k^{m-1}}\mathbb{E}_{\mathcal A_Q}\left[ \tr \left(  A Q_{-i}^{A_1^{l_1}}\Sigma_i\tilde Q\right)\right]\tilde T_i^{A^{l_2}_{l_1}}\cdots \tilde T_i^{A^{m}_{l_k}}\right\Vert_F
    \leq O\left( \frac{(c\kappa_z)^{m}}{\sqrt n} \right),
  \end{align*}
  where for any $k,l \in [m]$, $k<l$, $\tilde T^{\mathcal A_k^l}$ is a deterministic matrix satisfying $\|\tilde T_i^{A^{m}_{l_k}} - \tilde T_i^{A^{m}_{l_k}}\|_F \leq O((c\kappa_z)^{l-k+1}/\sqrt n)$.
\end{proposition}
 \begin{proof}%[Proof of Theorem~\ref{the:premier_estimation_Q^m}]
  % Let us consider two vectors $u,v\in \mathbb R^p$ of unit norm, Let us estimate:
  % We are now going to show (\ref{eq:estimation_Q^A_formule_1}) by iteration.

  % We know that (\ref{eq:estimation_Q^A_formule_1}) is true when $m=0$ (Proposition~\ref{pro:concentration_resolvente_1} and Corollary~\ref{cor:deux_eq_deterministes_proches}) we are now going to suppose its validity for an integer $m\geq 0$, and we will show it for the next step $m+1$. Since $m$ is a quasiasymptotic quantity, this iterative demonstration is quite abusive, however, its validity can be verified, if we replace the term $O \left(\frac{c^m}{\sqrt n} \right)$ in the iteration hypothesis by $\frac{Cc^{m-1}}{\sqrt n}$ for some $C>0$ and proceed the same way for all the concentrations appearing below.
  % We already know from Proposition~\ref{pro:borne_trCQm} that $t_m$ is bounded since it is possible, thanks to Lemma~\ref{lem:borne_trace_norme_spec}, to remove all the terms $QA_i$ when $i$ is even and $uu^TQ$ so that only remains the quantity $\frac{1}{p}$
  
  \sloppypar{Given a deterministic matrix $A \in \mathcal{M}_{p}$ such that $\|A\|_F \leq 1$, let us try and estimate $\mathbb{E}_{\mathcal A_Q}\left[\tr \left( A Q^{A_1^m} A_m (Q-\tilde Q) \right)\right]$, we allow ourselves not to display all the steps of the calculus since similar inferences were already displayed in the proofs of Propositions~\ref{pro:borne_EQ_m_tQ} and~\ref{pro:2_hypo_pour_proposition_equation_proche_pt_fixe_proche}. For simplicity, we note $\tilde Q$ instead of $\tilde Q^{\tilde \Lambda^z}$.}
   % and we assume that all the $x_i$ have the same distribution.
  \begin{align*}%\label{eq:descr_contributions_xQAQy}
    &\mathbb{E}_{\mathcal A_Q}\left[ \tr \left( AQ^{A_1^{m-1}} A_{m-1} ( Q- \tilde Q) \right)\right]\\
    &\hspace{1cm}=\frac{1}{n}\sum_{i=1}^n\mathbb{E}_{\mathcal A_Q}\left[ \frac{1}{z} \tr \left( A Q^{A^{m}} x_i x_i^T\tilde Q \right)\right] - \mathbb{E}_{\mathcal A_Q}\left[\frac{\tr \left( A Q^{A^{m}} \Sigma_i \tilde Q \right)}{\tilde \Lambda_i^z}\right] \\
    &\hspace{1cm}= \frac{1}{n}\sum_{i=1}^n  a_i + b_i + c_i %+O \left(\frac{1}{\sqrt{n}}\right)
  \end{align*}
  where for all $i\in [n]$:
  \begin{align*}
    & a_i
    = \mathbb{E}_{\mathcal A_Q} \left[\frac{\tilde \Lambda_i^z - \Lambda_i^z}{ \Lambda_i^z\tilde \Lambda_i^z} \, \tr \left( A Q^{A^{m-1}}A_{m-1}Q_{-i}x_ix_i^T\tilde Q \right) \right]  \\
    &b_i 
     = \frac{1}{\tilde \Lambda_i^z}\mathbb{E}_{\mathcal A_Q}\left[ \tr \left( A \left(Q^{A^{m-1}_1}-Q_{-i}^{A^{m-1}_1}\right) A_{m-1}Q_{-i}x_ix_i^T\tilde Q \right)\right] \\
     % = \mathbb{E}_{\mathcal A_Q}\left[u^T \left(Q^{A^{m-1}}-Q_{-i}^{A^{m-1}}\right)  A_{m-1} Qx_ix_i^T\tilde Qv\right] \\
    &c_i 
    =  \frac{1}{\tilde \Lambda_i^z}\mathbb{E}_{\mathcal A_Q}\left[ \tr \left( A \left(Q_{-i}^{A^{m}} - Q^{A^{m}} \right)\Sigma_i  \tilde Q \right)\right]
    % &A_{2,2}
    % =  \frac{1}{1+\delta}\frac{1}{n}\mathbb{E}_{\mathcal A_Q}\left[u^T (Q\tilde C)^m  Q_{-i} \tilde C \tilde Qx_ix_i^TQv\right]\\
  \end{align*}
  Let us first apply Proposition~\ref{pro:estimation_XDY} with the hypotheses:
   \begin{itemize}
      \item $\tilde QX \ | \ \mathcal A_Q \propto \mathcal E_2(\kappa_z)$ and $\|\mathbb E[\tilde Qx_i]\|\leq O(1)$ thanks to Assumption~\ref{ass:borne_norme_x_i}, \ref{ass:concentration_X},
      \item $Q^{A_1^m}X \ | \ \mathcal A_Q \propto \mathcal E_2((c\kappa_z)^m)) $ and $\|\mathbb E_{\mathcal A_Q}[Q^{A_1^m}x_i] \| \leq O((c\kappa_z)^m))$ given by Lemma~\ref{lem:concentration_QmX^A},
      \item $ \Lambda^z \ | \ \mathcal A_Q\in \mathbb E_{\mathcal A_Q}[\Lambda^z] \pm \mathcal E_2 \left(\frac{\kappa^z}{\sqrt n}\right)$ in $(\mathcal{D}_{n}, \| \cdot \|)$ given by Lemma~\ref{lem:Concentration_lambda},
      \item $\|  \mathbb E_{\mathcal A_Q}[\Lambda^z] - \hat \Lambda^z\|_F \leq O(\kappa^z/\sqrt n)$ thanks to Lemma~\ref{lem:lambda_lambda_hat_proche},
      % \item $|\hat \Lambda_i^z| \geq O(|z|/\check \kappa_z)$ given by Lemma~\ref{lem:Borne_Lambda_hat},
    \end{itemize}
  % Thanks to the bounds $O(\check\kappa_z) \leq |\Lambda^z |, |\Lambda^z|\leq O(\check\kappa_z)$ given by Lemmas~\ref{lem:Borne_Lambda},~\ref{lem:Lambda^z_tilde_borne} and thanks to Lemma~\ref{lem:borne_moment_produit_m_variables} applied to the concentrations:
  % \begin{itemize}
  %    \item $x_i^T\tilde Q v \in O(\kappa_z) \pm \mathcal E_2(\kappa_z)$ following from the assumptions on $x_i$ and Lemma~\ref{pro:borne_EQ_m_tQ}
  %    \item $u^T Q_{-i}^{A^{m}}x_i\in O(\kappa_z^m) \pm \mathcal E_2(\kappa_z^m)$ given by Lemma~\ref{lem:concentration_uQmx}*
  %    \item $\Lambda_i^z \in \tilde \Lambda_i^z \pm \mathcal E_2(\kappa_z/\sqrt n)$ given by Lemmas~\ref{lem:Concentration_lambda},~\ref{lem:lambda_lambda_hat_proche} and Proposition~\ref{pro:hat_lambda_vers_tilde_lambda},
  %  \end{itemize}
  to set:
  \begin{align*}
    \left\vert  \frac{1}{n} \sum_{i=1}^n a_i\right\vert
    &= \mathbb{E}_{\mathcal A_Q} \left[ \, \tr \left( A Q^{A^{m}}X\frac{\tilde \Lambda^z - \Lambda^z}{ \tilde \Lambda^z}X^T\tilde Q \right) \right] 
    % \leq O \left( \frac{\check \kappa_z^2}{|z|^2} \right) \mathbb{E}_{\mathcal A_Q} \left[|\tilde \Lambda_i^z - \Lambda_i^z| |u^T Q_{-i}^{A^{m}}x_i||x_i^T\tilde Q v| \right]
    \leq O \left( \frac{\check \kappa_z (c\kappa_z)^{m +2}}{|z|\sqrt n} \right) \leq \left( \frac{(c\kappa_z)^{m+1}}{\sqrt n} \right)
    % &\leq \sqrt{\mathbb{E}_{\mathcal A_Q} \left[\vert u^T Q_{-i}^{A^{m}}x_i \vert^2\right]} \, \mathbb{E}_{\mathcal A_Q} \left[\left\vert x_i^T\tilde Q v\right\vert^4\right]^{\frac{1}{4}} \, \mathbb{E}_{\mathcal A_Q}\left[\left\vert \delta -\frac{1}{n}x_i^T Q_{-i}x_i\right\vert^4\right]^{\frac{1}{4}}= \ \ O \left(\frac{c^m}{\sqrt n}\right)
  \end{align*} 
  % thanks to Lemmas~\ref{lem:concentration_uQ^A^mx} and~\ref{lem:concentration_uQx_uQ_-xx}. 
  The bound on $c_i$ is just a consequence of Corollary~\ref{cor:diff_Q^m_Q_-1^m}:
  \begin{align*}
    \left\vert c_i\right\vert
    \leq \kappa_z \left\Vert \mathbb E_{\mathcal A_Q}\left[  Q_{-i}^{A^l} -  Q^{A^l} \right]\right\Vert = O \left(\frac{\kappa_z^m}{n}\right),
  \end{align*}
  Because it relies on similar justifications, we will directly replace $\Lambda_i^z$ with $\tilde \Lambda_i^z$ in the coming estimations.

  The quantities $a_i$, $i \in [n]$, are not negligible as the two others, we need to evaluate it. We can again inspire from Lemma~\ref{lem:telescopage_Q^mi_m_x_Q^m} and write:
  \begin{align*}
    \frac{1}{n} \sum_{i=1}^nb_i 
     &= \frac{1}{z\tilde \Lambda_i^zn^2}\sum_{i=1}^n\sum_{l=1}^{m-1}\mathbb{E}_{\mathcal A_Q}\left[ \tr \left(  A Q^{A_1^{l}}x_ix_i^TQ_{-i}^{A^{m}_{l}}x_ix_i^T\tilde Q \right)\right] \\
     % &= \frac{1}{\Lambda_i^zn}\sum_{l=1}^{m-1}\mathbb{E}_{\mathcal A_Q}\left[ \tr \left(  A Q^{A_1^{l-1}}A_{l-1}Q_{-i}x_ix_i^TQ_{-i}^{A^{m}_{l}}x_ix_i^T\tilde Q \right)\right] \\
     &=\frac{1}{zn^2} \sum_{l=1}^{m-1}\mathbb{E}_{\mathcal A_Q}\left[ \tr \left(  A Q^{A_1^{l}}XTX^T\tilde Q \right)\right],
  \end{align*}
  (since $\check\kappa_z \kappa_z/|z| \leq 1$). 
  Noting that $T^{A^{m}_{l}} \propto \mathcal E_2 \left( \frac{(c\kappa_z)^{m-l}}{\sqrt n} \right)$ in $\left( \mathcal D_n, \|\cdot \| \right)$, one can use one more time Proposition~\ref{pro:estimation_XDY} to obtain for any deterministic diagonal matrix $\tilde T^{A^{m}_{l}}$ such that $\|\mathbb E_{\mathcal A_Q}[T^{A^{m}_{l}}] - \tilde T^{A^{m}_{l}}\|_F \leq O\left( \frac{(c\kappa_z)^{m-l+1}}{\sqrt n} \right)$:
  \begin{align*}
  \frac{1}{n} \sum_{i=1}^nb_i
    &=\frac{1}{nz} \sum_{l=1}^{m-1}\mathbb{E}_{\mathcal A_Q}\left[ \tr \left(  A Q^{A_1^{l}}X\tilde T^{A^{m}_{l}}X^T\tilde Q \right)\right] + O\left( \frac{(c\kappa_z)^{m}}{\sqrt n} \right)\\
    &=\frac{1}{n} \sum_{i=1}^n \frac{1}{\tilde \Lambda_i^z}\sum_{l=1}^{m-1}\mathbb{E}_{\mathcal A_Q}\left[ \tr \left(  A Q^{A_1^{l-1}}A_lQ_{-i} x_i\tilde T_i^{A^{m}_{l}}x_i^T\tilde Q \right)\right] + O\left( \frac{(c\kappa_z)^{m}}{\sqrt n} \right)\\
    &= \frac{1}{n}\sum_{i=1}^n\frac{1}{\tilde \Lambda_i^z} \sum_{l=1}^{m-1}\mathbb{E}_{\mathcal A_Q}\left[ x_i^T\tilde QA Q_{-i}^{A_1^{l}}x_i\tilde T^{A^{m}_{l}}\right] \\
    &\hspace{1cm}+\frac{1}{nz\tilde\Lambda_i^z} \sum_{i=1}^n\sum_{l=1}^{m-1}\sum_{k=1}^{l-1}\mathbb{E}_{\mathcal A_Q}\left[ \tr \left(  A Q^{A_1^{k}}x_ix_iQ_{-i}^{A_k^{l}}x_i\tilde T_i^{A^{m}_{l}}x_i^T\tilde Q \right)\right] + O\left( \frac{(c\kappa_z)^{m}}{\sqrt n} \right),
  \end{align*}
  With the same resort to Proposition~\ref{pro:estimation_XDY}, on can show iteratively that:
  \begin{align*}
    \frac{1}{n} \sum_{i=1}^nb_i
    &=\frac{1}{n} \sum_{i=1}^n \sum_{k=1}^{m-1}\frac{1}{\tilde\Lambda_i^z}\sum_{l\in L_k^{m-1}}\mathbb{E}_{\mathcal A_Q}\left[ x_i^T\tilde Q  A Q_{-i}^{A_1^{l_1}}x_i\tilde T_i^{A^{l_2}_{l_1}}\cdots \tilde T_i^{A^{m}_{l_k}}\right] + O\left( \frac{(c\kappa_z)^{m}}{\sqrt n} \right)\\
    &=\frac{1}{n} \sum_{i=1}^n\sum_{k=1}^{m-1}\frac{1}{\tilde\Lambda_i^z}\sum_{l\in L_k^{m-1}}\mathbb{E}_{\mathcal A_Q}\left[ \tr \left(  A Q_{-i}^{A_1^{l_1}}\Sigma_i\tilde Q\right)\right]\tilde T_i^{A^{l_2}_{l_1}}\cdots \tilde T_i^{A^{m}_{l_k}} + O\left( \frac{(c\kappa_z)^{m}}{\sqrt n} \right),
  \end{align*}
  for some constant $c'>0$ (each time one uses the proposition, the bounds of the estimation are the same and we use it $\sum_{k=1}^{m-1} \binom{k}{m-1} \, k \leq (m-1)2^{m-1}$).
  \end{proof}

  Given two integers $k, l>0$, $h\leq l$ and a tuple $\alpha = (\alpha_{-h},\ldots, \ldots, \alpha_{0},\alpha_{1},\ldots, \alpha_{l-1}) \in [n]^{l+h}$, let us note:
  % Given two integers $k,l \in[m-1]$, $k<l$: 
  \begin{align*}
    \Psi_\alpha^h &\equiv  \mathbb E_{\mathcal A_Q}  \left[ \frac{1}{n} \tr \left( \tilde \Sigma_{\alpha_{-h}}\tilde Q \cdots   \tilde \Sigma_{\alpha_{-1}}\tilde Q\tilde \Sigma_{\alpha_0} Q \cdots \tilde \Sigma_{\alpha_{l-1}} Q\right) \right],
    % \Phi_\alpha^h &\equiv  \mathbb E_{\mathcal A_Q}  \left[ \frac{1}{n} \tr \left( \Sigma_{\alpha_1}Q \cdots \Sigma_{\alpha_{l-h}}Q\Sigma_{\alpha_{l-h+1}}\tilde Q \cdots   \Sigma_{\alpha_l}\tilde Q\right) \right],
    % \Phi_k &\equiv \left( \mathbb E_{\mathcal A_Q}  \left[ \frac{1}{n\tilde \Lambda_{i_k}} \tr \left( \Sigma_{i_1}Q\Sigma_{i_2}Q \cdots Q  \Sigma_{i_k}\right) \right] \right)_{(i_1,\ldots,i_k) \in [m]^k}\\
    % \Psi_k &\equiv \left( \mathbb E_{\mathcal A_Q}  \left[ \frac{1}{n} \tr \left( \Sigma_{i_1}Q\Sigma_{i_2}Q \cdots \tilde Q  \Sigma_{i_k}\right) \right] \right)_{(i_1,\ldots,i_k) \in [n]^k},
    % \Psi_k &\equiv \left( \mathbb E_{\mathcal A_Q}  \left[ \frac{1}{n\tilde \Lambda_{i_k}} \tr \left( \Sigma_{i_1}Q\Sigma_{i_2}Q \cdots \tilde Q  \Sigma_{i_k}\right) \right] \right)_{(i_1,\ldots,i_k) \in [n]^k},
  \end{align*}
  where for any $i \in[n]$, we noted $\tilde \Sigma_i \equiv \Sigma_i/\tilde \Lambda_i^z$.
  We further introduce the tensor of shape $n \times \cdots \times n$ ($l$ times) $\Phi_l^h \equiv \left( \Phi_\alpha^h \right)_{\alpha \in [n]^l}$.
  Given $h>0$ and replacing in the last estimation $A$ with $\frac{1}{n}\tilde\Sigma_{\alpha_{1-h}}\tilde Q \cdots \tilde\Sigma_{\alpha_{-1}}\tilde Q\tilde\Sigma_{\alpha_0}$ satisfying:
  \begin{align*}
     \left\Vert \frac{1}{n}\tilde \Sigma_{\alpha_{1-h}}\tilde Q \cdots \tilde \Sigma_{\alpha_{-1}}\tilde Q\tilde \Sigma_{\alpha_0} \right\Vert_F \leq O \left( \frac{1}{\sqrt n} \right),
   \end{align*}
    we know that for any $\alpha =(\alpha_{-h},\ldots,\alpha_0,\alpha_1,\ldots, \alpha_{m-1}) \in [n]^{m+h}$:
  \begin{align*}
    \Psi_\alpha^h - \Psi_\alpha^{h+1}
    = \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^{m-1}\sum_{l\in L_k^{m-1}} \Psi^{h+1}_{\alpha_{-h}^{l_1}, i} \Psi^0_{\alpha_{l_1}^{l_2}, i}\cdots \Psi^0_{\alpha_{l_k}^m, i} + O\left( \frac{(c\kappa_z)^{m}}{n} \right),
  \end{align*}
  where for any $k,l \in \{h, m-1\}$, $k<l$, $\alpha_k^l = \alpha_k,\ldots, \alpha_{l-1}$.

  Inspiring from this equation, we are going to introduce with next proposition a set of tensors that will allow us to approximate $\mathbb E[Q^{A_1^m}]$.
  \begin{proposition}\label{pro:Definition_Phi}
    There exists a unique sequence of tensors $\Psi$ satisfying:
  \begin{align*}
  \left\{
    \begin{aligned}
    &\forall m >2, h \in \mathbb N, \alpha =(\alpha_{-h},\ldots, \alpha_{m-1}) \in [n]^{m+h}:\\
    % &\hspace{1cm} \ \tilde \Phi_\alpha^h - \tilde \Phi_\alpha^{h+1} = \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^{m-1}\sum_{l\in L_k^{m-1}} \tilde \Phi^{h+1}_{\alpha_{-h}^{l_1}, i} \tilde \Psi^0_{\alpha_{l_1}^{l_2}, i}\cdots \tilde \Psi^0_{\alpha_{l_k}^m, i},\\
    &\hspace{1cm} \ \tilde \Psi_\alpha^h - \tilde \Psi_\alpha^{h+1} = \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^{m-1}\sum_{l\in L_k^{m-1}} \tilde \Psi^{h+1}_{\alpha_{-h}^{l_1}, i} \tilde \Psi^0_{\alpha_{l_1}^{l_2}, i}\cdots \tilde \Psi^0_{\alpha_{l_k}^m, i},\\
    % & \forall l \in[n], \alpha \in [n]^l: \ \tilde \Phi^{l-1}_{\alpha} = \tilde \Phi^l_{\alpha}  = \frac{1}{n} \tr \left( \bar{\tilde \Sigma}_{\alpha_1} \bar{\tilde Q}\tilde \Sigma_{\alpha_{2}}\tilde Q  \cdots \tilde \Sigma_{\alpha_l} \tilde Q \right). \\
    & \forall l \in[n], \alpha \in [n]^l: \ \tilde \Psi^{l-1}_{\alpha} = \tilde \Psi^l_{\alpha}  = \frac{1}{n} \tr \left( \tilde \Sigma_{\alpha_1} \tilde Q  \cdots \tilde \Sigma_{\alpha_l} \tilde Q \right). 
    % & \forall l \in[n], \alpha \in [n]^l: \ \tilde \Phi^{l-1}_{\alpha} = \tilde \Phi^l_{\alpha}  = \frac{1}{n} \tr \left( \Sigma_{\alpha_1} \tilde Q  \cdots \Sigma_{\alpha_l} \tilde Q \right). 
    \end{aligned}\right.
  \end{align*}
  
  \end{proposition}

\begin{proof}
  % We are first going to show that there exists a unique sequence of tensors $\Phi$ such that:
  % \begin{align*}
  % \left\{
  %   \begin{aligned}
  %   &\forall m >2, h \in \mathbb N, \alpha =(\alpha_{-h},\ldots, \alpha_{m-1}) \in [n]^{m+h}:\\
  %   &\hspace{1cm} \ \tilde \Phi_\alpha^h - \tilde \Phi_\alpha^{h+1} = \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^{m-1}\sum_{l\in L_k^{m-1}} \tilde \Phi^{h+1}_{\alpha_{-h}^{l_1}, i} \mathfrak c^{l_1+h} \left( \tilde \Phi^0_{\alpha_{l_1}^{l_2}, i} \right)\cdots \mathfrak c^{l_k+h} \left( \tilde \Phi^0_{\alpha_{l_k}^m, i} \right),\\
  %   & \forall l \in[n], \alpha \in [n]^l: \ \tilde \Phi^{l-1}_{\alpha} = \tilde \Phi^l_{\alpha}  = \frac{1}{n} \tr \left( \Pi_{i=1}^l\mathfrak c^i \left( \tilde \Sigma_{\alpha_i} \tilde Q \right) \right), \\
  %   \end{aligned}\right.
  % \end{align*}
  % where $\mathfrak c$ is the conjugate involution (for any $M \in \mathcal{M}_{p,n}$, $\mathfrak c(M) = \bar M$).
  % Let us first show that the sequence $(\tilde \Phi_\alpha^h)_{l \in \mathbb N,\alpha \in [n]^l, h \in [l]}$ is well defined (existence and uniqueness).
 % The reason why we consider the tensor $\Phi$ having a conjugate matrix in its definition is that this way, the matrix $\tilde\Phi_2^2 \equiv (\tilde\Phi_{i,j}^2)_{1\leq i,j\leq n}$, unlike $\tilde\Psi_2^2$ , is invertible as a Gram matrix when the set of matrices $(\tilde \Sigma_1,\ldots, \tilde \Sigma_n)$ is a free family in the Hilbert space $\mathcal{M}_{p}(\mathbb C)$ endowed with the scalar product $\langle A | B \rangle = \frac{1}{n}\tr \left(  \mathfrak c (A^T\tilde Q) B \tilde Q \right)$. 
 % When $(\Sigma_1,\ldots, \Sigma_n)$ is not free, we can still extract a free sub-family $(\Sigma_{i_1},\ldots, \Sigma_{i_k})$ and express the sum on $i$ going from $1$ to $n$ as a weighted sum on $i_1,\ldots, i_k$.
 % then $\Phi_2^2$ is invertible as a Gramm {\color{red} it is a complex matrix} matrix of a free family of matrices. 
 We already know that for any $i \in [n]$:
  \begin{align*}
     % \tilde \Psi_{(i)} ^0 = \tilde \Psi_{(i)} ^1 = \frac{1}{n} \tr (\tilde \Sigma_i \tilde Q)&
     % &\text{and}&
     \tilde \Psi_{(i)} ^0 = \tilde \Psi_{(i)} ^1 = \frac{1}{n} \tr (\tilde \Sigma_i \tilde Q)
   \end{align*}
   Let us now assume that there exists $m>1$ such that for any $k\in [m-1]$, and any $h\in \{0,\ldots,k\}$, and any $\alpha \in [n]^{k}$, $\tilde \Psi_\alpha^{h}$ is well defined and we know how to compute it. Besides, for any $\alpha \in [m]^n$, we also know how to compute $\tilde \Psi^{m-1}_{\alpha} = \tilde \Psi^m_{\alpha} $. We then further assume that there exist $h \in [m]$ such that we know how to compute any $\tilde \Psi^k_{\alpha} $ for $k<h$. 
   If $h\geq 1$, then we see from the iteration formula that $\tilde \Psi_\alpha^h$ expresses as a sum of computable elements, the only issue raises when $h=0$, then $\tilde \Psi_\alpha^0$ are appearing on both side of the equality. To invoke the invertibility of $\tilde \Psi_2^2$, let us first consider:
   % Let us express for any $\alpha = (\alpha_{1-h}, \ldots, \alpha_0,\ldots, \alpha_{m-h}\}$:
  \begin{align*}
      \tilde \Psi_\alpha^0
      &= \tilde \Psi_\alpha^{1}
      +  \frac{1}{n} \sum_{i=1}^n\sum_{l=1}^{m-1} \tilde \Psi^{1}_{\alpha_{0}^{l}, i} \tilde \Psi^0_{\alpha_{l}^{m}, i}
      % +  \frac{1}{n} \sum_{i=1}^n\frac{1}{(\tilde \Lambda_{i}^z)^{2} }\sum_{l=1}^{m-h-1} \tilde \Psi^{h+1}_{\alpha_{1-h}^{l}, i}\tilde \Psi^0_{\alpha_{l}^{m-h}, i}\\
     + \frac{1}{n} \sum_{i=1}^n\sum_{k=2}^{m-1}\sum_{l\in L_k^{m-1}} \tilde \Psi^{1}_{\alpha_{-h}^{l_1}, i} \cdots \tilde \Psi^0_{\alpha_{l_k}^{m-h}, i}
    % &\hspace{1cm} + \frac{1}{n} \sum_{i=1}^n\sum_{k=2}^{m-h-1}\frac{1}{(\tilde \Lambda_{i}^z)^{k+1} }\sum_{l\in L_k^{m-h-1}} \tilde \Psi^{h+1}_{\alpha_{l_1-h}^{l_1}, i} \tilde \Psi^0_{\alpha_{l_1}^{l_2}, i}\cdots \tilde \Psi^0_{\alpha_{l_k}^{m-h}, i}
  \end{align*} 
  The right hand term that raise concern is $\sum_{i=1}^n \tilde\Psi^{1}_{\alpha_{0}^{1}, i}\tilde \Psi^0_{\alpha_{1}^m, i}$. Since $\tilde \Psi^0_{\alpha_{1}^m, i} = \tilde \Psi^0_{i, \alpha_{1}^m}$ and $\tilde \Psi_2^1 = \tilde \Psi_2^2$, we can rewrite it $(\tilde \Psi_2^2 \tilde \Psi_m^0)_{\alpha}$ (where the right product of a matrix and a tensor is a classical matricial product on the first variable of the tensor). We can bound for any $\alpha \in [n]^2$:
  \begin{align*}
    \left\vert \tilde \Psi_\alpha^2 \right\vert
    \leq \frac{\|\Sigma_{\alpha_1}\|\|\Sigma_{\alpha_2}\|}{|z|^2},
  \end{align*}
  therefore, for $|z|$ sufficiently big, $(I_n - \tilde \Psi_2^2)$ is invertible and one has the identity:
  % When $(\Sigma_1,\ldots, \Sigma_m)$ is free one can invert $\tilde \Psi_2^2$ and obtain an expression of $\tilde \Psi_m^0$ depending only on computable terms:
  \begin{align}\label{eq:Psi_explicit}
    \tilde \Psi_m^0 
      &= (I_n - \tilde \Psi_2^{2})^{-1} \cdot \left(\tilde \Psi_\alpha^{1}
      +  \frac{1}{n} \sum_{i=1}^n\sum_{l=2}^{m-1} \tilde \Psi^{1}_{\alpha_0^{l}, i}\tilde \Psi^0_{\alpha_{l}^m, i}\right.\\
    &\hspace{3cm} \left.+ \frac{1}{n} \sum_{i=1}^n\sum_{k=2}^{m-1}\sum_{l\in L_k^{m-1}} \tilde \Psi^{1}_{\alpha_0^{l_1}, i} \tilde \Psi^0_{\alpha_{l_1}^{l_2}, i}\cdots \tilde \Psi^0_{\alpha_{l_k}^m, i} \right)_{(\alpha_0,\ldots, \alpha_{m-1}) \in [n]^m}.
   \end{align} 
   Complex analysis inferences should then allow us to set the uniqueness for all the values of $z$.
   % When the family $(\tilde \Sigma_1,\ldots, \tilde \Sigma_m)$ is not free, one can still extract a free family $(\tilde \Sigma_{i_1},\ldots, \tilde \Sigma_{i_k})$ such that there exists some coefficient $a_1^{(i_1)},\ldots, a_n^{(i_1)},a_1^{(i_2)},\ldots, a_n^{(i_k)}$ satisfying:
   % \begin{align*}
   %   \forall j \in [n], l\in[k]: \ \tr \left( \tilde \Sigma_{i_l}\tilde Q \tilde \Sigma_j \tilde Q\right) = \sum_{h=1}^k  a_j^{(i_h)}\tr \left( \tilde \Sigma_{i_l}\tilde Q \tilde \Sigma_{i_h} \tilde Q\right)
   % \end{align*}
   % Since $(\tilde \Psi^2_{i_l,i_h})_{1\leq l,h\leq k}$ is invertible, one can then express $(\tilde \Psi^0_{i_l,j_1,\ldots, j_{m-1}})_{\genfrac{}{}{0pt}{2}{l\in[k]}{1\leq j_1,\ldots, j_{m-1} \leq n}}$. Then one just has to multiply this matrix by $(a_{i}^{(i_l)})_{i\in[n], l\in[k]}$ on the left to obtain $\tilde \Psi^0_m$.

   % To recover $\tilde \Psi^0_m$ from $\tilde \Phi^0_m$, one just has to use the identity:
   % \begin{align*}
   %   \tilde \Psi^l_{\alpha} - \tilde \Phi^l_{\alpha}
   %   &=  -\frac{\Im(\tilde \Lambda_{\alpha_1}^z)}{|\tilde \Lambda_{\alpha_1}^z|^2}\frac{1}{n}\tr \left(  \Sigma_{\alpha_1}  \tilde Q  \tilde \Sigma_{\alpha_2}  \cdots \tilde \Sigma_{\alpha_l} \tilde Q \right)
   %   + \frac{1}{n} \tr \left( \bar{\tilde \Sigma}_{\alpha_1} \left( \tilde Q - \bar{\tilde Q} \right)  \cdots \tilde \Sigma_{\alpha_l} \tilde Q \right)\\
   %   &= -\frac{\Im(\tilde \Lambda_{\alpha_1}^z)}{\tilde \Lambda_{\alpha_1}^z} \tilde \Phi^l_{\alpha}
   %   +\frac{1}{n} \tr \left( \Sigma_{\alpha_1}  \tilde Q\left(\frac{1}{n} \sum_{i=1}^n \frac{\Im(\Lambda_i^z)}{|\Lambda_i^z|^2} \Sigma_i\right) \bar{\tilde Q}   \cdots \Sigma_{\alpha_l} \tilde Q \right)\\
   %   &= -\frac{\Im(\tilde \Lambda_{\alpha_1}^z)}{\tilde \Lambda_{\alpha_1}^z} \tilde \Phi^l_{\alpha}
   %   +\frac{1}{n^2} \sum_{i=1}^n \frac{\Im(\Lambda_i^z)}{\Lambda_i^z} \tilde \Phi^l_{i,\alpha_2,\ldots, \alpha_l, \alpha_1},
   % \end{align*}
   % and for any $(\alpha_1,\ldots, \alpha_m) \in [n]^m$ use the iteration formula:
   % \begin{align*}
   %   \tilde \Psi^h_m - \tilde \Phi^h_m  
   %   = \tilde \Psi_\alpha^{h+1} - \tilde \Phi_\alpha^{h+1} + \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^{m-1}\sum_{l\in L_k^{m-1}} \left( \tilde \Phi^{h+1}_{\alpha_{-h}^{l_1}, i} - \tilde \Psi^{h+1}_{\alpha_{-h}^{l_1}, i} \right) \tilde \Psi^h_{\alpha_{l_1}^{l_2}, i}\cdots \tilde \Psi^h_{\alpha_{l_k}^m, i}
   % \end{align*}
\end{proof}
Once $\tilde \Psi_m^h$ is defined for all $m\in \mathbb N$, $h\in[m]$, one can define iteratively for any sequence of deterministic matrices $A_{-h},\ldots, A_{m-1}$ followingly:
% \begin{align*}
%   \tilde \Psi_{A_{-h},\ldots, A_{m-1}}^h
%   =\tr \left(A_{-h}\tilde Q \cdots A_{-1} \tilde Q A_0 Q\ldots, A_{m-1}  \right)
% \end{align*}
\begin{align*}
  \left\{
    \begin{aligned}
    &\forall m >2, h \in \mathbb N, \forall A_{-h},\ldots, A_{m-1} \in \mathcal{M}_{p}^{m+h} :\\
    &\hspace{0.5cm} \ \tilde \Psi_{A_{-h},\ldots, A_{m-1}}^h - \tilde \Psi_{A_{-h},\ldots, A_{m-1}}^{h+1}\\
    &\hspace{1.5cm}= \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^{m-1}\sum_{l\in L_k^{m-1}} \tilde \Psi^{h+1}_{A_{-h},\ldots, A_{l_1 - 1},\Sigma_i} \tilde \Psi^0_{A_{l_1},\ldots, A_{l_2 - 1},\Sigma_i}\cdots \tilde \Psi^0_{A_{l_k},\ldots, A_{m - 1},\Sigma_i},\\
    & \forall l \in[n], A_1,\ldots, A_l \in \mathcal{M}_{p}^l: \ \tilde \Psi^{l-1}_{A_{-h},\ldots, A_{m - 1}} = \tilde \Psi^l_{A_{-h},\ldots, A_{m - 1}}  = \frac{1}{n} \tr \left( A_{1} \tilde Q  \cdots A_{l-1}\tilde QA_{l} \bar{\tilde Q} \right). 
    % & \forall l \in[n], \alpha \in [n]^l: \ \tilde \Phi^{l-1}_{\alpha} = \tilde \Phi^l_{\alpha}  = \frac{1}{n} \tr \left( \Sigma_{\alpha_1} \tilde Q  \cdots \Sigma_{\alpha_l} \tilde Q \right). 
    \end{aligned}\right.
  \end{align*}
One should need a proper proof to justify it, but we will just explain that the existence and uniqueness is proven iteratively considering sequences of matrices $(A_1,\ldots, A_i, \tilde \Sigma_{\alpha_{i+1}}, \ldots, \tilde \Sigma_{\alpha_m})$ with $(\alpha_{i+1}, \ldots, \alpha_m) \in [n]^{m-i}$ and $i$ going from $1$ to $m$.

We can finally properly estimate $Q^{\mathcal A_1^m}$. We express this result in the case $m$ constant, but one could probably get a similar result for an asymptotic $m$. The proof is just a laborious use of the explicit formulation \eqref{eq:Psi_explicit}.
\begin{proposition}\label{pro:estimation_finale_Qm}
  Given a constant integer $m \in \mathbb N$ and $m$ matrices $A_1,\ldots, A_m$ satisfying $\|A_i\|_F\leq 1$, we can estimate:
  \begin{align*}
    \tr(A_m Q^{A_1^m}) \ | \ \mathcal A_Q \in \tilde \Psi^0_{A_1,\ldots, A_m} \pm \mathcal E_2 \left( \frac{\kappa_z}{\sqrt n} \right).
  \end{align*}
\end{proposition}


  %  $b_i= \sum_{k=1}^{m-1} \sum_{l \in \mathcal L_k^{m-1}} b_i^{l}$ with:
  % \begin{align*}
  %   b_i^{l}
  %   % &=\mathbb{E}_{\mathcal A_Q}\left[u^T Q^{A^{l-1}}A_{l-1}\left(Q-Q_{-i}\right) Q_{-i}^{A^{m-1}}  A_{m-1} Qxx^T\tilde Qv\right] \\
  %   &=\frac{1}{n^k}\mathbb{E}_{\mathcal A_Q} \left[\frac{x_i^T\tilde Q AQ_{-i}^{A^{l_1}}x_ix_i^TQ_{-i}^{A^{l_2}_{l_1}}x_i\ldots x_i^T Q_{-i}^{A^{m}_{l_k}}x_i}{(\Lambda_i^z)^{k+1}}\right]
  % \end{align*}

%   Here we can apply Lemma~\ref{lem:borne_moment_produit_m_variables} bounding the variation of a product of random variables to the concentrations:
%   \begin{itemize}
%     \item $\frac 1 n x_i^TQ_{-i}^{A^{l_2}_{l_1}}x_i \in \frac{1} n \tr\left(\Sigma\mathbb{E}_{\mathcal A_Q} \left[ Q_{-i}^{A^{l_2}_{l_1}} \right]\right) \pm  \mathcal E_{\frac q 2}(\frac{(c\kappa_z)^{l_2-l_1}}{\sqrt n})$, $1\leq l_1 <l_2< m$ and $\left\vert \frac{1} n \tr\left(\Sigma\mathbb{E}_{\mathcal A_Q} \left[ Q_{-i}^{A^{l_2}_{l_1}} \right]\right) \right\vert \leq O \left( (c\kappa_z)^{l_2-l_1} \right)$
%     \item $\frac{1}{\Lambda^z_i} \in \frac{1}{\tilde \Lambda} \pm  \mathcal E_q(\frac{\check \kappa_z}{|z|\sqrt n})$ thanks to Corollary~\ref{cor:concentration_1_s_Lambda}
%   \end{itemize}
%   and to obtain thanks to Lemma~\ref{lem:borne_moment_produit_m_variables}:
%   \begin{align*}
%       &\mathbb{E}_{\mathcal A_Q}\left[\left\vert\frac{1}{n^k}\frac{x_i^TQ_{-i}^{A^{l_2}_{l_1}}x_i\ldots x_i^T Q_{-i}^{A^{m}_{l_k}}x_i}{\Lambda_i^z} - \frac{1}{n^k}\frac{\tr\left(\Sigma_i\mathbb{E}_{\mathcal A_Q} Q_{-i}^{A^{l_2}_{l_1}}\right)\ldots \tr\left(\Sigma_i\mathbb{E}_{\mathcal A_Q} Q_{-i}^{A^{m}_{l_k}}\right)}{\tilde \Lambda^z_i} \right\vert^2\right] \\
%       &\hspace{1cm}= O \left( \left( \frac{m^{k/2}(c'\kappa_z)^{m-l_1 + k} \check \kappa_z^k}{\sqrt n} |z|^k \right)^2 \right)
%       = O\left( \frac{(c\kappa_z)^{2(m-l_1) }}{n} \right),
%   \end{align*}
%   for some universal constants $c',c>1$.
%   %\cosme{J'abandonne le second terme, car je crois qu'on pourra suppooser que $k\leq m \leq n$, et donc je ne m'embÃªterai avec ces termes seulement si je suis sÃ»r qu'ils sont necessaires}
% % Then if we note $$\kappa_q(m,n) = \sup_{1\leq k \leq m}\frac{(2k)^{\frac {2k}{q}}}{n^\frac k 2}, $$ 
% Then we can show with H\"older inequality (and the concentration of $u^TQ_{-i}^{A^{l_1}}x_i$ and $x_i^T\tilde Q v$) that:
%   \begin{align*}
%       a_i^{l}=\frac{1}{n^k}\frac{\tr\left(\Sigma_i\mathbb{E}_{\mathcal A_Q} Q_{-i}^{A^{l_2}_{l_1}}\right)\ldots \tr\left(\Sigma_i\mathbb{E}_{\mathcal A_Q} Q_{-i}^{A^{m}_{l_k}}\right)}{\tilde \Lambda^z_i}\mathbb{E}_{\mathcal A_Q} \left[u^TQ_{-i}^{A^{l_1}}\Sigma_i\tilde Q v\right]  + O\left( \frac{(c\kappa_z)^{m }}{n} \right).
%     % &=\frac{1}{n}\mathbb{E}\left[\frac{u^T Q^{A^{l}}x_ix_i^T Q_{-i}^{A^{m}_q} x_ix_i^T \tilde Qv}{1+\frac{1}{n}x_i^T Q_{-i}x_i}\right]\\
%     % &=\frac{1}{n}\mathbb{E}\left[\frac{}{1+\delta}u^T Q^{A^{l}}x_ix_i^T Q_{-i}^{A^{m}_q} x_ix_i^T \tilde Qv\right]
%   \end{align*} 
%   % since $u^TQ_{-i}^{A^{l_1}}x_i \in O(c^{l_1}) \pm  \mathcal E_q(c^{l_1})$, $x_i^T\tilde Q v \in O(1) \pm  \mathcal E_q(1)$ (see Lemma~\ref{lem:concentration_uQx_uQ_-xx} and Lemma~\ref{lem:produit_et_somme_variables_exp_conc}).
%   Thus, taking the supremum on $u,v \in \mathbb R^p$ such that $\left\Vert u\right\Vert,\left\Vert v\right\Vert\leq 1$ we find the identity:
%   \begin{align*}
%     \mathbb{E}_{\mathcal A_Q}Q^{A_1^m}
%     &= \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^{m}  \frac{1}{ (n\tilde \Lambda_i^z)^k}  \! \! \sum_{l \in \mathcal L_k^{m}} \tr\left(\Sigma_i\mathbb{E}_{\mathcal A_Q} Q_{-i}^{A^{l_2}_{l_1}}\right)\ldots \tr\left(\Sigma_i\mathbb{E}_{\mathcal A_Q} Q_{-i}^{A^{m}_{l_k}}\right)\mathbb{E}_{\mathcal A_Q} \left[Q_{-i}^{A_1^{l_1}}\Sigma_i\tilde Q \right] \\
%     &\hspace{0.5cm}+ \mathbb{E}_{\mathcal A_Q}\left[Q^{A^{m-1}}A_{m-1}\tilde Q \right] + O_{\left\Vert \cdot\right\Vert}\left( \frac{(c\kappa_z)^{m }}{n} \right)
%   \end{align*}
%   In this formula, thanks to Corollary~\ref{cor:diff_Q^m_Q_-1^m}, it is possible to replace the terms $Q_{-i}^{A^l}$ for $1\leq l \leq m-1$ by $Q^{A^l}$.
%   For a given $l \in \mathcal L_k^j$, $j \geq k$, let us introduce the short notation 
%   \begin{align*}
%     T_{i,l}^j=\frac{1}{(n\tilde\Lambda_i^z)^k}\tr\left(\Sigma_i\mathbb{E}_{\mathcal A_Q} Q^{A^{l_2}_{l_1}}\right)\ldots \tr\left(\Sigma_i\mathbb{E}_{\mathcal A_Q} Q^{A^{j}_{l_k}}\right)&
%     &\text{and}&
%     &T_{()}^j=1,
%   \end{align*}
%   it is possible to modify the summation in the estimate of $\mathbb E Q^{A_1^m}$to get a simpler identity.
%   \begin{align*}
%     &\mathbb{E}_{\mathcal A_Q} \left[Q^{A_1^m} -Q^{A_1^{m-1}}A_{m-1}\tilde Q \right] \\
%     \hspace{0.5cm}&= \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^{m}   \sum_{l \in \mathcal L_k^m}   T_{i,l}^m\mathbb{E} \left[Q^{A_1^{l_1}}\Sigma_i\tilde Q \right] + O_{\left\Vert \cdot\right\Vert}(c^{m}\kappa_q(m,n))\\
%     \hspace{0.5cm}&= \frac{1}{n} \sum_{i=1}^n\sum_{k=1}^{m-1} \sum_{j=k+1}^{m}  \sum_{1\leq l_1<\ldots< l_{k-1}<j} \! \!  T_{i,l}^j\mathbb{E} \left[Q^{A^{l_1}}\Sigma_i\tilde Q \right]\frac{\tr\left(\Sigma_i\mathbb{E} Q^{A^{m}_{j}}\right)}{n\tilde \Lambda_i^z} + O_{\left\Vert \cdot\right\Vert}(c^{m}\kappa_q(m,n))\\
%     % &\hspace{1cm} - \frac{1}{n}\sum_{j=1}^{m-1} \frac{\mathbb{E}[Q^{A^{j}}\Sigma \tilde Q]}{\tilde \Lambda_i^z} \tr \left(\Sigma \mathbb E Q^{A_1^m_{j}}\right)+ O_{\left\Vert \cdot\right\Vert}\left(\frac{c^m}{\sqrt n}\right)\\
%     \hspace{0.5cm}&= \frac{1}{n} \sum_{i=1}^n\sum_{j=2}^{m} \left(\sum_{k=1}^{j-1}    \sum_{l\in \mathcal L_{k-1}^{j-1}} \! T_{i,l}^j\mathbb{E} \left[Q^{A^{l_1}}\Sigma\tilde Q \right] \right)\frac{\tr\left(\Sigma_i\mathbb{E} Q^{A^{m}_{j}}\right)}{n\tilde \Lambda_i^z} + O_{\left\Vert \cdot\right\Vert}(c^{m}\kappa_q(m,n))\\
%     \hspace{0.5cm}&= \frac{1}{n} \sum_{i=1}^n\sum_{j=2}^{m} \left(\mathbb{E}_{\mathcal A_Q} \left[Q^{A_1^{j-1}} -Q^{A^{j-2}}A_{j-2}\tilde Q \right] \right)\frac{\tr\left(\Sigma_i\mathbb{E} Q^{A^{m}_{j}}\right)}{n\tilde \Lambda_i^z} + O_{\left\Vert \cdot\right\Vert}(c^{m}\kappa_q(m,n))\\
%     % \hspace{0.5cm}&= \frac{1}{n} \sum_{i=1}^n\sum_{j=2}^{m} \left(\mathbb{E} Q^{A^j} - \mathbb{E}\left[Q^{A^{j-1}}A_{j-1}\tilde Q \right] +\frac{\mathbb{E}[Q^{A^{j}}\Sigma \tilde Q]}{\tilde \Lambda_i^z}\right)\frac{1}{n}\tr\left(\Sigma\mathbb{E} Q^{A^{m}_{j}}\right) + O_{\left\Vert \cdot\right\Vert}(c^{m}\kappa_q(m,n))\\
%     % \hspace{0.5cm}&= \sum_{j=1}^{m-1} \frac{1}{n}\tr\left(\Sigma\mathbb{E} Q^{A^{m}_{j}}\right)\left(z\mathbb{E} Q^{A^j} - \mathbb{E}\left[Q^{A^{j-1}}A_{j-1}\tilde Q \right] \right) + O_{\left\Vert \cdot\right\Vert}(c^{m}\kappa_q(m,n))
%     % &\underset{O\left(\frac{c^m}{\sqrt n}\right)}{\approx} \sum_{l=1}^{m-1}\left(\sum_{k=l}^{m-1}  \left(\frac{-1}{n} \right)^{k-1} \! \! \sum_{1\leq l_1<\ldots\leq l-1} \! \!  \frac{\tr\left(\Sigma\mathbb{E} Q^{A^{l_2}_{l_1}}\right)\ldots \tr\left(\Sigma\mathbb{E} Q^{A^{l}_{l_{k-1}}}\right)}{\tilde \Lambda_i^z}\mathbb{E} \left[Q^{A^{l_1}}\Sigma\tilde Q \right] \right)\frac{\tr\left(\Sigma\mathbb{E} Q^{A^{m}_{l}} }{n}
%   \end{align*}
%   (since $\tilde Q \Sigma = I_p - z \tilde Q$)
%   The issue is then that one of the term of the sum, $\frac{1}{n}\tr\left(\Sigma\mathbb{E} Q^{A^{m}_{j}}\right)$ depends on $\mathbb{E}Q^{A_1^m}$ when $j=1$, thus the formula is still not recursive nor explicit. The idea is to take advantage of the fact that $\left\Vert \frac{1}{n}\Sigma  \right\Vert_1 = \frac{\tr \Sigma}{n}\leq O(1)$ (see the discussion following Assumption~\ref{ass:classes}) which implies that one can compute with the upper formula $\frac{1}{n}\tr(\Sigma \mathbb{E}Q^{A_1^m})$ to obtain after a small reformulation, the identity:
%   \begin{align*}
%     &\frac{1}{n}\tr(\Sigma \mathbb{E}Q^{A_1^m}) 
%     =O_{\left\Vert \cdot\right\Vert}(c^{m}\kappa_q(m,n)) + \frac{1+\delta}{1+\delta- \frac{1}{n} \tr \Sigma \tilde Q \Sigma \tilde Q  }  \\
%     &\hspace{0.6cm} \times \frac{1}{n} \left(\tr\left(\Sigma\mathbb{E}\left[Q^{A^{m-1}} \right]A_{m-1}\tilde Q\right) 
%     +\sum_{j=2}^{m-1} \frac{1}{n}\tr\left(\Sigma\mathbb{E} Q^{A^{m}_{j}}\right)\tr\left(\Sigma\left(z\mathbb{E} Q^{A^j} - \mathbb{E}\left[Q^{A^{j-1}}A_{j-1}\tilde Q \right] \right)\right) \right)
%   \end{align*}
%   One can see here that $\frac{1}{n}\tr(\Sigma \mathbb{E}Q^{A_1^m})$ can be approximated with a quantity depending on elements of the form $\frac{1}{n}\tr(B \mathbb{E}Q^{A^l})$ for $1\leq l <m$ and $\Vert B \Vert \leq 1$. 



  % Therefore we can construct an estimator of $\mathbb E Q^{A_1^m}$ following the chain construction:
  % \begin{align*}
  %   \mathbb E Q^{A^1} \! \!\approx\tilde Q& 
  %   &\rightarrow&
  %   &\frac{\tr(\Sigma \mathbb E Q^{A^2})}{n} &
  %   &\rightarrow&
  %   &\! \! \mathbb E Q^{A^2}&
  %   &\! \! \! \rightarrow \ \ldots \ \rightarrow&
  %   &\! \! \frac{\tr(\Sigma \mathbb E Q^{A_1^m})}{n} &
  %   &\rightarrow&
  %   & \mathbb E Q^{A_1^m}&
  % \end{align*}  
  % The estimation error will be multiplied by $O(m)$ with each arrow which in total gives us for the estimation of $Q^{A_1^m}$ an error of order $O(\frac{c^m}{\sqrt n})$ with a new constant $c>1$.
  
  
% \subsection{Identities for $m=2$ and $m=3$}\label{sse:clt_uQa_cas_general}
% \color{red}
% Let us apply the formulas in the case $m=2$ ($A_0=0$). first we have (sans les $O(\cdot)$):
% \begin{align*}
%     &\frac1n\tr(\Sigma \mathbb E[QA_1Q]) = \frac{1}{n} \frac{1+\delta}{1+\delta- \frac{1}{n} \tr \Sigma \tilde Q \Sigma \tilde Q  } \tr(\Sigma \tilde QA_1\tilde Q)\\
%     & \mathbb E[QA_1Q] = \tilde QA_1\tilde Q +   \frac1n\tr(\Sigma \mathbb E[QA_1Q]) \frac{\tilde Q \Sigma\tilde Q }{1+\delta}
% \end{align*}
% With $m=3$ (we need the formulas of the case $m=2$):
% \begin{align*}
%     &\frac1n\tr(\Sigma \mathbb E[QA_1QA_2Q]) = \frac1n\frac{1+\delta}{1+\delta- \frac{1}{n} \tr \Sigma \tilde Q \Sigma \tilde Q } \\
%     &\hspace{1cm} \times\left(\tr(\Sigma \mathbb E[QA_1 Q]A_2\tilde Q) + \frac1n \tr( \Sigma \mathbb E[QA_2 Q])\left(z\tr(\Sigma \mathbb E[QA_1 Q])-\tr(\Sigma \tilde Q A_1\tilde Q)\right)\right) \\
%     & \mathbb E[QA_1QA_2Q] = \mathbb E[QA_1 Q]A_2\tilde Q + \frac1n \tr( \Sigma \mathbb E[QA_1QA_2Q])\frac{\mathbb E[\tilde Q\Sigma \tilde Q]}{1+\delta}\\
%     &\hspace{4.65cm} + \frac1n \tr( \Sigma \mathbb E[QA_2 Q])\left(z\tr(\Sigma \mathbb E[QA_1 Q])-\tr(\Sigma \tilde Q A_1\tilde Q)\right)
% \end{align*}
% \color{black}



































































\chapter{Concentration of the resolvent with random diagonal term}\label{cha:deterministic_equivalent_I_m_XDX}

We study here the concentration of a resolvent $Q =(I_p - \frac{1}{n}XDX^T)^{-1}$ with Assumptions~\ref{ass:n_p_commensurable}-\ref{ass:Sigma_borne_inferieurement} for $X$ and $D$ (in particular $D$ is random). Among other use, this object appears when studying robust regression \cite{ELK13, MAI19}. 
% Assuming $Y=X = (x_1,\ldots, x_n)$ and one tries 
In several settings, robust regression can be expressed by the following fixed point equation:
\begin{align}\label{eq:point_fixe_robust}
   \beta = \frac{1}{n} \sum_{i=1}^n f(x_i^T\beta)x_i, \ \ \beta \in \mathbb R^p,
 \end{align} 
where $\beta$ is the weight vector performing the regression (to classify data, for instance).
It was then shown in \cite{SED21} that the estimation of the expectation and covariance of $\beta$ (and therefore, of the performances of the algorithm) rely on an estimation of $Q$, with $D = \diag(f'(x_i^T\beta))$.
To obtain a sharp concentration on $Q$ (as it is done in Theorem~\ref{the:concentration_resolvent_XDX} below), one has to understand the dependence between $Q$ and $x_i$, for all $i\in[n]$. This is performed with the notation, given for any $M = (m_1,\ldots, m_n)\in \mathcal M_{p,n}$ or any $\Delta = \diag_{i\in[n]}(\Delta_i) \in \mathcal D_n$:
\begin{itemize}
  \item $M_{-i} = (m_1,\ldots, m_{i-1}, 0, m_{i+1},\ldots, m_n) \in \mathcal M_{p,n}$,
  \item $\Delta_{-i} = \diag  (\Delta_1,\ldots, \Delta_{i-1}, 0, \Delta_{i+1},\ldots, \Delta_n) \in \mathcal D_n$.
\end{itemize}
% The structure of the study of the resolvent is very similar to the one conducted in Section~\ref{sec:XDY} and we will try to draw the maximum of analogy between the two sections. The first theorem should for instance be compared to Proposition~\ref{pro:estimation_XDY} and Proposition~\ref{pro:concentration_lineaire_XDY}.
% Let us now formulate our theorem with those notations.
% Without entering too much into details we will focus on showing the following theorem:

\begin{theorem}\label{the:concentration_resolvent_XDX}
   Given a positive random diagonal matrix $D \in \mathcal D_n^+$ and a random matrix $X = (x_1,\ldots, x_n)$, in the regime\footnote{It is not necessary to assume that $p\leq O(n)$ but it simplifies the concentration result (if $p \gg n$, the concentration is not as good, but it can still be expressed).} $p\leq O(n)$ and under the assumptions:
   \begin{itemize}
     \item $(X,D) \propto \mathcal E_2$,
     \item all the columns $x_1,\ldots, x_n$ are independent,
     % \item all the couples $(x_i,y_i)$ are independent,
     \item $O(1) \leq \sup_{i\in[n]}\|\mathbb E[x_i] \|\leq O(1)$,
     \item for all $i \in[n]$, there exists a random positive diagonal matrix $D^{(i)} \in \mathcal D_n^+$, independent of $x_i$, such that $ \sup_{i\in[n]}\|D_{-i} - D_{-i}^{(i)}\|_F \leq O(1)$,
     \item there exist\footnote{The assumptions $\|X\|/\sqrt n$ bounded and $\kappa^2 \kappa_D\leq 1-\varepsilon$ might look a bit strong (since it is not true for matrices with i.i.d. Gaussian entries), it is indeed enough to assume that $\mathbb E[\|X\|] \leq O(\sqrt n)$ and introduce a parameter $z>0$ to study the behavior of $(zI_p - \frac{1}{n}XDX^T)^{-1}$ when $z$ is far from the spectrum of $\frac{1}{n}XDX^T$ -- as it is done in Section~\ref{sec:main_res_lipschitz}.
      % -- on the event $\{\|Y\|,\|X\| \leq \sqrt n  \kappa\}$ that has an overwhelming probability to happen since $\|X\| /\sqrt n\in \mathbb E[\|X\|]/\sqrt n \pm \mathcal E_2(1/\sqrt n)$ and the same holds for $Y$. 
      We however preferred here to make a relatively strong hypothesis not to have supplementary notations and proof precautions, that might have blurred the message.} three constants $\kappa,\kappa_D, \varepsilon>0$ ($\varepsilon \geq O(1)$ and $\kappa,\kappa_D\leq O(1)$), such that $\|X\| \leq \sqrt n\kappa$, $\|D^{(i)}\|,\|D\| \leq \kappa_D$ and $\kappa^2 \kappa_D\leq 1-\varepsilon$,
   \end{itemize}
   the resolvent $Q \equiv (I_p - \frac{1}{n}XDX^T)^{-1}$ follows the concentration
   \begin{align*}
     Q  \in \mathbb E[Q] \pm \mathcal E_{3/2} \left( \sqrt{\frac{\log n }{n}} \right)&
    &\text{in} \ (\mathcal M_{p}, \|\cdot \|_F).
   \end{align*}
\end{theorem}
Inspiring from the formulation of the deterministic equivalent introduced in Chapter~\ref{cha:resolvente_lipschtiz}, we introduce the following notation that will help us to express the deterministic equivalent of $ Q$. Given
  $\delta, D\in \mathcal M_n $, we note:
 \begin{align*}
   \tilde Q^\delta(D) \equiv \left( I_p - \frac{1}{n} \sum_{i=1}^n \mathbb E \left[ \frac{D_i}{1 + \delta D_i} \right] \Sigma_i \right)^{-1},
 \end{align*}
 (where we recall that $\forall i \in [n]$, $\Sigma_i \equiv \mathbb E[x_ix_i^T]$).

\begin{theorem}\label{the:estimation_resolvent_XDX}
  For any diagonal matrix $D' \in \mathcal{D}_{n}$, the fixed point equation:
  \begin{align*}
    \delta = \diag_{i\in [n]} \left( \Sigma_i \tilde Q^\delta(D') \right)
  \end{align*}
  admits a unique solution $\delta(D') \in \mathcal D_n$ and, under the hypotheses of Theorem~\ref{the:concentration_resolvent_XDX}, 
  % \begin{align*}
  %   \tilde Q \equiv \left( I_p - \frac{1}{n}X\tilde DY^T\right)^{-1}&
  %   &\text{for any} \ \tilde D \in \mathcal D_n \ \ \text{satisfying:}&
  %   &\left\Vert\tilde D -  \frac{1}{\mathbb E[\frac{1}{D}]} \right\Vert_F
  %   \leq O(1),
  % \end{align*}
  one can estimate:
  \begin{align*}
    \|\mathbb E[Q ]-\tilde Q^{\delta(D)}(D)\|_F \leq O(\sqrt{\log n}).
  \end{align*}
 \end{theorem}
 \begin{remark}\label{rem:convergence_OD_1}
    Note here that although there are no term $1/\sqrt n$ in the bound, this result still provides some good convergence bound for the estimation of linear forms like the Stieltjes transform or more generally any $\frac{1}{n}\tr(AQ)$ when $\|A\| \leq 1$ (because then $\frac{1}{n}\|A\|_F \leq O(1/\sqrt n)$).
 \end{remark}
 \begin{remark}\label{rem:event_AQ_not_needed}
   Unlike in the result of Chapter~\ref{cha:resolvente_lipschtiz} (for instance Theorem~\ref{the:concentration_resolvente_main_res}), there is no resort to the high probability event $\mathcal A_Q$ here. It is because, as we will see later in Lemma~\ref{lem:Q_borne}, in the current setting all the drawings of the resolvent $Q$ are bounded thanks to the hypothesis $\kappa^2 \kappa_D\leq 1-\varepsilon$. 
   In the sens, the parameter $z$ of Chapter~\ref{cha:resolvente_lipschtiz} is here always far from the spectrum of $\frac{1}{n}XX^T$.
   % One can see the current study as the preceding with a parameter $z \in \mathbb R$ and strictly lower than zero such that the distance from $z$ to the spectrum of $\frac{1}{n}XX^T$ is always positive.
 \end{remark}
 
 % Putting the two last theorem, one obtains:
 % \begin{corollary}\label{cor:concentration_resolvante_eq_det}
 %   Under the hypotheses of Theorem~\ref{the:concentration_resolvent_XDX}
 %   \begin{align*}
 %     Q  \in \mathcal E_1 \left(\log(n)\right) + \mathcal E_{1/2} \left(\frac{1}{\sqrt{n}}\right)  &
 %    &\text{in} \ (\mathcal M_{p}, \|\cdot \|).
 %   \end{align*}
 % \end{corollary}
 % \begin{remark}\label{rem:concentration_resolvent_calcul equivalent deterministe}
 %   Theorem~\ref{the:concentration_resolvent_XDX} simplifies greatly the study of the resolvent $Q= (I_p - \frac{1}{n}XDY^T)^{-1}$ because it states that it basically behaves like the random matrix $\tilde Q = (I_p - \frac{1}{n}X\tilde DY^T)^{-1}$ which was far more studied in the random matrix literature (see \cite{SIL95, PAJ09}, for instance). It can be shown indeed that under the hypotheses of Theorem~\ref{the:concentration_resolvent_XDX}:
 %   \begin{align*}
 %     \tilde Q \in \check Q_\delta \pm \mathcal E_2&
 %     &\text{in} \ \left(\mathcal M_{p,n}, \|\cdot \|_F\right),
 %   \end{align*} 
 %   where for all $\nu\in \mathbb R^n$, $\check Q_\nu \equiv \left(I_p - \frac{1}{n}\sum_{i=1}^n \frac{\tilde D_i \Sigma_i}{1 - \tilde D_i \nu_i}\right)^{-1}$ (when it is defined), $\forall i \in [n]$, $\Sigma_i \equiv \mathbb E[x_iy_i^T]$ and $\delta \in \mathbb R^n$ is the unique solution to:
 %   \begin{align*}
 %     \forall i \in [n]: \delta_i = \frac{1}{n} \tr \left(\Sigma_i \check Q_\delta\right).
 %   \end{align*}
 % \end{remark}
 % We leave the proof in Appendix~\ref{app:preuve_theorem_concentration_resolvante}.

 \begin{remark}\label{rem:D_m_D_(i)}
   Let us give two examples of the matrices $D^{(i)}$ that one could encounter in practice:
   \begin{itemize}
      \item For all $ i \in[n]$, $D_i =f(x_{i})$ for $f: \mathbb R^{p} \to \mathbb R$, bounded, then, $D_i$ just depends on $x_i$ so one can merely take $D^{(i)} = D_{-i}$ for all $i \in[n]$.
      \item For the robust regression described by Equation~\ref{eq:point_fixe_robust}, as in \cite{SED21}, we can assume for simplicity\footnote{The bound $\|f\|_\infty \leq O(1)$ is not necessary to set the concentration of $Q$, but it avoids a lot of complications.} $\|f\|_\infty,\|f'\|_\infty,\|f'{}'\|_\infty \leq O(1)$. If we choose $D = \diag(f'(x_i^T\beta))$, then it is convenient to assume $\frac{1}{n}\|f'\|_\infty \|X\|^2 \leq 1-\varepsilon $ (which implies in particular $\frac{1}{n}\|X\|^2\|D\| \leq 1-\varepsilon$) so that $\beta$ is well defined, being solution of a contractive fixed point equation. One can further introduce $\beta^{(i)} \in \mathbb R^p$, the unique solution to
      \begin{align*}
        \beta^{(i)} = \frac{1}{n}\sum_{\genfrac{}{}{0pt}{2}{1\leq j \leq n}{j \neq i}}f(x_j^T \beta^{(i)}) x_j.
      \end{align*}
      By construction, $\beta^{(i)}$ is independent of $x_i$ and so is:
      \begin{align*}
        D^{(i)}\equiv \diag \left(f'(x_1^T\beta^{(i)}), \ldots, f'(x_{i-1}^T\beta^{(i)}), 0, f'(x_{i+1}^T\beta^{(i)}), \ldots, f'(x_n^T\beta^{(i)}) \right).
      \end{align*}
      Besides $\|D_{-i}-D^{(i)}_{-i} \|_F \leq \|f'{}'\|_\infty \|X_{-i}^T(\beta - \beta^{(i)}) \|_F$. Now, the identities:
      \begin{align*}
        X_{-i}^T\beta = \frac{1}{n}X_{-i}^TXf(X^T\beta)&
        &\text{and}&
        &X_{-i}^T\beta^{(i)} = \frac{1}{n}X_{-i}^TX_{-i}f(X_{-i}^T\beta^{(i)})
      \end{align*}
      (where $f$ is applied entry-wise) imply:
      \begin{align*}
        \|X_{-i}^T(\beta - \beta^{(i)}) \|_F \leq \frac{1}{n} \|f'\|_\infty \|X_{-i}\|^2 \|X_{-i}^T(\beta - \beta^{(i)}) \|_F + \frac{1}{n}f(x_i^T\beta)X_{-i}^Tx_i.
      \end{align*}
      We can then deduce (since $\frac{1}{n} \|f'\|_\infty \|X_{-i}\|^2 \leq 1-\varepsilon$ by hypothesis):
      \begin{align*}
         \|D_{-i}-D^{(i)}_{-i} \|_F \leq \|f'{}'\|_\infty\|X_{-i}^T(\beta - \beta^{(i)}) \|_F \leq \frac{ \|f'{}'\|_\infty}{n\varepsilon}f(x_i^T\beta)X_{-i}^Tx_i \leq O(1).
      \end{align*}

    \end{itemize} 
 \end{remark}

 % The expression of the result of Theorem~\ref{the:concentration_resolvent_XDX} is very similar to Proposition~\ref{pro:estimation_XDY}, it is proven the same way, 
% {\color{red} ** Je prÃ©fÃ¨re dire les choses comme Ã§a (plutÃ´t que dire: c'est la fin du papier alors je balance la preuve ou sion allez vous coucher...): **}
 % The proof of Theorem~\ref{the:concentration_resolvent_XDX} follows the scheme of the proof of Proposition~\ref{pro:estimation_XDY} which employs Corollary~\ref{cor:borne_norme_d_XAY}, showing the concentration of $\|Y^TAX\|_d$ and requiring in particular:
 % \begin{enumerate}
 %    \item $\|x_i\|,\|y_i\|\leq O(1)$,
 %    \item if $\|A\|_*$ is not of order $O(1)$ then $\|x_iy_i^T\|_F\leq O(1)$.
 % \end{enumerate}
 % The preliminary lemmas to the proof of Theorem~\ref{the:concentration_resolvent_XDX} are here to prove a similar result to Corollary~\ref{cor:borne_norme_d_XAY}, namely the concentration of $\|X^TQAQX\|_d$, given in Lemma~\ref{lem:concentration_norme_d_XQAQY}. 
 % To this end, we fist bound $\|\mathbb E[Qx_i]\|$ and $\|\mathbb E[Q^Ty_i]\|$ from the bound given on $\|\mathbb E[x_i]\|$ and $\|\mathbb E[y_i]\|$ in Appendix~\ref{app:borne_Qx_i_Qy_i}. 
 % The proof of Theorem~\ref{the:concentration_resolvent_XDX} requires a finer approach presented in Appendix~\ref{app:estimation_resolvent}.
 % To treat the case where $\|A\|_* \gg O(1)$, we show that, when $\|x_iy_i^T\|_F \leq O(1)$, then $\|\mathbb E[Qx_iy_i^T Q]\|_F \leq O(1)$ directly in Lemma~\ref{lem:concentration_norme_d_XQAQY}, in Appendix~\ref{app:preuve_concentration_y_iQAQx_i}. 
 % We then have all the elements to prove Theorem~\ref{the:concentration_resolvent_XDX} in Appendix~\ref{app:preuve_concentration_lineaire_Q}.
 %\begin{enumerate}
 %    \item  
 %    \item f we do not have the hypothesis 
 %    \item We show the concentration of the random variables $y_i^TQAQx_i$ in Appendix~\ref{app:preuve_concentration_y_iQAQx_i} with a similar property than Proposition~\ref{pro:concentration_lineaire_YAX} setting the concentration of $x_i^TAy_i$.
 %\end{enumerate}.
 %an interesting application of the concentration of measure framework developed in the previous sections, and deserves as such to be delineated here.
 
 \medskip
\section{Concentration of Q}\label{app:concentration_lipschitz_Q}
 \begin{lemma}\label{lem:Q_borne}
   Under the assumptions of Theorem~\ref{the:concentration_resolvent_XDX}, $\|Q\| \leq \frac{1}{\varepsilon} \leq O(1)$.
 \end{lemma} 
 Then we can show a Lipschitz concentration of $Q$ but with looser observable diameter that the one given by Theorem~\ref{the:concentration_resolvent_XDX} (as for $XDX^T$, we get better concentration speed in the linear concentration framework).
 \begin{lemma}\label{lem:concentration_faible_resolvante}
   Under the hypotheses of Theorem~\ref{the:concentration_resolvent_XDX}: 
   \begin{align*}
      \left(Q, \frac{1}{\sqrt n} QX\right) \propto \mathcal E_2 \quad \text{in} \ \ (\mathcal M_{p,n}, \| \cdot \|_F).
    \end{align*} 
 \end{lemma}
   \begin{proof}
   Let us just show the concentration of the resolvent, the tuple is treated the same way. If we note $\phi(X,D) = Q$ and we introduce $X' \in \mathcal M_{p,n}$ and $D' \in \mathcal D_n$, satisfying $\|X'\|\leq \kappa \sqrt n$ and $\|D'\| \leq \kappa_D$ as $X,D$, we can bound:
   \begin{align*}
     &\left\Vert \phi(X,D) - \phi(X',D)\right\Vert_F\\
     &\hspace{0.5cm}= \frac{1}{n}\left\Vert \phi(X,D) (X-X') DX^T \phi(X',D)\right\Vert_F + \frac{1}{n}\left\Vert \phi(X,D) X' D(X- X')^T \phi(X',D)\right\Vert_F \\
     &\hspace{0.5cm}\leq \frac{2\kappa\kappa_D}{\varepsilon^2\sqrt n} \left\Vert X- X'\right\Vert_F,
   \end{align*}
   thanks to the hypotheses and Lemma~\ref{lem:Q_borne} given above. The same way, we can bound:
   \begin{align*}
     \left\Vert \phi(X,D) - \phi(X,D')\right\Vert_F\leq \frac{\kappa^2}{\varepsilon^2} \left\Vert D- D'\right\Vert_F
   \end{align*}
   % \begin{itemize}
   %   \item $ \left\Vert \phi(X,D) - \phi(X,D')\right\Vert_F\leq \frac{\kappa^2}{\varepsilon^2} \left\Vert D- D'\right\Vert_F,$
   %   % \item $ \left\Vert \phi(X,D) - \phi(X,D')\right\Vert_F\leq \frac{\kappa_D\kappa}{\varepsilon^2\sqrt n} \left\Vert Y- Y'\right\Vert_F.$
   % \end{itemize}
   Therefore, as a $O(1)$-Lipschitz transformation of $(X,D)$, $Q \propto \mathcal E_2$.
   \end{proof}
% Before proving Theorem~\ref{the:concentration_resolvent_XDX}, let us give some preliminary lemmas. The first one is given without proof:
%  \begin{lemma}\label{lem:Q_borne}
%    Under the assumptions of Theorem~\ref{the:concentration_resolvent_XDX}, $\|Q\| \leq \frac{1}{\varepsilon} \leq O(1)$.
%  \end{lemma}
 % A central step of the proof of Theorem~\ref{the:concentration_resolvent_XDX}  provided in~Appendix~\ref{app:proof_the:concentration_resolvent} is to bound $\|Qx_i\|_\infty$ that happens to control the variation of $Q$ relatively to $X,D$ and $Y$. With a naive approach one can just set that $Qx_i \propto \mathcal E_2(\sqrt n)$ as it is explained in Remark~\ref{lem:concentration_faible_resolvante}. 
 \section{Control on the dependency on $x_i$}\label{app:borne_Qx_i_Qy_i}
   
 The dependence between $Q$ and $x_i$ prevent us from bounding straightforwardly $\|Qx_i\|$ with Lemma~\ref{lem:Q_borne} and the hypotheses on $x_i$. We can still disentangle this dependence thanks to the notations: 
 \begin{align*}
   Q_{-i} = \left(I_p - \frac{1}{n}X_{-i}^TDX_{-i}^T\right)^{-1}&
   &\text{and}&
   &Q^{(i)}_{-i} = \left(I_p - \frac{1}{n}X_{-i}^TD^{(i)}X_{-i}^T\right)^{-1}.
 \end{align*}
 We can indeed bound:
 \begin{align}\label{eq:borne_Q_m_i_(i)_x_i}
   \|\mathbb E[Q_{-i}^{(i)}x_i]\| \leq \|\mathbb E[Q_{-i}^{(i)}]\mathbb E[x_i]\| \leq O(1),
 \end{align}
 and we even have interesting concentration properties that will be important later: 
 \begin{lemma}\label{lem:concentration_Q_m_i_x_i}
   Under the assumptions of Theorem~\ref{the:concentration_resolvent_XDX}:
   \begin{align*}
      Q^{(i)}_{-i}x_i, \
      % Q^{(i)}_{-i}x_i; \quad  y_i^TQ^{(i)}_{-i}; \quad \frac{1}{\sqrt n}X_{-i}^TQ^{(i)}_{-i}x_i; \quad \frac{1}{\sqrt n}y_i^TQ^{(i)}_{-i}X_{-i} \quad\in \mathcal E_2
      \frac{1}{\sqrt n}X_{-i}^TQ^{(i)}_{-i}x_i \in O(1) \pm \mathcal E_2.
      % &\text{and}&
      % &\frac{1}{n}y_i^T  Q^{(i)}_{-i} x_i \in O \left(1 \right) \pm \mathcal E_2 \left(\frac{1}{\sqrt n} \right) + \mathcal E_1 \left(\frac{1}{n}\right).
    \end{align*} 
 \end{lemma}
 % The proof is left in~Appendix~\ref{app:proof_lem:concentration_Q_m_i_x_i}.
 \begin{proof}
   Considering $u\in \mathbb R^p$, deterministic such that $\|u\|\leq 1$, we can bound thanks to the independence between $Q^{(i)}_{-i}$ and $x_i$:
   \begin{align*}
     \left\vert u^TQ^{(i)}_{-i}x_i - \mathbb E[u^TQ^{(i)}_{-i}x_i]\right\vert \leq \left\vert u^TQ^{(i)}_{-i} \left(x_i - \mathbb E[x_i]\right)\right\vert + \left\vert u^T \left(Q^{(i)}_{-i}- \mathbb E[Q^{(i)}_{-i}]\right) \mathbb E[x_i] \right\vert .
   \end{align*}
   Therefore, the concentrations $x_i\propto \mathcal E_2$ and $Q^{(i)}_{-i}\propto \mathcal E_2$ given in Lemma~\ref{lem:concentration_faible_resolvante} imply that there exist two constants $C,c>0$ such that $\forall t>0$ such that if we note $\mathcal A_{-i}$, the sigma algebra generated by $X_{-i}$ (it is independent with $x_i$):
   \begin{align*}
     &\mathbb P \left(\left\vert u^TQ^{(i)}_{-i}x_i - \mathbb E[u^TQ^{(i)}_{-i}x_i]\right\vert \geq t\right) \\
     &\hspace{0.5cm}\leq \mathbb E \left[\mathbb P \left( \left\vert u^TQ^{(i)}_{-i} \left(x_i - \mathbb E[x_i]\right)\right\vert \geq \frac{t}{2} \ | \ \mathcal A_{-i}\right) \right]
     + \mathbb P \left(\left\vert u^T \left(Q^{(i)}_{-i}- \mathbb E \left[Q^{(i)}_{-i}\right]\right) \mathbb E[x_i] \right\vert \geq \frac{t}{2}\right)\\
     &\hspace{0.5cm}\leq \mathbb E \left[Ce^{(t/c\|Q^{(i)}_{-i}\|)^2} \right] + Ce^{(t/c\|\mathbb E[x_i]\|)^2} \leq C' e^{-t^2/c'},
   \end{align*}
   for some constants $C',c' >0$, thanks to the bounds $\|\mathbb E[x_i]\|\leq O(1)$ given in the assumptions and $\|Q^{(i)}_{-i}\| \leq O(1)$ given by Lemma~\ref{lem:Q_borne}.% then allows us to conclude on the linear concentration of $Q_{-i}^{(i)}x_i$.

   The linear concentration of $X_{-i}^TQ_{-i}^{(i)}x_i/\sqrt n$ is proven the same way since one can show as in Lemma~\ref{lem:concentration_faible_resolvante} that $(X,D) \mapsto X_{-i}^TQ_{-i}^{(i)}/\sqrt n$ is $O(1)$-Lipschitz on $\{\|X\|\leq \kappa\sqrt n, \|D\|\leq \kappa_D\}$, and therefore, $X_{-i}^TQ_{-i}^{(i)}/\sqrt n \propto \mathcal E_2$. 

   % The concentration of $\frac{1}{n}y_i^T  Q^{(i)}_{-i} x_i$ is also shown the same way with Proposition~\ref{pro:concentration_lineaire_YAX}, noticing that $\frac{1}{n}\|Q^{(i)}_{-i}\|_F \leq O(1/\sqrt n)$ and $\frac{1}{n}\|\mathbb E[x_iy_i^T]\|_F \leq O(1/\sqrt n)$ (thanks to Lemma~\ref{lem:Q_borne} and Remark~\ref{rem:E_x_i_y_i_F_borne}).
 \end{proof}
 % The link between $Qx_i$ and $Q_{-i}x_i$ is made possible thanks to classical Schur identities:
 Let us adapt the Schur identity to the presence of the diagonal matrix $D_i$:
\begin{align*}%\label{eq:lien_q_qj_schur_D}
  % &Q=Q_{-i} +\frac{1}{n}(1+ \frac1nx_i^TQx_i)Q_{-i}x_ix_i^TQ_{-i}&
  % &\text{and}&
  % &Qx_i=(1+ \frac1nx_i^TQx_i)Q_{-i}x_i,
  &Q=Q_{-i} -\frac{1}{n}\frac{D_iQ_{-i}x_ix_i^TQ_{-i}}{1 + D_i \Delta_i}&
  &\text{and}&
  &Qx_i=\frac{Q_{-i}x_i}{1+ D_i \Delta_i},
\end{align*}
where we noted $\Delta_i \equiv \frac1nx_i^TQ_{-i}x_i$.
 The link between $Q_{-i}x_i$ and $Q_{-i}^{(i)}x_i$ is made thanks to:
 \begin{lemma}\label{lem:norme_Q_m_i_Q_(i)_x_i} 
   Under the hypotheses of Theorem~\ref{the:concentration_resolvent_XDX}, for all $i\in[n]$: 
   \begin{align*}
     \|Q_{-i}x_i - Q^{(i)}_{-i}x_i\| \in O(\sqrt{\log n}) \pm \mathcal E_2(\sqrt{\log n}).
   \end{align*}
 \end{lemma}
 Let us first prove a Lemma of independent interest:
 \begin{lemma}\label{lem:concentration_norm_infty_YQx}
 Under the hypotheses of Theorem~\ref{the:concentration_resolvent_XDX}, for all $i\in[n]$
 \begin{align*}
   \left\Vert \frac{1}{\sqrt n} X_{-i}^T Q_{-i}^{(i)} x_i \right\Vert_\infty
   \in O(\sqrt {\log n}) \pm \mathcal E_2(\sqrt {\log n}).
 \end{align*}
   
 \end{lemma}
 \begin{proof}
   The control on the variation is given by Lemma~\ref{lem:concentration_Q_m_i_x_i} ($\|\cdot\|_\infty \leq \|\cdot \|_F)$ and the bound on the expectation is a consequence of Proposition~\ref{pro:tao_conc_exp} and the bound:
\begin{align}
  \frac{1}{\sqrt n} \left\Vert \mathbb E \left[ X_{-i}^T Q_{-i}^{(i)} x_i \right]\right\Vert_\infty \leq \frac{1}{\sqrt n} \left\Vert \mathbb E \left[ X_{-i}^T Q_{-i}^{(i)} \right]  \mathbb E \left[  x_i \right]\right\Vert \leq O(1).
\end{align}
 \end{proof}
 \begin{proof}[Proof of Lemma~\ref{lem:norme_Q_m_i_Q_(i)_x_i}]
 Let us bound directly:
   \begin{align*}
  % &\left\Vert \frac{1}{n}  Q_{-i} X_{-i} (D_{-i}^{(i)} - D_{-i})  X_{-i}^T Q_{-i}^{(i)} x_i \right\Vert_\infty\\
    \left\Vert \left(Q_{-i} - Q_{-i}^{(i)}\right) x_i\right\Vert
    &\leq  \left\Vert \frac{1}{n}  Q_{-i} X_{-i} (D_{-i}^{(i)} - D_{-i})  X_{-i}^T Q_{-i}^{(i)} x_i \right\Vert\\
    &\leq \frac{1}{n} \| Q_{-i} X_{-i}\| \|D_{-i}^{(i)} - D_{-i}\|_F \|  X_{-i}^T Q_{-i}^{(i)} x_i \|_\infty 
    \ \leq O \left(\frac{1}{\sqrt n} \|  X_{-i}^T Q_{-i}^{(i)} x_i \|_\infty \right).
\end{align*}
We can then conclude thanks to Lemma~\ref{lem:concentration_norm_infty_YQx}.
% therefore, $\|QX\|_\infty \leq O( \sup_{i\in [n]} \|  Q_{-i}^{(i)} x_i \|_\infty + \frac{1}{\sqrt n} \|  X_{-i}^T Q_{-i}^{(i)} x_i \|_\infty)$.
% Introducing, as in Section~\ref{sec:concentration_norm}, $(e_1,\ldots,e_p)$ and $(f_1,\ldots,f_n)$, respectively, the canonical basis of $\mathbb R^p$ and $\mathbb R^n$ we know from Lemma~\ref{lem:concentration_Q_m_i_x_i} that for all $k\in [p]$ and $i,j \in [n]$:
% \begin{align*}
%     e_k^TQ_{-i}^{(i)} x_i \in O(1) \pm \mathcal E_2&
%     &\text{and}&
%     &\frac{1}{\sqrt n}f_j^TX_{-i}^T Q_{-i}^{(i)} x_i \in O(1) \pm  \mathcal E_2
%  \end{align*}
%  since $|\mathbb E[e_k^TQ_{-i}^{(i)} x_i]| \leq\|\mathbb E[Q_{-i}^{(i)}]\|\|\mathbb E[x_i]\|\leq O(1)$ and similarly, $|\mathbb E[f_j^TX_{-i}^T Q_{-i}^{(i)} x_i]/ \sqrt n| \leq O(1)$ by hypothesis, thanks to the independence between $x_i$ and $Q_{-i}^{(i)}$ and between $x_i$ and $X_{-i}^T Q_{-i}^{(i)}$.
% Following the arguments displayed in Section~\ref{sec:concentration_norm}, there exist four constants $K,C,c,c'$ (all $\leq  O(1)$) such that we can bound:
% \begin{align*}
%   \mathbb P(\|QX\|_\infty \geq t)
%   &\leq \mathbb P \left( \sup_{\genfrac{}{}{0pt}{2}{i,j\in [n]}{k \in [p]}} e_k^TQ_{-i}^{(i)} x_i + \frac{1}{\sqrt n}f_j^T X_{-i}^T Q_{-i}^{(i)} x_i \geq \frac{t}{K}\right) \\
%   & \leq \max \left(1,n^2p C e^{-t^2/c} \right)
%   \ \ \leq  \max(e,C) e^{-K^2t^2/c'\log(n^2p)}
% \end{align*}
 \end{proof}
 % We can then deduce Lemma~\ref{lem:concentration_norme_infinie_Qx} from Lemma~\ref{lem:concentration_Q_m_i_x_i} and 
 
% Here, the bound  is crucial.
 % we provide, as a first step, the following concentrations 
 % (proven in~Appendix~\ref{app:proof_lem:concentration_Q_m_i_x_i}):
%  We can then bound $\|Qx_i\|$ and $\|Q^Tx_i\|$ combining Lemmas~\ref{lem:concentration_Q_m_i_x_i} and~\ref{lem:norme_Q_m_i_Q_(i)_x_i} with \eqref{eq:borne_Q_m_i_(i)_x_i}.
%  \begin{lemma}\label{lem:borne_norme_Qx_i}
%    Under the hypotheses of Theorem~\ref{the:concentration_resolvent_XDX} we have the concentration:
%    % \begin{align*}
%    %   \|\mathbb E[Qx_i]\|\leq O(\sqrt{\log n})&
%    %   &\text{and}&
%    %   &\|\mathbb E[Qx_i]\|\leq O(\sqrt{\log n}).
%    % \end{align*}
%    \begin{align*}
%      \|Qx_i \in O(\sqrt{\log n}) \pm \mathcal E_2(\sqrt {\frac{\log n}{n} })&
%      &\text{and}&
%      &\|Qx_i \in O(\sqrt{\log n}) \pm \mathcal E_2(\sqrt {\frac{\log n}{n} }).
%    \end{align*}
%    % If we assume in addition that $\| \mathbb E[x_ix_i^T]\|_F \leq O(1)$, then $\|\mathbb E[Qx_ix_i^TQ]\|\leq O(\log n)$.
%  \end{lemma}
%  \begin{proof}
%    % Let us bound with 
%    The Schur identities~\eqref{eq:lien_q_qj_schur} allow us to write:
%    \begin{align*}
%      \mathbb E[Qx_i] =  \mathbb E \left[ \delta_i  Q_{-i} x_i \right]&
%      &\text{where} \ \ \delta_i \equiv 1+\frac{1}{n} D_i  x_i^T  Q_{-i} x_i. %\leq \varepsilon \sup_{i\in[n]} \left\Vert x_i^T Q_{-i}\right\Vert_\infty,
%     % \Psi(X,D) = \sup_{\genfrac{}{}{0pt}{2}{i\in[n]}{j\in[p]}} x_i^T Qe_j
%   \end{align*}
% %   Let us first give a concentration inequality on:
% %   \begin{align*}
% %   \frac{1}{n} D_i  x_i^T  Q_{-i} x_i = \frac{1}{n} D_i  x_i^T  Q^{(i)}_{-i} x_i + \frac{1}{n} D_i  x_i^T  (Q_{-i}- Q_{-i}^{(i)}) x_i.
% % \end{align*} 
% % we know that $D_i \in O(1) \pm \mathcal E_2(1)$, from Lemma~\ref{lem:concentration_Q_m_i_x_i} that $\frac{1}{n}x_i^T  Q^{(i)}_{-i} x_i \in O(1) \pm \mathcal E_2(\frac{1}{\sqrt n}) \pm \mathcal E_1(\frac{1}{ n})$ and from Lemma~\ref{lem:norme_Q_m_i_Q_(i)_x_i} that $\|(Q_{-i}- Q_{-i}^{(i)}) x_i\| \in O(\sqrt{\log n} ) \pm \mathcal E_2 (\sqrt{\log n} )$, therefore thanks to the bounds $|D_i| \leq O(1)$ and $\|x_i\|\leq O(1)$:
% % \begin{align*}
% %   \delta_i \in O(1) \pm \mathcal E_1 \left(\frac{1}{\sqrt n}\right)
% % \end{align*}
% %   Introducing the matrix $ P \equiv \left(I_n - \frac{1}{n} Y^T  X D \right)^{-1} \in \mathcal M_{n}$, 
% % % \begin{align*}%\label{eq:definition_Q_check}
% % %    Q \equiv \left(\frac{1}{n}X^TX + I_n\right)^{-1} \in \mathcal M_{n},
% % % \end{align*}
% %  we have the identities:
% % \begin{align}\label{eq:lien_Q_Q_check}
% %    Y^T  Q =  P  Y^T &
% %   &\text{and}&
% %   & P - \frac{1}{n} P  Y^T   XD=  I_n
% % \end{align}
% % from which we can deduce with the Schur identities~\eqref{eq:lien_q_qj_schur} that $|1 +\frac{1}{n} D_i  x_i^T  Q_{-i} x_i| = | P_{i,i}| \leq \frac{1}{\varepsilon}$ ($\| P\| \leq \frac{1}{\varepsilon}$ like $\|Q\|$) and $| P_{i,i}| \in O(1) \pm \mathcal E_2$. 
% For any deterministic $u \in \mathbb R^p$ such that $\|u\| \leq 1$, we can bound:% thanks to Lemma~\ref{lem:norme_Q_m_i_Q_(i)_x_i}:
% \begin{align*}
%   \left\vert u^T\mathbb E[Qx_i]\right\vert 
%   &\leq \left\vert \mathbb E \left[ \delta_i u^TQ^{(i)}_{-i}x_i \right]  + \mathbb E \left[\delta_i u^T \left(Q_{-i} - Q^{(i)}_{-i} \right)x_i \right] \right\vert\\
%   &\leq O \left(\mathbb E \left[ | u^TQ^{(i)}_{-i}x_i | \right]  + \mathbb E \left[ \left\Vert \left(Q_{-i} - Q^{(i)}_{-i} \right)x_i \right\Vert \right] \right)
% \end{align*}
% (since $|\delta_i| \leq \frac{\kappa^2 \kappa_D}{\varepsilon}$). We can then conclude that $\|\mathbb E[Qx_i]\| \leq \sup_{\|u \|\leq 1} |u^T\mathbb E[Qx_i]| \leq O(\sqrt{\log n})$ thanks to Lemma~\ref{lem:norme_Q_m_i_Q_(i)_x_i} and the concentration $u^TQ^{(i)}_{-i}x_i\in O(1) \pm \mathcal E_2$. 
% % But we know that $u^TQ^{(i)}_{-i}x_i\in O(1) \pm \mathcal E_2$, $ \left(Q_{-i} - Q^{(i)}_{-i} \right)x_i \in O(\sqrt{\log(n)}) \pm \mathcal E_2(\sqrt{\log(n)})$, we can bound:
% % \begin{align*}
% %   \|\mathbb E[Qx_i]\| \leq \sup_{\|u \|\leq 1} |u^T\mathbb E[Qx_i]| \leq O(\sqrt{\log n})
% % \end{align*}
% The same holds for $ \|\mathbb E[Qx_i]\|$.
% \end{proof}

% \section{Concentration of $QX$, $X^TQ$ and $X^TQAQX$}
\section{Proof of the concentration}\label{app:preuve_concentration_x_iQAQx_i}

Let us first provide a preliminary result that will allow us to set that $x_i^TQAQx_i$ behaves more or less like a $O(\sqrt{\log n})$-Lipschitz observation of $(X,D,Y)$.

\begin{lemma}\label{lem:concentration_norme_infinie_Qx}
  Under the hypotheses of Theorem~\ref{the:concentration_resolvent_XDX}, $\forall i \in[n]$, and for any deterministic matrices $U,V \in \mathcal M_{p}$ such that $\|U\|,\|V\|\leq 1$:
  \begin{align*}
    \|  VQ  X\|_\infty
    % \|  UQ  Y\|_\infty)
    % ,\frac{1}{\sqrt n} \| Y^T Q  x_i\|_\infty
    \in O \left(\sqrt{\log n}\right) \pm  \mathcal E_2 \left(\sqrt{\log n}\right).
  \end{align*}
\end{lemma}
Be careful that the bound would not have been so tight for $\|  Q  XU\|_\infty$ given $U,V \in \mathcal M_{n}$. 
We just need a small lemma to be able to bound $1 + \Delta_i D_i$ from below, it is basically a rewriting of Lemma~\ref{lem:Borne_Lambda} bounding $\Lambda$ in Chapter~\ref{cha:resolvente_lipschtiz}.
\begin{lemma}\label{lem:borne_1_D_Delta}
  Under the hypotheses of Theorem~\ref{the:concentration_resolvent_XDX}, $\forall i \in[n]$:
  \begin{align*}
   |\Delta_i| \leq \frac{\kappa^2}{\varepsilon}&
   &\text{and}&
   &\varepsilon \leq 1 + D_i \Delta_i \leq 1+ \frac{\kappa \kappa_D}{\epsilon}
  \end{align*}
\end{lemma}
\begin{proof}
  Let us simply bound for any $i\in [n]$: $\|\Delta_i\| = \frac{1}{n} |x_i^T Qx_i | \leq \frac{\kappa^2}{\varepsilon} $ thanks to Lemma~\ref{lem:Q_borne}. We can then directly deduce the upper bound of $|1 +  D_i \Delta_i|$.
  
  For the lower bound, let us introduce again the matrix $\check Q = (I_n - D^{1/2}X^TXD^{1/2})^{-1}$, we can bound as in Lemma~\ref{lem:Q_borne} $\|\check Q\| \leq \frac{1}{\varepsilon}$, and we can show again that:
  \begin{align*}
    1 +  D_i \Delta_i = 1 +  \frac{D_i}{n} x_i^T Qx_i = \frac{1}{\check Q_i},
  \end{align*}
  which allows us to bound $|1 +  D_i \Delta_i| \geq \frac{1}{\|\check Q\|} \geq \varepsilon$.
\end{proof}

% \begin{proof}[Proof of Lemma~\ref{lem:concentration_norme_infinie_Qx}]
 \begin{proof}
    Following the same identities and arguments presented in the proof of Lemma~\ref{lem:norme_Q_m_i_Q_(i)_x_i}, we can bound thanks to Lemma~\ref{lem:borne_1_D_Delta}
  \begin{align*}
    \| V Q  X\|_\infty
    = \sup_{i\in[n]} \left\Vert  \frac{VQ_{-i}^{(i)} x_i + \frac{1}{n}  V(Q_{-i} - Q_{-i}^{(i)}) x_i}{1+ D_i\Delta_i}\right\Vert_\infty\\
    \leq  O \left( \sup_{i\in[n]} \left(\|VQ_{-i}^{(i)} x_i\|_\infty, \frac{1}{\sqrt n} \|  X_{-i}^T Q_{-i}^{(i)} x_i \|_\infty\right) \right).
   %\leq \varepsilon \sup_{i\in[n]} \left\Vert x_i^T Q_{-i}\right\Vert_\infty,
    % \Psi(X,D) = \sup_{\genfrac{}{}{0pt}{2}{i\in[n]}{j\in[p]}} x_i^T Qe_j
  \end{align*}
%   Introducing the matrix $ P \equiv \left(I_n - \frac{1}{n} Y^T  X D \right)^{-1} \in \mathcal M_{n}$, 
% % \begin{align*}%\label{eq:definition_Q_check}
% %    Q \equiv \left(\frac{1}{n}X^TX + I_n\right)^{-1} \in \mathcal M_{n},
% % \end{align*}
%  we have the identities:
% \begin{align}\label{eq:lien_Q_Q_check}
%    Y^T  Q =  P  Y^T &
%   &\text{and}&
%   & P - \frac{1}{n} P  Y^T   XD=  I_n
% \end{align}
% from which we can deduce with the Schur identities~\eqref{eq:lien_q_qj_schur} that $|1 +\frac{1}{n} D_i  x_i^T  Q_{-i} x_i| = | P_{i,i}| \leq \frac{1}{\varepsilon}$ ($\| P\| \leq \frac{1}{\varepsilon}$ like $\|Q\|$).
% Starting with the identity $ Q_{-i} x_i  =  Q_{-i}^{(i)} x_i + \frac{1}{n}  Q_{-i} X_{-i} (D_{-i}^{(i)} - D_{-i})  X_{-i}^T Q_{-i}^{(i)} x_i$, we want to bound:
% \begin{align*}
%   &\left\Vert \frac{1}{n}  Q_{-i} X_{-i} (D_{-i}^{(i)} - D_{-i})  X_{-i}^T Q_{-i}^{(i)} x_i \right\Vert_\infty\\
%     &\hspace{1cm}\leq  \left\Vert \frac{1}{n}  Q_{-i} X_{-i} (D_{-i}^{(i)} - D_{-i})  X_{-i}^T Q_{-i}^{(i)} x_i \right\Vert\\
%     &\hspace{1cm}\leq \frac{1}{n} \| Q_{-i} X_{-i}\| \|D_{-i}^{(i)} - D_{-i}\|_F \|  X_{-i}^T Q_{-i}^{(i)} x_i \|_\infty 
%     \ \leq O \left(\frac{1}{\sqrt n} \|  X_{-i}^T Q_{-i}^{(i)} x_i \|_\infty \right)
% \end{align*}
% therefore, $\|QX\|_\infty \leq O( \sup_{i\in [n]} \|  Q_{-i}^{(i)} x_i \|_\infty + \frac{1}{\sqrt n} \|  X_{-i}^T Q_{-i}^{(i)} x_i \|_\infty)$.
%  we get eventually $\Psi( X,D) \leq O(\sup_{i\in [n]}\psi_i( X,D))$, where:
% \begin{align*}
%   \psi_i( X,D) \equiv \|  Q_{-i}^{(i)} x_i \|_\infty + \frac{1}{\sqrt n} \|  X_{-i}^T Q_{-i}^{(i)} x_i \|_\infty.
%   % \psi_i( X,D) \equiv \|  Q_{-i}^{(i)} x_i \|_\infty + \frac{1}{\sqrt n} \|  X_{-i}^T Q_{-i}^{(i)} x_i \|_\infty \in \mathcal E_2(\sqrt{\log(n)})
% \end{align*}
Introducing, as in Section~\ref{sec:concentration_norm}, $(e_1,\ldots,e_p)$ and $(f_1,\ldots,f_n)$, respectively, the canonical basis of $\mathbb R^p$ and $\mathbb R^n$ we know from Lemma~\ref{lem:concentration_Q_m_i_x_i} that for all $k\in [p]$ and $i,j \in [n]$:
\begin{align*}
    e_k^TVQ_{-i}^{(i)} x_i \in O(1) \pm \mathcal E_2&
    &\text{and}&
    &\frac{1}{\sqrt n}f_j^TX_{-i}^T Q_{-i}^{(i)} x_i \in O(1) \pm  \mathcal E_2,
 \end{align*}
 since $|\mathbb E[e_k^TVQ_{-i}^{(i)} x_i]| \leq\|\mathbb E[Q_{-i}^{(i)}]\|\|\mathbb E[x_i]\|\leq O(1)$ and similarly, $|\mathbb E[f_j^TX_{-i}^T Q_{-i}^{(i)} x_i]/ \sqrt n| \leq O(1)$. % by hypothesis, thanks to the independence between $x_i$ and $Q_{-i}^{(i)}$ and between $x_i$ and $X_{-i}^T Q_{-i}^{(i)}$.
%  besides:
% \begin{align*}
%   \|\mathbb E[ Q_{-i}^{(i)} x_i] \|_\infty \leq \|\mathbb E[ Q_{-i}^{(i)} x_i] \| \leq O(1)&
%   &\text{and}&
%   &\left\Vert \mathbb E \left[\frac{1}{\sqrt n}  X_{-i}^T Q_{-i}^{(i)} x_i\right]\right\Vert_\infty \leq O(1).
% \end{align*}
% Therefore, Proposition~\ref{pro:tao_conc_exp} allows us to conclude that $\|Q_{-i}^{(i)} x_i\|_\infty +\|  X_{-i}^T Q_{-i}^{(i)} x_i /\sqrt n \|_\infty \in O(\sqrt{\log n}) \pm  \mathcal E_2(\sqrt{\log n})$ which allows us to conclude on the concentration of $\leq \sup_{i\in[n]}$
Following the arguments displayed in Section~\ref{sec:concentration_norm}, there exist four constants $K,C,c,c'$ (all $\leq  O(1)$) such that we can bound:
\begin{align*}
  \mathbb P(\|VQX\|_\infty \geq t)
  % &\leq \mathbb P(\sup_{i\in [n]}\|Qx_i\|_\infty \geq t)\\
  &\leq \mathbb P \left( \sup_{\genfrac{}{}{0pt}{2}{i,j\in [n]}{k \in [p]}} e_k^TVQ_{-i}^{(i)} x_i + \frac{1}{\sqrt n}f_j^T X_{-i}^T Q_{-i}^{(i)} x_i \geq \frac{t}{K}\right) \\
  & \leq \max \left(1,n^2p C e^{-t^2/c} \right)
  \ \ \leq  \max(e,C) e^{-K^2t^2/c'\log(n^2p)}.
  % \in O \left(\sqrt{\log n}\right) \pm  \mathcal E_2 \left(\sqrt{\log n}\right),
\end{align*}
We can then deduce the concentration of $\|VQX\|_\infty$ since $\log(n^2p) \leq O(\log(n))$.
 \end{proof}
% We can then obtain with the same inequalities as the one given in the proof of 
Let us now prove three results of progressive difficulty.
Since $Q \propto \mathcal E_2$ and $x_i \propto \mathcal E_2$, one can follow the lines of Lemma~\ref{lem:concentration xQx} to set:
\begin{lemma}\label{lem:COncentration_xQy}
   Under the hypotheses of Theorem~\ref{the:concentration_resolvent_XDX}:
   \begin{align*}
     \Delta_i \equiv \frac{1}{n}x_i^TQ_{-i}x_i  \in \bar \Delta_i   \pm 
     % \mathcal E_2 \left(\sqrt{\frac{1}{n}}\right) + 
     \mathcal E_2 \left(\sqrt{\frac{1}{n}}\right) + \mathcal E_1 \left(\sqrt{\frac{1}{n}}\right),
   \end{align*}
   where we noted $\bar \Delta_i \equiv \mathbb E[\frac{1}{n}x_i^TQ_{-i}x_i]$ (recall that $\forall i\in[n]: \ |\bar \Delta_i| \leq \frac{\kappa^2}{\varepsilon}$.
    % In addition, $\sup_{i\in[n]}|\bar \Delta_i| \leq O  \left(\sqrt{\frac{\log n}{n}}\right)$
 \end{lemma}
 We let the reader refer to the proof of Lemma~\ref{lem:concentration xQx} or more simply to next result to get justifications for this lemma.
 % \begin{proof}
 % Let us follow the lines of the proof of Lemma~\ref{}
 %   We know from Lemma~\ref{lem:concentration_Q_m_i_x_i}, the bound \eqref{eq:borne_Q_m_i_(i)_x_i} and the concentration of the product of random vectors that:
 %   \begin{align*}
 %    \frac{1}{n}x_i^TQ_{-i} ^{(i)}x_i  \in O \left( 1 \right) \pm \mathcal E_1 \left(\frac{1}{\sqrt{n}}\right),
 %   \end{align*}
 %   one can then conclude with Lemma~\ref{lem:norme_Q_m_i_Q_(i)_x_i}.
 % \end{proof}
\begin{lemma}\label{lem:concentration_xiQAQyi}
Under the hypotheses of Theorem~\ref{the:concentration_resolvent_XDX}, given a deterministic matrix $A \in \mathcal M_{p,n}$:
  \begin{align*}
     x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i  \in O(\sqrt n \|A\|_F) \pm \mathcal E_2(\|A\|_F) + \mathcal E_1(\|A\|).
  \end{align*}
\end{lemma}
\begin{proof}
  Let us bound:
  \begin{align*}
    &\left\vert x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i - \mathbb E \left[ x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i \right] \right\vert\\
    &\hspace{0.5cm} \leq \left\vert x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i -  \tr \left( \Sigma_i Q_{-i}^{(i)}AQ_{-i}^{(i)} \right) \right\vert +\left\vert \tr \left( \Sigma_i Q_{-i}^{(i)}AQ_{-i}^{(i)} \right) - \tr \left( \Sigma_i \mathbb E \left[Q_{-i}^{(i)}AQ_{-i}^{(i)}\right] \right)  \right\vert
  \end{align*}
  One can then deduce the result from Lemma~\ref{lem:bounded_linear_concentration} (setting that if $Z \in O(\sigmaÂ° \pm \mathcal E_q(\sigma)$ and $0 \leq Y \leq Z$, then $Y \in O(\sigma) \pm \mathcal E_q(\sigma)$) applied to the concentrations:
  % Now we know that there exists two constants $C,c>0$ such that:
  \begin{itemize}
    \item $ x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i \ | \ \mathcal A_{-i} \in  \tr \left( \Sigma_i Q_{-i}^{(i)}AQ_{-i}^{(i)} \right) \pm \mathcal E_2(\|A\|_F/\varepsilon^2) + \mathcal E_1(\|A\|/\varepsilon^2)$ thanks to Hanson-Wright inequality (Proposition~\ref{pro:concentration_lineaire_YAX}),
    \item $|\tr \left( \Sigma_i Q_{-i}^{(i)}AQ_{-i}^{(i)} \right)|$ is a $(\frac{1}{\varepsilon}\|\Sigma_i\|\|A\|_F)$-Lipschitz transformation of $Q_{-i}^{(i)}$, and therefore, one can deduce from Lemma~\ref{lem:concentration_faible_resolvante} that $ \tr \left( \Sigma_i Q_{-i}^{(i)}AQ_{-i}^{(i)} \right) \in  \tr \left( \Sigma_i \mathbb E \left[Q_{-i}^{(i)}AQ_{-i}^{(i)}\right] \right) \pm \mathcal E_2(\|A\|_F)$. 
    % \item $\mathbb P \left( \left\vert x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i -  \tr \left( \Sigma_i Q_{-i}^{(i)}AQ_{-i}^{(i)} \right) \right\vert \geq t \right) \leq C e^{-c(\varepsilon^2t/\|A\|_F)^2} + $
  \end{itemize}
  Besides, one can bound:
  \begin{align*}
    \left\vert \mathbb E \left[ x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i \right] \right\vert = \left\vert \tr \left(  \Sigma_i \mathbb E \left[ Q_{-i}^{(i)}AQ_{-i}^{(i)}  \right] \right) \right\vert \leq O(\sqrt p \|A\|_F).
  \end{align*}
\end{proof}
\begin{lemma}\label{lem:concentration_norme_d_XQAQY}
   Under the hypotheses of Theorem~\ref{the:concentration_resolvent_XDX}, given a deterministic matrix $A \in \mathcal M_{p,n}$ such that $\|A\|_F\leq 1$:
   \begin{align*}
     \frac{1}{n}\|X^TQAQX\|_d \in O \left( \frac{1}{\sqrt n} \right) \pm \mathcal E_1 \left(\sqrt{\frac{\log n}{n}}\right).
   \end{align*}
   % If we assume in addition\footnote{Note that for $\|A\|_F \leq 1$, one already has $\mathbb E[\frac{1}{n}\|X^TQAQX\|_d] \leq \mathbb E[\frac{1}{n}\|Y\|\|A\|_F\|X\|\|Q^2\|] \leq O(1)$.} that $\|A\|_*\leq 1$, then $\mathbb E[\frac{1}{n}\|X^TQAQX\|_d]\leq O(\log n/\sqrt n)$.
   % If we assume in addition that $\|A\|_*\leq 1$ or $\| \mathbb E[x_ix_i^T]\|_F \leq O(1)$, then $\mathbb E[\frac{1}{n}\|X^TQAQX\|_d]\leq O(\log n/\sqrt n)$.
\end{lemma}
This Lemma in particular gives us the concentration of any diagonal term of the random matrix $\frac{1}{n}X^TQAQX$, i.e. of any $\frac{1}{n}x_i^TQAQx_i$, $i\in [n]$.
\begin{proof}
To prove the concentration, let us introduce again the decomposition $A = U^T\Lambda V$, with $U,V \in \mathcal O_p$ and $\Lambda \in \mathcal D_p$. We are going to bound the variation of $\frac{1}{n}\|X^TQAQX\|_d$ towards the variations of $\frac{1}{\sqrt n}VQX \propto \mathcal E_2$ (see Lemma~\ref{lem:concentration_faible_resolvante}). 
Let us define the mapping $\phi : \mathcal M_{p,n}^2\to \mathbb R$ satisfying for all $M,P \in \mathcal M_{p,n}$, $\phi(M,P) = \|M^T\Lambda P\|_d$ (with that definition, $\frac{1}{n}\|X^TQAQX\|_d = \phi(\frac{1}{\sqrt n}VQX, \frac{1}{\sqrt n}UQX)$).
Given $4$ variables $M,P,M',P'$ satisfying $\|M\|,\|P\|,\|M'\|,\|P'\| \leq \frac{\kappa}{\varepsilon}$ we can bound as in the proof of Corollary~\ref{cor:borne_norme_d_XAY}:
\begin{align*}
  % \frac{1}{n}\|X^TQAQX\|_d
  \left\vert \phi(M,P) - \phi(M',P)\right\vert \leq \|(M-M')^T\Lambda P\|_d \leq 
  % \left\{\begin{aligned}
    \|M-M'\|_F \|P\|_\infty \|\Lambda\|_F
    \leq \|M-M'\|_F \|P\|_\infty,
    % \frac{1}{\sqrt n\varepsilon^2}\|M-M'\|_F \|P\|_\infty,
  % \end{aligned}\right.
\end{align*}
and the same way, $\left\vert \phi(M,P) - \phi(M,P')\right\vert \leq \|P-P'\|_F \|M\|_\infty$. 
% and the same way, $\left\vert \phi(M,P) - \phi(M,P')\right\vert \leq \frac{1}{\sqrt n\varepsilon^2}\|P-P'\|_F \|M\|_\infty$. 
We further invoke Lemma~\ref{lem:concentration_norme_infinie_Qx} that provides the concentration:
    \begin{align}\label{eq:bound_UQX_infty}
       \left( \frac{1}{\sqrt n}\|  VQ  X\|_\infty, \frac{1}{\sqrt n}
    \|  UQ  X\|_\infty \right)
    % ,\frac{1}{\sqrt n} \| Y^T Q  x_i\|_\infty
    \in O \left(\sqrt{\frac{\log n}{n}}\right) \pm  \mathcal E_2 \left(\sqrt{\frac{\log n}{n}}\right).
     \end{align} 
     We can then deduce from Theorem~\ref{off:plus_de_norme_2} the concentration $\sqrt{\frac{ n}{\log n}} \phi(\frac{1}{\sqrt n}VQX, \frac{1}{\sqrt n}UQX) \propto \mathcal E_2 + \mathcal E_1 \propto \mathcal E_1$, from which we deduce the concentration of $\|X^TQAQX\|_d$.

For the estimation, let us first express:
\begin{align*}
  x_i^TQAQx_i
  = x_i^TQ_{-i}AQ_{-i}x_i(1 + D_i \Delta_i)
\end{align*}

Thanks to Lemmas~\ref{lem:COncentration_xQAQyd},~\ref{lem:concentration_xiQAQyi} and the assumptions on the concentration of $D_i$, one can bound:
\begin{align*}
  \left\Vert x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i(1 + D_i \Delta_i) \right\Vert \leq O(\sqrt n).
\end{align*}
% When $\|A\|_* \leq 1$, we can simply bound, as it was done in the proof og Lemma~\ref{lem:concentration_norme_infinie_Qx}, for any $i \in [n]$:
% for any $x_i,x_i \in$:
To be able to replace $Q_{-i}^{(i)}$ with $Q_{-i}$ in the previous inequality, one can bound:
\begin{align*}
  &\left\vert x_i^TQAQx_i
  - \left( 1 + (1 + D_i \Delta_i) \right)\left(  x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i \right) \right\vert\\
  &\hspace{1cm}\leq \left( 1 + \frac{\kappa_D\kappa^2}{\varepsilon} \right)\left( \left\vert x_i^T \left( Q_{-i} - Q_{-i}^{(i)} \right)A \left( Q_{-i} - Q_{-i}^{(i)} \right)x_i \right\vert + \left\vert x_i^T \left( Q_{-i} - Q_{-i}^{(i)} \right)AQ_{-i}^{(i)}x_i \right\vert \right.\\
  &\hspace{4.5cm} \left. + \left\vert x_i^TQ_{-i}^{(i)} A  \left( Q_{-i} - Q_{-i}^{(i)} \right)x_i \right\vert  \right)
  % &\leq |1 + D_i \Delta_i| (\|(Q_{-i} - Q_{-i}^{(i)})x_i\| \|x_i^TQ_{-i}^{(i)} A\|
  % \frac{1}{n}\|X^TQAQX\|_d \leq \frac{1}{\sqrt n} \|QY\|_\infty\|QY\|_\infty \|A\|_*,
\end{align*}
We can then invoke the concentrations:
\begin{itemize}
  \item $\|x_i^TQ_{-i}^{(i)} A\|, \|AQ_{-i}^{(i)} x_i\| \in O(1) \pm \mathcal E_2$ thanks to Lemmas~\ref{lem:concentration_Q_m_i_x_i} and~\ref{lem:borne_Ax}.
  \item $\|(Q_{-i} - Q_{-i}^{(i)})x_i\|, \|x_i(Q_{-i} - Q_{-i}^{(i)})\| \in O(\sqrt {\log n}) \pm \mathcal E_2(\sqrt {\log n})$ thanks to Lemma~\ref{lem:norme_Q_m_i_Q_(i)_x_i}
  \item $\left\vert x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i \right\vert \in O(\sqrt n) \pm \mathcal E_1 $ thanks to Lemma~\ref{lem:concentration_xiQAQyi}.
\end{itemize}
to be able to finally bound $\mathbb E[\frac{1}{n}\|X^TQAQX\|_d] \leq O(\sqrt n)$ thanks to \eqref{eq:bound_UQX_infty} (with $U=V=I_p$).
  % Introducing again the decomposition $A = U^t\Lambda V$, with $U,V \in \mathcal O_p$ and $\Lambda \in \mathcal D_p$,
% To bound the expectation of $\|X^TQAQX\|_d$, recall from the proof of Corollary~\ref{cor:borne_norme_d_XAY}, that we just need to show that for all $i\in [n]$:
% \begin{align}\label{eq:concentration_x_iQAQx_i}
%   x_i^T QAQx_i \in O \left(\log n\right) \pm \mathcal E_1\left(\log n \right).
%   % \frac{1}{n} x_i^T QAQx_i \in O \left(\frac{\log n}{ n} \right) \pm \left(\frac{\log n}{ n} \right) .
%  \end{align}
%  % for some constant $q>0$. 
%  Since the projection on any of the diagonal elements of a matrix is a $1$-Lipschitz mapping for the semi-norm $\|\cdot\|_d$, we already know that $x_i^T QAQx_i \propto  \mathcal E_1\left(\sqrt{\log n }\right)$, we are thus left to bound $\left\vert \mathbb E[x_i^T QAQx_i]\right\vert$, for all $i\in[n]$.
%  Let us decompose with the same calculus as in the proof of Lemma~\ref{lem:borne_norme_Qx_i}:
%  \begin{align*}
%    x_i^TQAQx_i 
%   % &=  \mathbb E \left[\delta_i^2\tr \left(AQ_{-i}^{(i)}x_ix_i^TQ_{-i}^{(i)}\right) +   \delta_i^2\tr \left(A(Q_{-i}-Q_{-i}^{(i)})x_ix_i^T(Q_{-i}-Q_{-i}^{(i)})\right) \right.\\
%   % &\hspace{0.5cm}\left.+  \delta_i^2\tr \left(AQ_{-i}^{(i)}x_ix_i^T(Q_{-i}-Q_{-i}^{(i)})\right) +  \delta_i^2\tr \left(A(Q_{-i}-Q_{-i}^{(i)})x_ix_i^TQ_{-i}^{(i)}\right) \right]
%   &=  \delta_i^2x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i +   \delta_i^2 x_i^T(Q_{-i}-Q_{-i}^{(i)})A(Q_{-i}-Q_{-i}^{(i)})x_i \\
%   &\hspace{0.5cm}+  \delta_i^2x_i^T(Q_{-i}-Q_{-i}^{(i)})AQ_{-i}^{(i)}x_i +  \delta_i^2x_i^TQ_{-i}^{(i)}A(Q_{-i}-Q_{-i}^{(i)})x_i .
%  \end{align*}
%  We already know that (assuming only $\|A\|_F\leq 1)$:
%  \begin{itemize}
%   \item $|\delta_i | \leq O(1)$ and $x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i \propto \mathcal E_1(\sqrt{\log n})$,
%   % \item ,
%   % \item  with similar arguments as in the proof of Lemma~\ref{lem:concentration_Q_m_i_x_i}, $x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i \propto \mathcal E_2 + \mathcal E_1$ because $\|Q_{-i}^{(i)}AQ_{-i}^{(i)}\|_F \leq O(1)$ and $\|\mathbb E[x_ix_i^T]\|_F \leq O(1)$ 
%   \item $\left\vert x_i^T(Q_{-i}-Q_{-i}^{(i)})A(Q_{-i}-Q_{-i}^{(i)})x_i\right\vert \leq \|(Q_{-i}-Q_{-i}^{(i)})x_i\|\|(Q_{-i}-Q_{-i}^{(i)})x_i\| \in O(\log n) \pm \mathcal E_1(\log n)$ thanks to Lemma~\ref{lem:norme_Q_m_i_Q_(i)_x_i} and because $\|A\|\leq \|A\|_F \leq 1$,
%   \item  we can bound: $|x_i^T(Q_{-i}-Q_{-i}^{(i)})AQ_{-i}^{(i)}x_i| \leq  \|VQ_{-i}^{(i)}x_i\|_\infty \|\Lambda\|_F \|U (Q_{-i}-Q_{-i}^{(i)}) x_i \|\in O(\log n) \pm \mathcal E_1(\log n)$, thanks to Lemma~\ref{lem:norme_Q_m_i_Q_(i)_x_i} and the concentration $\|VQ_{-i}^{(i)}x_i\|_\infty \in O(\sqrt {\log n}) + \mathcal E_2(\sqrt {\log n})$ given by Lemma~\ref{lem:concentration_norme_infinie_Qx}.
%   % (see Proposition~\ref{pro:tao_conc_exp} and Lemma~\ref{lem:concentration_Q_m_i_x_i}).
% \end{itemize}
% In addition, noting $\Sigma \equiv \mathbb E[x_ix_i^T]$, we already know from Proposition~\ref{pro:carcaterisation_vecteur_linearirement_concentre_avec_moments} and the hypotheses on $(x_i,x_i)$ that $\|\Sigma\|\leq 1$ and:
% \begin{itemize}
%   \item if $\|A\|_* \leq 1$, $\left\vert \mathbb E[x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i]\right\vert \leq \frac{\|\Sigma\|}{\varepsilon^2} \|A\|_* \leq O(1)$,
%   \item if $\|\Sigma\|_F \leq 1$, $\left\vert \mathbb E[x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i]\right\vert \leq \frac{\|\Sigma\|_F}{\varepsilon^2} \|A\|_F \leq O(1)$.
% \end{itemize}
% Therefore, in all cases, H\"older inequalities allow us to show that $\mathbb E[|x_i^TQAQx_i|] \leq O(\log n)$ and \eqref{eq:concentration_x_iQAQx_i} is true, we can then conclude as in the proof of Corollary~\ref{cor:borne_norme_d_XAY} that $\frac{1}{n}\mathbb E[\|X^TQAQX\|_d] \leq O(\log n/\sqrt n)$.
% Let us now show with similar arguments as in the proof of Lemma~\ref{lem:concentration_Q_m_i_x_i} that:
% \begin{align*}
%    x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i \in O(\log n) \pm  \mathcal E_1(\log n).
%  \end{align*}
%  We already know that 
%  % Noting $\Sigma \equiv \mathbb E[x_ix_i^T]$, we already know that:
%  % \begin{align*}
%  %   \mathbb P \left(\left\vert x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i - \tr \left(\Sigma Q_{-i}^{(i)}AQ_{-i}^{(i)}\right)\right\vert\geq t\right) \leq \mathbb E[C e^{-t/c\|Q_{-i}^{(i)}AQ_{-i}^{(i)}\|_F}] \leq C e^{-t/c'},
%  % \end{align*}
%  % for some constants $C,c,c'>0$.
%  % Besides,
%  % \begin{align*}
%  %   \left\vert \tr \left(\Sigma Q_{-i}^{(i)}AQ_{-i}^{(i)}\right)\right\vert
%  %   \leq \frac{\|\Sigma\|\|A\|_F}{\varepsilon}\|Q_{-i}^{(i)}\|_F \leq O(\|Q_{-i}^{(i)}\|_F),
%  %   % \leq \frac{\|\Sigma\|}{\varepsilon}\|Q_{-i}^{(i)}\| \leq O(\|Q_{-i}^{(i)}\|_F),
%  % \end{align*}
%  % since $\|\Sigma\|\leq O(1)$ thanks to Proposition~\ref{pro:carcaterisation_vecteur_linearirement_concentre_avec_moments}. Therefore $\tr \left(\Sigma Q_{-i}^{(i)}AQ_{-i}^{(i)}\right) \propto \mathcal E_2$ as a $O(1)$-Lipschitz observation of the concentrated random matrix $Q_{-i}^{(i)} \propto \mathcal E_2$. Putting the two concentration together, we obtain as expected $x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i \propto \mathcal E_2 + \mathcal E_1$

%  Assuming first that $\|A\|_* \leq 1$, we can also bound:
%  % \begin{align*}
%  %   \mathbb P \left(\left\vert \tr \left(\Sigma Q_{-i}^{(i)}AQ_{-i}^{(i)}\right) - \tr \left(\Sigma \mathbb E[Q_{-i}^{(i)}AQ_{-i}^{(i)}]\right)\right\vert\geq t\right)
%  % \end{align*}


%   because $\|Q_{-i}^{(i)}AQ_{-i}^{(i)}\|_F \leq O(1)$ and $\|\mathbb E[x_ix_i^T]\|_F \leq O(1)$


%  Now, if we assume that $\| \mathbb[x_ix_i^T]\|_F \leq O(1)$,
% % to be able to bound $\|\mathbb E[Qx_ix_i^TQ]\|_F$, 
% we start with the identity:
% \begin{align*}
%   \tr \left(A\mathbb E[Qx_ix_i^TQ]\right) 
%   % &=  \mathbb E \left[\delta_i^2\tr \left(AQ_{-i}^{(i)}x_ix_i^TQ_{-i}^{(i)}\right) +   \delta_i^2\tr \left(A(Q_{-i}-Q_{-i}^{(i)})x_ix_i^T(Q_{-i}-Q_{-i}^{(i)})\right) \right.\\
%   % &\hspace{0.5cm}\left.+  \delta_i^2\tr \left(AQ_{-i}^{(i)}x_ix_i^T(Q_{-i}-Q_{-i}^{(i)})\right) +  \delta_i^2\tr \left(A(Q_{-i}-Q_{-i}^{(i)})x_ix_i^TQ_{-i}^{(i)}\right) \right]
%   &=  \mathbb E \left[\delta_i^2x_i^TQ_{-i}^{(i)}AQ_{-i}^{(i)}x_i +   \delta_i^2 x_i^T(Q_{-i}-Q_{-i}^{(i)})A(Q_{-i}-Q_{-i}^{(i)})x_i \right.\\
%   &\hspace{0.5cm}\left.+  \delta_i^2x_i^T(Q_{-i}-Q_{-i}^{(i)})AQ_{-i}^{(i)}x_i +  \delta_i^2x_i^TQ_{-i}^{(i)}A(Q_{-i}-Q_{-i}^{(i)})x_i \right]
%   % &\leq \|\mathbb E[Q_{-i}^{(i)}]\|^2 \|\mathbb E[x_ix_i^T]\|_F
% \end{align*}
% Note that $|d_i|\leq O(1)$ and besides:

% Therefore, we can eventually bound 
% \begin{align*}
%   \left\Vert \mathbb E[Qx_ix_i^TQ]\right\Vert_F \leq O \left(\log n\right).
% \end{align*}

 % $\leq O(\log n)$.
 \end{proof}

 % \section{Proof of Theorem~\ref{the:concentration_resolvent_XDX}}\label{app:preuve_concentration_lineaire_Q}
\begin{proof}[Proof of Theorem~\ref{the:concentration_resolvent_XDX}]
   % \begin{proof}[Proof of Theorem~\ref{the:concentration_resolvent_XDX}]
  % To employ Theorem~\ref{the:Concentration_produit_de_vecteurs_d_algebre_optimise} (or, more precisely, Theorem~\ref{off:plus_de_norme_2}), let us bound the variations of $Q = Q(X,D,Y)$ when $X,D,Y$ variate. In the beginning of the proof we consider $X,D,Y$ to be constant, and we further introduce $X',Y' \in \mathcal M_{p,n}$ and $D' \in \mathcal D_n$. 
  % Let us first bound:
  
  % Considering a matrix $A \in \mathcal M_{p}$, such that $\|A\|_F \leq 1$
  % To show the concentration of $Q$, we 
  Let us consider $A\in \mathcal{M}_{p,n}$ such that $\|A\|_F\leq 1$ and let us note $\phi(X,D)  = \tr(A Q)$. We abusively work with $X,D$ and independent copies $X',D'$  satisfying $\|X\|,\|X'\| \leq \sqrt n \kappa$ and $\|D\|,\|D'\| \leq \kappa_D$ as if they were deterministic variables, and we note $Q'_X \equiv \phi(X',D)$, $Q'_D \equiv \phi(X,D')$. Let us bound the variations
  \begin{align*}
    \left\vert \phi(X,D) - \phi(X',D)\right\vert = \frac{1}{n} \left\vert \tr \left(AQ (X-X') DX Q'_X\right)\right\vert \leq \frac{\kappa\kappa_D}{\varepsilon^2\sqrt n} \|X-X'\|_F.
  \end{align*}
  % The same way, $\left\vert \phi(X,D,Y) - \phi(X,D)\right\vert \leq \frac{\kappa\kappa_D}{\varepsilon^2\sqrt n} \|Y-Y'\|_F $, a
  We can also bound as in the proof of Proposition~\ref{pro:concentration_lineaire_XDY}:
  \begin{align*}
    \left\vert \phi(X,D) - \phi(X,D')\right\vert \leq \frac{1}{n} \left\Vert X Q'_D AQX\right\Vert_d \left\Vert D-D'\right\Vert_F.
  \end{align*}
  The concentration $1/\sqrt{n\log n}\left\Vert X Q'_D AQX\right\Vert_d \in O(1/\sqrt {\log n}) \pm \mathcal E_1$ is provided by Lemma~\ref{lem:concentration_norme_d_XQAQY} (actually Lemma~\ref{lem:concentration_norme_d_XQAQY} gives the concentration of $\left\Vert X Q AQX\right\Vert_d$, but the proof remains the same if one replaces one of the $Q$ with $Q_D'$, for a diagonal matrix $D'$, independent with $D$).
  To simplify the use of Theorem~\ref{off:plus_de_norme_2}, let us note $\tilde \phi \equiv \sqrt{\frac{ n}{\log n}} \phi$. Then we have:
  \begin{itemize}
    \item $\left\vert \tilde \phi(X,D) - \tilde \phi(X',D)\right\vert \leq \Psi_1(X,X',D) \left\Vert X-X'\right\Vert_F$ with $\Psi_1(X,D,D') \propto \mathcal E_2 + \mathcal E_1$,
    \item $\left\vert \tilde \phi(X,D) - \tilde \phi(X,D')\right\vert \leq \Psi_2(X,D,D') \left\Vert D-D'\right\Vert_F$ with $\Psi_2(X,D,D') \propto \mathcal E_2 + \mathcal E_1$,
  \end{itemize}
  and we can add an other inequality with an imaginary variable to be able to apply Theorem~\ref{off:plus_de_norme_2} with $m=3$, $\sigma = \mu_1 = \mu_2 = \mu_3 = 1$ which gives us $\tilde \phi(X,D) \propto \mathcal E_2 + \mathcal E_1 + \mathcal E_{3/2}$ from which we can deduce the concentration of $\tr(AQ) = \sqrt{\log n/n} \tilde \phi(X,D)$.
  % We can then conclude applying Theorem~\ref{off:plus_de_norme_2} (with $\mu = (1/\sqrt n, \sqrt {\log n/n})$ and $\sigma = 1$) to the variation control we provided and the concentration of $\frac{1}{n} \left\Vert X Q'_D AQX\right\Vert_d$ given by .
\end{proof}

\section{Proof of the estimation}\label{app:estimation_resolvent}
% To be able to bound $\|\mathbb E[Q] - \mathbb E[(I_p - \frac{1}{n}X (1/\mathbb E[1/D])X^T)^{-1}]$, one will need this last lemma.
 \begin{lemma}\label{lem:COncentration_xQAQyd}
   Under the hypotheses of Theorem~\ref{the:concentration_resolvent_XDX}, given a deterministic matrix $A \in \mathcal M_{p,n}$ such that $\|A\|_F\leq 1$:
   \begin{align*}
     x_i^TQAQx_i (1+D_i\bar \Delta_i) \in O(\sqrt n) \pm \mathcal E_{2/3} \left(\sqrt{\log n}\right).
   \end{align*}
 \end{lemma}
 \begin{proof}
  % Let us first note that since $\frac{1}{n}x_i^T Q_{-i}x_i \in O  \left(\sqrt{\frac{\log n}{n}}\right)  \pm \mathcal E_1 \left(\sqrt{\frac{\log n}{n}}\right)$
  Let us first show the concentration of:
  \begin{align*}
    \phi(X,D) 
    \equiv x_i^TQAQx_i (1+D_i \Delta_i)
    = x_i^TQAQ_{-i}x_i = x_i^TQ_{-i}AQx_i.
  \end{align*}
   % Introducing the notation $\phi(X,Y,D) \equiv x_i^TQAQx_i (1+D_i\bar \Delta_i)$
  Given $X,X' \in X(\Omega)$, we note $Q' \equiv (I_p - \frac{1}{n}X'DX'{}^T)^{-1}$ and $\Delta' \equiv \frac{1}{n}x_i^TQ'x_i$. One can bound:
   \begin{align*}
    &\left\vert \phi(X,D) - \phi(X',D) \right\vert \\
    &\hspace{1cm} \leq \left\vert x_i^T(Q-Q')AQ_{-i}x_i \right\vert + \left\vert x_i^TQ'AQx_i D_i (\Delta_i - \Delta_i')\right\vert + \left\vert x_i^TQ_{i}'A(Q-Q')x_i \right\vert
    % &\hspace{1cm} \leq \left\vert x_i^T(Q-Q')AQ_{-i}x_i \right\vert + \left\vert x_i^TQ'AQx_i D_i (\Delta_i - \Delta_i')\right\vert + \left\vert x_i^TQ_{i}'A(Q-Q')x_i \right\vert\\
   \end{align*}
   \begin{enumerate}
     \item 
   One can then bound ($\left\vert x_i^TQ_{-i}'A(Q-Q')x_i \right\vert$ is treated the same way):
   \begin{align*}
     &\left\vert x_i^T(Q-Q')AQ_{-i}x_i \right\vert\\
     &\hspace{0.5cm}= \frac{1}{n} \left\vert x_i^TQ(X-X')DX^TQ'AQ_{-i}x_i \right\vert + \frac{1}{n} \left\vert x_i^TQX'D(X-X')^TQ'AQ_{-i}x_i \right\vert \\
     &\hspace{0.5cm}\leq \frac{2\kappa^2\kappa_D}{\varepsilon^2}\|AQ_{-i}x_i\| \|X-X'\|,
   \end{align*}
   \item besides:
   \begin{align*}
     \left\vert \Delta_i - \Delta_i' \right\vert 
     &\leq  \frac{1}{n^2}\left\vert x_i^T(Q-Q_{-i}) x_i \right\vert 
     % &\leq  \frac{1}{n^2}\left\vert x_i^TQ_{-i}(X_{-i}-X_{-i}')DX_{-i}Q_{-i} x_i \right\vert 
     + \frac{2}{n} \left\vert x_i^TQ'_{-i} (x_i- x'_i) \right\vert\\
     &\leq \left( \frac{2\kappa^3\kappa_D}{\varepsilon^2\sqrt n} + \frac{2\kappa}{\varepsilon\sqrt n} \right) \|X-X'\|,
   \end{align*}
   \end{enumerate}
   Therefore:
   \begin{align*}
     \left\vert \phi(X,D) - \phi(X',D) \right\vert
     \leq O \left( \frac{1 }{\sqrt n}\left\vert x_i^TQ'AQx_i \right\vert  + \|AQ_{-i}x_i\|\right)\|X-X'\|.
   \end{align*}
   % The variation $\phi(X,D) - \phi(X,Y',D)$ for a given $Y'\in \mathcal{M}_{p,n}$ is bounded the same way. 
   We are then left to bound the variation towards $D$ which is slightly more tricky. Let us consider $D' \in \mathcal D_n$ and note $Q'{}' \equiv(I_p - \frac{1}{n}XD'X^T)^{-1}$ and $\Delta' \equiv \frac{1}{n}x_i^TQ'{}'x_i$. This time one should decompose followingly:
   \begin{align*}
     &\left\vert \phi(X,D) - \phi(X,D') \right\vert \\
    &\hspace{1cm} \leq \left\vert x_i^T(Q_{i}-Q_{i}'{}')AQx_i \right\vert + \left\vert x_i^TQ_{i}'{}'AQx_i D_i (\Delta_i - \Delta_i'{}')\right\vert + \left\vert x_i^TQ'{}'A(Q_{i}-Q_{i}'{}')x_i \right\vert
   \end{align*}
   \begin{enumerate}
     \item First let us take advantage of the independence between $x_i$ and $X_{-i}$ to bound as in the proof of Lemma~\ref{lem:norme_Q_m_i_Q_(i)_x_i}:
   \begin{align*}
     \left\vert x_i^T(Q_{i}-Q_{i}'{}')AQx_i \right\vert
     & = \frac{1}{n}\left\vert x_i^TQ_{i}X_{-i} (D-D')X_{-i}Q_{i}'{}'AQx_i \right\vert\\
     &\leq \frac{\kappa^2 }{\varepsilon^2}\left\Vert  \frac{1}{\sqrt n}x_i^TQ_{i}X_{-i} \right\Vert_\infty \|AQ_{-i}x_i\| \|D-D'\|_F
   \end{align*}
   \item Second, let us bound:
   \begin{align*}
     \left\vert \Delta_i - \Delta_i'{}' \right\vert 
     &\leq  \frac{1}{n^2}\left\vert x_i^TQ_{-i}X_{-i}(D-D'{}')X_{-i}Q_{-i} x_i \right\vert 
     \leq \frac{\kappa^4}{\varepsilon^2\sqrt n}  \|D-D'{}'\|
   \end{align*}
   \end{enumerate}
   That allows us to set that:
   \begin{align*}
     \left\vert \phi(X,D) - \phi(X,D') \right\vert \leq O \left( \frac{1 }{\sqrt n}\left\vert x_i^TQ'AQx_i \right\vert +  \left\Vert  \frac{1}{\sqrt n}x_i^TQ_{i}X_{-i} \right\Vert_\infty \|AQ_{-i}x_i\| \right) \|D-D'\|_F
   \end{align*}
   We have then all the elements to apply Theorem~\ref{off:plus_de_norme_2} with the concentrations:
   \begin{itemize}
     \item \sloppypar{$ \frac{1}{\sqrt {\log n}}\|AQ_{-i}x_i\| \in O(1) \pm \mathcal E_2(1)$ thanks to Lemmas~\ref{lem:concentration_Q_m_i_x_i}, \ref{lem:norme_Q_m_i_Q_(i)_x_i} and the fact that $\mathbb E[\|AQ_{-i}^{(i)}x_i\|]\leq \sqrt{\mathbb E[x_i^T Q_{-i}^{(i)}AAQ_{-i}^{(i)}x_i]} \leq \frac{1}{\varepsilon}\|\mathbb E[x_ix_i^T]\|^{1/2} \|A\|_F \leq O(1)$.}
     \item $\frac{1 }{\sqrt {n\log n}}\left\vert x_i^TQ'AQx_i \right\vert \in O(1/\sqrt{\log n}) \pm \mathcal E_2$ thanks to Lemma~\ref{lem:concentration_norme_d_XQAQY}
     \item $\left\Vert  \frac{1}{\sqrt {n\log n}}x_i^TQ_{i}X_{-i} \right\Vert_\infty \in O(1) \pm \mathcal E_2$ thanks to Lemma~\ref{lem:concentration_norm_infty_YQx}.
   \end{itemize}
   and the parameters $\sigma=1$ and $\mu = (1, 1,1)$ to obtain:
   \begin{align*}
     x_i^TQAQx_i (1+D_i \Delta_i) \in \mathcal E_2 \left(\sqrt{\log n}\right) +  \mathcal E_{1} \left(\sqrt{\log n}\right) +  \mathcal E_{2/3}(\sqrt{\log n}).
   \end{align*}

   To show the concentration of $x_i^TQAQx_i (1+D_i\bar \Delta_i)$, note that:
  \begin{align*}
    \left\vert x_i^TQAQx_i (1+D_i\bar \Delta_i) - x_i^TQAQx_i (1+D_i \Delta_i) \right\vert 
    &\leq \kappa_D \left\vert x_i^TQAQx_i \right\vert \left\vert \Delta_i - \bar \Delta_i \right\vert,
  \end{align*}
   Lemma~\ref{lem:conc_autour_prod} allows us to set the concentration of the product between $x_i^TQAQx_i \in O(\sqrt n) \pm \mathcal E_1$ and $\left\vert \Delta_i - \bar \Delta_i \right\vert \in 0 \pm \mathcal E_2(1/\sqrt {n}) + \mathcal E_1(1/n)$ satisfying $\left\vert \Delta_i - \bar \Delta_i \right\vert \leq \frac{\kappa^2}{\varepsilon}$:
   \begin{align*}
     \left\vert x_i^TQAQx_i \right\vert \left\vert \Delta_i - \bar \Delta_i \right\vert \in O(1) \pm \mathcal E_2(1) + \mathcal E_1(1/\sqrt n) 
   \end{align*}
  Lemma~\ref{lem:bounded_linear_concentration} then allows us to conclude on the concentration of $x_i^TQAQx_i (1+D_i \Delta_i)$.
 \end{proof}
The existence of the deterministic parameters $\delta \in \mathcal D_n$ such that:
\begin{align*}
   &\hspace{2.5cm}\delta = \frac{1}{n} \diag_{i\in [n]} \tr (\Sigma_i \tilde Q^\delta(D))\\
   & \left( \text{recall that } \tilde Q^\delta(D) \equiv  \left( I_p - \frac{1}{n} \sum_{i=1}^n \mathbb E \left[ \frac{D_i}{1+ D_i \delta_i} \right] \Sigma_i \right)^{-1}\right)
 \end{align*} 
 is a consequence of Theorem~\ref{the:definition_existence_tilde_Lambda}.
Note that Corollary~\ref{cor:deux_eq_deterministes_proches} giving a deterministic equivalent for $Q = (I_p - \frac{1}{n}XX^T)^{-1}$ imposes the columns of $X$ to be independent but they can possibly be non identically distributed. It concerns in particular the case of matrices $(I_p - \frac{1}{n}X \tilde DX^T)^{-1}$ for deterministic diagonal matrices $\tilde D$ as stated below.
It is at the basis of the estimation of $\mathbb E[Q] = \mathbb E[(I_p - \frac{1}{n}XDX^T)^{-1}]$.
\begin{proof}[Proof of Theorem~\ref{the:estimation_resolvent_XDX}]
Let us introduce the resolvent $\bar Q \equiv (I_p - \frac{1}{n}X \bar D X^T)^{-1}$ where we defined
\begin{align*}
  \bar D \equiv \frac{\mathbb E \left[ \frac{D}{I_p+\bar \Delta D} \right]}{I_p - \Delta \mathbb E \left[ \frac{D}{I_p+\bar \Delta D} \right]}.
\end{align*}
As will be understood later, this elaborated definition is taken for $\bar D$ to satisfy the following relation:
\begin{align*}
  \frac{\bar D}{I_p + \bar D \bar \Delta} = \mathbb E \left[ \frac{D}{I_p+\bar \Delta D} \right],
\end{align*}
it implies in particular that $\tilde Q^\delta(D) = \tilde Q^\delta(\bar D)$ for any $\delta \in \mathcal D_n$.
Let us then consider a deterministic matrix $A\in \mathcal M_{p}$, such that 
% \footnote{One could have more simply considered two deterministic vectors $u,v \in \mathbb R^p$ such that $\|u\|, \|v\|\leq 1$ to be able to bound $\|\mathbb E[Q] - \mathbb E[\bar Q]\|$, but this setting is closer to the setting of Lemma~\ref{lem:concentration_norme_d_XQAQY}}
$\|A\|_F \leq 1$ and bound:
   % We first have thanks to the vectorial version of Proposition~\ref{pro:concentration_lineaire_YAX}:
  \begin{align*}
    &\left\vert \mathbb E[\tr(AQ)] -\mathbb E[\tr(A\bar Q)]\right\vert\\
    &\hspace{1cm}= \frac{1}{n}\sum_{i=1}^n \left\vert \mathbb E \left[ x_i^T QA \bar Q x_i \bar \Delta_i^{-1}\left(\bar \Delta_i D_i + 1 - (\bar \Delta_i \bar D_i +1)\right)\right]\right\vert\\
    &\hspace{1cm}= \frac{1}{n}\sum_{i=1}^n \left\vert \mathbb E \left[ x_i^T QA \bar Q x_i \bar \Delta_i^{-1} \left( \bar \Delta_i D_i + 1 \right)\left( \bar \Delta_i \bar D_i + 1 \right)\left(\frac{1}{\bar \Delta_i \bar D_i +1} - \frac{1}{\bar \Delta_i D_i + 1} \right) \right]\right\vert\\
    &\hspace{1cm}= \frac{1}{n}\sum_{i=1}^n \left\vert \mathbb E \left[ x_i^T QA \bar Q x_i \left( \bar \Delta_i D_i + 1 \right)\left( \bar \Delta_i \bar D_i + 1 \right)\left(\frac{D_i}{\bar \Delta_i D_i + 1}  - \mathbb E \left[ \frac{D_i}{\bar \Delta_i D_i +1} \right]\right) \right]\right\vert\\
    &\hspace{1cm}= \frac{1}{n}\sum_{i=1}^n \left\vert \mathbb E \left[ \left( x_i^T QA \bar Q x_i \left( \bar \Delta_i D_i + 1 \right) - \mathbb E \left[ x_i^T QA \bar Q x_i \left( \bar \Delta_i D_i + 1 \right) \right] \right)\frac{D_i\left( \bar \Delta_i \bar D_i + 1 \right)}{\bar \Delta_i D_i + 1}  \right]\right\vert\\
    &\hspace{1cm}= \kappa_D \left( \frac{\kappa_D\kappa^2}{\varepsilon} + 1 \right)\sup_{i\in [n]} \mathbb E \left[ \left\vert x_i^T QA \bar Q x_i \left( \bar \Delta_i D_i + 1 \right) - \mathbb E \left[ x_i^T QA \bar Q x_i \left( \bar \Delta_i D_i + 1 \right) \right] \right\vert  \right]\\
    &\hspace{1cm}\leq O \left(\sqrt{\log n} \right)
    % &\hspace{1cm}\leq \sum_{i=1}^n  \sqrt{\mathbb E \left[\left\vert x_i^T A x_i - \mathbb E [x_i^T A x_i] \right\vert^2 \right] \mathbb E \left[\left\vert D_i -\mathbb E[D_i] \right\vert^2\right]} \ \ 
    % \leq  \ O \left(\log n \right),
  \end{align*}
  Thanks to Lemma~\ref{lem:COncentration_xQAQyd}. 
  Then Corollary~\ref{cor:deux_eq_deterministes_proches} allows us to state that the deterministic diagonal matrix $\delta(\bar D) \in \mathcal D_n$ solution to:
  \begin{align*}
    \delta = \frac{1}{n} \tr \left( \Sigma_i \tilde Q^\delta(\bar D) \right)&
    & \left( = \frac{1}{n} \tr \left( \Sigma_i \tilde Q^\delta(D) \right) \right),
  \end{align*}
  satisfies the estimation:
  \begin{align*}
    \left\Vert \mathbb E[ Q] - \tilde Q^{\delta(D)}(D) \right\Vert_F
    \leq \left\Vert \mathbb E[ Q] -  \mathbb E[ \bar Q] \right\Vert_F+\left\Vert \mathbb E[\bar Q] - \tilde Q^{\delta(D)}(D) \right\Vert_F
    \leq O \left( \sqrt{\log n} + \frac{1}{\sqrt n}   \right)
    \leq O \left( \sqrt{\log n}\right).
  \end{align*}

  % thanks to H\"older's inequality applied to the concentrations $D_i \propto \mathcal E_2$ and $x_i^T QA \bar Qx_i \propto \mathcal E_1(\log n)$ thanks to Lemma~\ref{lem:concentration_norme_d_XQAQY}; (with the same concentration constants for all $i\in [n]$). 
  % We can further bound:
  % \begin{align*}
  %   \left\Vert \mathbb E[\tilde Q] -\mathbb E[\bar  Q]\right\Vert_F
  %   &\leq \frac{1}{n}\left\Vert \mathbb E \left[\bar Q X (\tilde D - \mathbb E[D]) Y^T\tilde  Q\right]\right\Vert_F \leq \frac{\kappa^2}{\varepsilon^2}\left\Vert \tilde D - \mathbb E[D]\right\Vert_F \leq O(1),
  % \end{align*}
  % which eventually allows us to set that $\left\Vert \mathbb E[ Q] -\mathbb E[\tilde  Q]\right\Vert_F \leq O(\log n)$.
  
\end{proof}







 The same way that Theorem~\ref{the:concentration_resolvent_XDX} can be linked to Proposition~\ref{pro:concentration_lineaire_XDY} giving the linear concentration of $XDX^T$, the next proposition can be linked to Proposition~\ref{pro:Concentration_XDYu} giving the Lipschitz concentration of $XDX^Tu$ for any deterministic $u \in \mathbb R^p$. 
 % the proof is left in Appendix~\ref{app:preuve_concentration_Qu}.% we leave the proof in Appendix~\ref{app:preuve_concentration_uQ}.
\begin{proposition}\label{pro:concentration_uQ}
  In the setting of Theorem~\ref{the:concentration_resolvent_XDX}, for any deterministic vector~$u\in \mathbb R^p$ such that $\|u\|\leq O(1)$:
  \begin{align*}
    Qu \propto \mathcal E_1 \left(\sqrt{\frac{\log n}{n}}\right).
  \end{align*}
\end{proposition}
\begin{proof}
    With the same variables $X,X \in \mathcal M_{p,n}$, $D,D' \in \mathcal D_n$ and with the same notations $Q,Q'_X,Q'_D$ as in the proof of Theorem~\ref{the:concentration_resolvent_XDX}, we bound:
  % such that $\|X'\|, \|Y'\| \leq \sqrt \kappa$ and $\|D'\| \leq \kappa_D$, and employing abusively the notation $Q$ to designate the mapping satisfying $Q(X,D,Y) = Q$, first we can bound:
  \begin{align*}
    \left\Vert Qu - Q_X'u\right\Vert 
    &= \frac{1}{ n}\left\Vert Q (X-X') DX^TQ_X'u\right\Vert + \frac{1}{ n}\left\Vert Q X' D(X-X')^TQ_X'u\right\Vert\\
    &\leq \frac{\kappa \kappa_D}{ \varepsilon^2\sqrt n}\left\Vert X-X'\right\Vert,
  \end{align*}
  % and the same way, $\left\Vert Qu - Q_Y'u\right\Vert \leq \frac{\kappa \kappa_D}{ \varepsilon^2 \sqrt n}\left\Vert Y-Y'\right\Vert$.
  Second:
  \begin{align*}
    \left\Vert Qu - Q_D'u\right\Vert 
    &= \frac{1}{ n}\left\Vert Q_D' X (D-D')X^TQu\right\Vert
    \leq \frac{\kappa }{ \varepsilon \sqrt n}\left\Vert D-D'\right\Vert_F \|X^TQu \| _\infty,
  \end{align*}
  and we know from Lemma~\ref{lem:concentration_norme_infinie_Qx} that $\|X^TQu \| _\infty \in O(\sqrt{\log n}) + \mathcal E_2(\sqrt{\log n})$, which allows us to conclude with Theorem~\ref{off:plus_de_norme_2} that:
  \begin{align*}
    \sqrt{\frac{n}{\log n}} Qu \propto \mathcal E_2 + \mathcal E_1 ,
  \end{align*}
  but the $\mathcal E_2$ decay can here be removed since the $\mathcal E_1$ is looser.  
\end{proof}


% \bibliographystyle{alpha}
%  \bibliography{C:/Users/cosme/Documents/Travail/These/Biblio/biblio} 
% % \bibliography{biblio}
\end{document}